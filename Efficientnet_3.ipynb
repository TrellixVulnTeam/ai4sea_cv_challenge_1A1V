{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import time\n",
    "import os\n",
    "from helper import get_car_paths, get_cars_df\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch import nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_all(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        print(m.weight)\n",
    "    elif type(m) == nn.BatchNorm1d:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_effnet(name=\"efficientnet-b0\", pretrained=True, n_class=None):\n",
    "    \n",
    "    assert n_class != None, \"Please specify the number of output classes `n_class`\"\n",
    "    \n",
    "    if pretrained == True:\n",
    "        print(f\"Getting pretrained {name}\")\n",
    "        m = EfficientNet.from_pretrained(name)\n",
    "    else:\n",
    "        print(f\"Getting random initialized {name}\")\n",
    "        m = EfficientNet.from_name(name)\n",
    "    \n",
    "    n_in = m._fc.in_features\n",
    "    m._fc = nn.Sequential(\n",
    "#         nn.BatchNorm1d(n_in), \n",
    "        nn.Dropout(p=0.5), \n",
    "        nn.Linear(n_in, n_class))\n",
    "    m._fc.apply(init_weights)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Untar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path, test_path = get_car_paths()\n",
    "train_df = get_cars_df('cars_train_annos.mat')\n",
    "test_df = get_cars_df('cars_test_annos_withlabels.mat')\n",
    "# train_idx, val_idx = train_test_split(train_df.index, test_size=0.2, random_state=42, stratify=train_df[\"class_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.split(lambda m: (children(m)[-2],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, Squish Resize, 5 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms()\n",
    "sz = (300, 300)    #Squish Resize if a tuple is defined\n",
    "bs = 32\n",
    "img_data = ImageDataBunch.from_df(train_path, train_df,\n",
    "                                  ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0.2, bs=bs)\n",
    "img_data_test = ImageDataBunch.from_df(test_path, test_df,\n",
    "                                  ds_tfms=None, size=sz, fn_col=0, label_col=1, valid_pct=0., bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0718, -0.0658, -0.0117,  ...,  0.0062,  0.0119,  0.0428],\n",
      "        [ 0.0639, -0.0524, -0.0286,  ..., -0.0625,  0.0323, -0.0058],\n",
      "        [ 0.0173,  0.0078, -0.0237,  ...,  0.0203, -0.0095,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0226,  0.0317,  ...,  0.0056,  0.0121, -0.0259],\n",
      "        [-0.0409,  0.0348,  0.0044,  ..., -0.0138, -0.0759, -0.0460],\n",
      "        [-0.0812,  0.0199,  0.0363,  ..., -0.0296, -0.0574,  0.0551]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n_class = 196\n",
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6c8609b400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(img_data, eff_net, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.054483</td>\n",
       "      <td>6.036619</td>\n",
       "      <td>0.056511</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.785380</td>\n",
       "      <td>3.887783</td>\n",
       "      <td>0.205160</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.593256</td>\n",
       "      <td>1.852135</td>\n",
       "      <td>0.511056</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.746731</td>\n",
       "      <td>0.818504</td>\n",
       "      <td>0.760442</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.337999</td>\n",
       "      <td>0.513456</td>\n",
       "      <td>0.853194</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-1\n",
    "epochs = 5\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_squish_5epochs_delextraBN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46624365, tensor(0.8618)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_fp32().validate(img_data_test.train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, Squish Resize, 10 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms()\n",
    "sz = (300, 300)    #Squish Resize if a tuple is defined\n",
    "bs = 32\n",
    "img_data = ImageDataBunch.from_df(train_path, train_df,\n",
    "                                  ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0.2, bs=bs)\n",
    "img_data_test = ImageDataBunch.from_df(test_path, test_df,\n",
    "                                  ds_tfms=None, size=sz, fn_col=0, label_col=1, valid_pct=0., bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0052,  0.0297,  0.0563,  ..., -0.0224,  0.0170, -0.0083],\n",
      "        [ 0.0177, -0.0600, -0.0125,  ...,  0.0155, -0.0003, -0.0210],\n",
      "        [-0.0525,  0.0239, -0.0498,  ..., -0.0483,  0.0444, -0.0162],\n",
      "        ...,\n",
      "        [-0.0220,  0.0069, -0.0109,  ...,  0.0083, -0.0175,  0.0059],\n",
      "        [-0.0306,  0.0052,  0.0699,  ..., -0.0484,  0.0196, -0.0155],\n",
      "        [ 0.0479,  0.0388,  0.0242,  ...,  0.0422,  0.0465, -0.0197]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n_class = 196\n",
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Dodge Dakota Club Cab 2007,Dodge Journey SUV 2012,Dodge Charger Sedan 2012,Chevrolet Traverse SUV 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Toyota 4Runner SUV 2012,Ferrari 458 Italia Convertible 2012,Cadillac Escalade EXT Crew Cab 2007,Cadillac CTS-V Sedan 2012,Buick Regal GS 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6c8609b400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(img_data, eff_net, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.606143</td>\n",
       "      <td>3.938150</td>\n",
       "      <td>0.133907</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.647028</td>\n",
       "      <td>4.802804</td>\n",
       "      <td>0.179975</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.177080</td>\n",
       "      <td>2.877943</td>\n",
       "      <td>0.311425</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.606682</td>\n",
       "      <td>3.091734</td>\n",
       "      <td>0.265971</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.179604</td>\n",
       "      <td>2.375498</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.788048</td>\n",
       "      <td>1.457037</td>\n",
       "      <td>0.603194</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.482107</td>\n",
       "      <td>0.912161</td>\n",
       "      <td>0.754300</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.232403</td>\n",
       "      <td>0.583314</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.136256</td>\n",
       "      <td>0.437136</td>\n",
       "      <td>0.874693</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.086852</td>\n",
       "      <td>0.421378</td>\n",
       "      <td>0.881450</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-1\n",
    "epochs = 10\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_squish_10epochs_delextraBN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36836353, tensor(0.8988)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_fp32().validate(img_data_test.train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, Squish Resize, 20 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms()\n",
    "sz = (300, 300)    #Squish Resize if a tuple is defined\n",
    "bs = 32\n",
    "img_data = ImageDataBunch.from_df(train_path, train_df,\n",
    "                                  ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0.2, bs=bs)\n",
    "img_data_test = ImageDataBunch.from_df(test_path, test_df,\n",
    "                                  ds_tfms=None, size=sz, fn_col=0, label_col=1, valid_pct=0., bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[-0.0477,  0.0116, -0.0115,  ...,  0.0296,  0.0023, -0.0329],\n",
      "        [ 0.0353, -0.0733, -0.0141,  ...,  0.0182, -0.0187,  0.0307],\n",
      "        [ 0.0435, -0.0272, -0.0181,  ...,  0.0040,  0.0461,  0.0848],\n",
      "        ...,\n",
      "        [-0.0039,  0.0460,  0.0303,  ..., -0.0165, -0.0330, -0.0518],\n",
      "        [-0.0143, -0.0255,  0.0056,  ..., -0.0273,  0.0061,  0.0093],\n",
      "        [-0.0108,  0.0083,  0.0022,  ..., -0.0749,  0.0207, -0.0380]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n_class = 196\n",
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Hyundai Sonata Hybrid Sedan 2012,Dodge Journey SUV 2012,Dodge Charger Sedan 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Ford Expedition EL SUV 2009,Hyundai Azera Sedan 2012,Jeep Wrangler SUV 2012,GMC Savana Van 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6c8609b400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(img_data, eff_net, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.998348</td>\n",
       "      <td>4.599803</td>\n",
       "      <td>0.093366</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.685622</td>\n",
       "      <td>1.964207</td>\n",
       "      <td>0.501229</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.663632</td>\n",
       "      <td>2.638872</td>\n",
       "      <td>0.402334</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.673813</td>\n",
       "      <td>2.670644</td>\n",
       "      <td>0.411548</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.524455</td>\n",
       "      <td>3.306524</td>\n",
       "      <td>0.331081</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.420306</td>\n",
       "      <td>2.972173</td>\n",
       "      <td>0.360565</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.207585</td>\n",
       "      <td>2.392275</td>\n",
       "      <td>0.422604</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.038747</td>\n",
       "      <td>1.943943</td>\n",
       "      <td>0.517813</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.918218</td>\n",
       "      <td>1.920231</td>\n",
       "      <td>0.524570</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.733144</td>\n",
       "      <td>1.758879</td>\n",
       "      <td>0.551597</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.599593</td>\n",
       "      <td>1.586899</td>\n",
       "      <td>0.595823</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.489054</td>\n",
       "      <td>1.490038</td>\n",
       "      <td>0.630221</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.339034</td>\n",
       "      <td>1.064930</td>\n",
       "      <td>0.732187</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.202468</td>\n",
       "      <td>0.755735</td>\n",
       "      <td>0.796683</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.161268</td>\n",
       "      <td>0.677257</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.101375</td>\n",
       "      <td>0.617994</td>\n",
       "      <td>0.854423</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.073985</td>\n",
       "      <td>0.499813</td>\n",
       "      <td>0.885749</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.047019</td>\n",
       "      <td>0.479350</td>\n",
       "      <td>0.889435</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.036922</td>\n",
       "      <td>0.464269</td>\n",
       "      <td>0.894349</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.025803</td>\n",
       "      <td>0.460066</td>\n",
       "      <td>0.899263</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-1\n",
    "epochs = 20\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_squish_20epochs_delextraBN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38278568, tensor(0.9099)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_fp32().validate(img_data_test.train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, Squish Resize, 40 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms()\n",
    "sz = (300, 300)    #Squish Resize if a tuple is defined\n",
    "bs = 32\n",
    "img_data = ImageDataBunch.from_df(train_path, train_df,\n",
    "                                  ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0.2, bs=bs)\n",
    "img_data_test = ImageDataBunch.from_df(test_path, test_df,\n",
    "                                  ds_tfms=None, size=sz, fn_col=0, label_col=1, valid_pct=0., bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[-0.0236,  0.0427,  0.0382,  ..., -0.0184,  0.0693, -0.0091],\n",
      "        [ 0.0148,  0.0055,  0.0404,  ..., -0.0035,  0.0616, -0.0192],\n",
      "        [-0.0177,  0.0290, -0.0114,  ..., -0.0569,  0.0201,  0.0118],\n",
      "        ...,\n",
      "        [ 0.0604, -0.0160,  0.0609,  ..., -0.0144, -0.0334,  0.0391],\n",
      "        [-0.0505, -0.0488, -0.0248,  ..., -0.0867, -0.0318,  0.0139],\n",
      "        [-0.0135,  0.0413,  0.0100,  ..., -0.0285,  0.0018, -0.0007]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n_class = 196\n",
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Suzuki Kizashi Sedan 2012,Chevrolet Sonic Sedan 2012,Buick Rainier SUV 2007,Audi S4 Sedan 2012,Jeep Wrangler SUV 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6c8609b400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(img_data, eff_net, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.128613</td>\n",
       "      <td>4.861635</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.683148</td>\n",
       "      <td>2.941810</td>\n",
       "      <td>0.360565</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.803190</td>\n",
       "      <td>1.429626</td>\n",
       "      <td>0.640049</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.031447</td>\n",
       "      <td>1.325484</td>\n",
       "      <td>0.636978</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.987477</td>\n",
       "      <td>1.734598</td>\n",
       "      <td>0.580467</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.047483</td>\n",
       "      <td>2.103171</td>\n",
       "      <td>0.508600</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.109118</td>\n",
       "      <td>1.809640</td>\n",
       "      <td>0.555897</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.138561</td>\n",
       "      <td>2.383320</td>\n",
       "      <td>0.442260</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.131836</td>\n",
       "      <td>2.695831</td>\n",
       "      <td>0.391278</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.159948</td>\n",
       "      <td>2.840493</td>\n",
       "      <td>0.400491</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.089756</td>\n",
       "      <td>2.196323</td>\n",
       "      <td>0.469287</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.062845</td>\n",
       "      <td>2.523309</td>\n",
       "      <td>0.424447</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.946984</td>\n",
       "      <td>1.744101</td>\n",
       "      <td>0.558354</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.822988</td>\n",
       "      <td>2.159456</td>\n",
       "      <td>0.475430</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.813459</td>\n",
       "      <td>2.189612</td>\n",
       "      <td>0.479115</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.762388</td>\n",
       "      <td>2.193871</td>\n",
       "      <td>0.492015</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.653517</td>\n",
       "      <td>1.578319</td>\n",
       "      <td>0.595209</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.640919</td>\n",
       "      <td>2.695704</td>\n",
       "      <td>0.379607</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.577564</td>\n",
       "      <td>2.300038</td>\n",
       "      <td>0.487715</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.525528</td>\n",
       "      <td>2.090009</td>\n",
       "      <td>0.496314</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.479200</td>\n",
       "      <td>1.574462</td>\n",
       "      <td>0.613022</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.456539</td>\n",
       "      <td>1.626210</td>\n",
       "      <td>0.611794</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.398373</td>\n",
       "      <td>1.139597</td>\n",
       "      <td>0.710688</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.327681</td>\n",
       "      <td>1.552150</td>\n",
       "      <td>0.606265</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.271850</td>\n",
       "      <td>1.343840</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.250453</td>\n",
       "      <td>1.153728</td>\n",
       "      <td>0.706388</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.205975</td>\n",
       "      <td>0.997030</td>\n",
       "      <td>0.749386</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.157235</td>\n",
       "      <td>0.823290</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.146033</td>\n",
       "      <td>0.749771</td>\n",
       "      <td>0.808968</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.117530</td>\n",
       "      <td>0.636321</td>\n",
       "      <td>0.837224</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.082464</td>\n",
       "      <td>0.673376</td>\n",
       "      <td>0.836609</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.054887</td>\n",
       "      <td>0.572141</td>\n",
       "      <td>0.862408</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.058703</td>\n",
       "      <td>0.575651</td>\n",
       "      <td>0.861179</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.038792</td>\n",
       "      <td>0.467069</td>\n",
       "      <td>0.892506</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.025074</td>\n",
       "      <td>0.459627</td>\n",
       "      <td>0.887592</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.023534</td>\n",
       "      <td>0.427755</td>\n",
       "      <td>0.903563</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>0.414440</td>\n",
       "      <td>0.911548</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.013619</td>\n",
       "      <td>0.411977</td>\n",
       "      <td>0.912776</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.010439</td>\n",
       "      <td>0.412651</td>\n",
       "      <td>0.912776</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.012920</td>\n",
       "      <td>0.411762</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-1\n",
    "epochs = 40\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# learn.save(\"b3_squish_40epochs_delextraBN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Suzuki Kizashi Sedan 2012,Chevrolet Sonic Sedan 2012,Buick Rainier SUV 2007,Audi S4 Sedan 2012,Jeep Wrangler SUV 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6c8609b400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"b3_squish_40epochs_delextraBN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39753482, tensor(0.9114)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_fp32().validate(img_data_test.train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, Squish Resize, 60 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms()\n",
    "sz = (300, 300)    #Squish Resize if a tuple is defined\n",
    "bs = 32\n",
    "img_data = ImageDataBunch.from_df(train_path, train_df,\n",
    "                                  ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0.2, bs=bs)\n",
    "img_data_test = ImageDataBunch.from_df(test_path, test_df,\n",
    "                                  ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0., bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[-0.0191, -0.0069, -0.0193,  ..., -0.0038,  0.0247,  0.0120],\n",
      "        [-0.0190, -0.0468, -0.0101,  ...,  0.0143, -0.0132, -0.0188],\n",
      "        [-0.0589, -0.0107,  0.0006,  ...,  0.0211, -0.0241, -0.0263],\n",
      "        ...,\n",
      "        [ 0.0176, -0.0264,  0.0600,  ...,  0.0285,  0.0299,  0.0342],\n",
      "        [-0.0176, -0.0185,  0.0985,  ...,  0.0777,  0.0076,  0.0430],\n",
      "        [-0.0050, -0.0994, -0.0289,  ...,  0.0018,  0.0163, -0.0526]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n_class = 196\n",
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Hyundai Sonata Hybrid Sedan 2012,Geo Metro Convertible 1993,Dodge Journey SUV 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Dodge Durango SUV 2012,GMC Yukon Hybrid SUV 2012,Cadillac CTS-V Sedan 2012,Chrysler Sebring Convertible 2010,BMW M3 Coupe 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6c8609b400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(img_data, eff_net, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.133954</td>\n",
       "      <td>4.896970</td>\n",
       "      <td>0.078624</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.021070</td>\n",
       "      <td>3.411146</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.328663</td>\n",
       "      <td>1.715750</td>\n",
       "      <td>0.614251</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.176291</td>\n",
       "      <td>1.045913</td>\n",
       "      <td>0.740172</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.728208</td>\n",
       "      <td>0.983831</td>\n",
       "      <td>0.728501</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.652868</td>\n",
       "      <td>1.344279</td>\n",
       "      <td>0.652334</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.744472</td>\n",
       "      <td>1.498730</td>\n",
       "      <td>0.639435</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.833667</td>\n",
       "      <td>1.737340</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.781198</td>\n",
       "      <td>1.676369</td>\n",
       "      <td>0.603808</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.810158</td>\n",
       "      <td>1.829392</td>\n",
       "      <td>0.593980</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.881335</td>\n",
       "      <td>1.936797</td>\n",
       "      <td>0.534398</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.926038</td>\n",
       "      <td>1.785047</td>\n",
       "      <td>0.575553</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.983353</td>\n",
       "      <td>2.934071</td>\n",
       "      <td>0.395577</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.943052</td>\n",
       "      <td>1.766007</td>\n",
       "      <td>0.566953</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.968037</td>\n",
       "      <td>2.170839</td>\n",
       "      <td>0.508600</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.904181</td>\n",
       "      <td>2.114678</td>\n",
       "      <td>0.484644</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.890297</td>\n",
       "      <td>2.279387</td>\n",
       "      <td>0.442260</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.853188</td>\n",
       "      <td>2.169636</td>\n",
       "      <td>0.487101</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.835553</td>\n",
       "      <td>3.042727</td>\n",
       "      <td>0.393120</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.800583</td>\n",
       "      <td>1.903342</td>\n",
       "      <td>0.542998</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.701025</td>\n",
       "      <td>2.141877</td>\n",
       "      <td>0.484644</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.712637</td>\n",
       "      <td>2.700260</td>\n",
       "      <td>0.409705</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.715798</td>\n",
       "      <td>1.679396</td>\n",
       "      <td>0.610565</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.616185</td>\n",
       "      <td>2.500269</td>\n",
       "      <td>0.434275</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.556069</td>\n",
       "      <td>1.708243</td>\n",
       "      <td>0.595209</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>1.917386</td>\n",
       "      <td>0.547297</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.595390</td>\n",
       "      <td>1.888686</td>\n",
       "      <td>0.582310</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.516124</td>\n",
       "      <td>3.303757</td>\n",
       "      <td>0.343980</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.533138</td>\n",
       "      <td>2.140316</td>\n",
       "      <td>0.536241</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.513573</td>\n",
       "      <td>1.585833</td>\n",
       "      <td>0.606265</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.439703</td>\n",
       "      <td>1.906154</td>\n",
       "      <td>0.546069</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.403332</td>\n",
       "      <td>2.057744</td>\n",
       "      <td>0.535012</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>2.595026</td>\n",
       "      <td>0.421990</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.337495</td>\n",
       "      <td>1.480135</td>\n",
       "      <td>0.624693</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.315391</td>\n",
       "      <td>1.551357</td>\n",
       "      <td>0.635749</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.313838</td>\n",
       "      <td>1.618617</td>\n",
       "      <td>0.616708</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.265439</td>\n",
       "      <td>1.268379</td>\n",
       "      <td>0.708845</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.243006</td>\n",
       "      <td>1.279410</td>\n",
       "      <td>0.695332</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.206198</td>\n",
       "      <td>1.177508</td>\n",
       "      <td>0.732801</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.213671</td>\n",
       "      <td>1.468564</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.159157</td>\n",
       "      <td>1.261808</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.150491</td>\n",
       "      <td>1.026991</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.130089</td>\n",
       "      <td>0.915792</td>\n",
       "      <td>0.777027</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.114630</td>\n",
       "      <td>0.955336</td>\n",
       "      <td>0.789926</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.085612</td>\n",
       "      <td>0.803303</td>\n",
       "      <td>0.813882</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.061926</td>\n",
       "      <td>0.642521</td>\n",
       "      <td>0.861179</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.057814</td>\n",
       "      <td>0.592602</td>\n",
       "      <td>0.862408</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.050525</td>\n",
       "      <td>0.624632</td>\n",
       "      <td>0.851966</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.039253</td>\n",
       "      <td>0.600237</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.028355</td>\n",
       "      <td>0.641269</td>\n",
       "      <td>0.870393</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.027025</td>\n",
       "      <td>0.576618</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.019825</td>\n",
       "      <td>0.525553</td>\n",
       "      <td>0.880221</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.018206</td>\n",
       "      <td>0.514025</td>\n",
       "      <td>0.896192</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.519811</td>\n",
       "      <td>0.896806</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.009548</td>\n",
       "      <td>0.450226</td>\n",
       "      <td>0.909705</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.008874</td>\n",
       "      <td>0.458982</td>\n",
       "      <td>0.912162</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>0.463772</td>\n",
       "      <td>0.910934</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.007398</td>\n",
       "      <td>0.456965</td>\n",
       "      <td>0.912162</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>0.455511</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.453864</td>\n",
       "      <td>0.910934</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-1\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_squish_60epochs_delextraBN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46149084, tensor(0.9039)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_fp32().validate(img_data_test.train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, Squish Resize, 80 Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms()\n",
    "sz = (300, 300)    #Squish Resize if a tuple is defined\n",
    "bs = 32\n",
    "img_data = ImageDataBunch.from_df(train_path, train_df,\n",
    "                                  ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0.2, bs=bs)\n",
    "img_data_test = ImageDataBunch.from_df(test_path, test_df,\n",
    "                                  ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0., bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[-0.0528, -0.0006,  0.0088,  ..., -0.0220,  0.0292,  0.0340],\n",
      "        [-0.0068, -0.0522, -0.0363,  ...,  0.0164, -0.0067,  0.0089],\n",
      "        [ 0.0207, -0.0712, -0.0314,  ..., -0.0325, -0.0015, -0.0116],\n",
      "        ...,\n",
      "        [-0.0457, -0.0126,  0.0412,  ...,  0.0028,  0.0078,  0.0328],\n",
      "        [ 0.0070,  0.0334, -0.0511,  ..., -0.0133, -0.0134,  0.0442],\n",
      "        [-0.0337,  0.0558,  0.0454,  ...,  0.0514,  0.0118, -0.0756]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n_class = 196\n",
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Ford Ranger SuperCab 2011,Isuzu Ascender SUV 2008,Nissan Juke Hatchback 2012,Ford F-150 Regular Cab 2007,Chevrolet Malibu Sedan 2007\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6c8609b400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(img_data, eff_net, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.152809</td>\n",
       "      <td>4.900450</td>\n",
       "      <td>0.078010</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.064227</td>\n",
       "      <td>3.467667</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.548881</td>\n",
       "      <td>1.940120</td>\n",
       "      <td>0.601351</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.381855</td>\n",
       "      <td>1.138963</td>\n",
       "      <td>0.726658</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.766221</td>\n",
       "      <td>0.917035</td>\n",
       "      <td>0.759828</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.495663</td>\n",
       "      <td>0.895098</td>\n",
       "      <td>0.752457</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.461132</td>\n",
       "      <td>0.932477</td>\n",
       "      <td>0.744472</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.573592</td>\n",
       "      <td>1.271542</td>\n",
       "      <td>0.665848</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.582742</td>\n",
       "      <td>1.410255</td>\n",
       "      <td>0.664619</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.670396</td>\n",
       "      <td>1.604575</td>\n",
       "      <td>0.622236</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.689977</td>\n",
       "      <td>1.603123</td>\n",
       "      <td>0.616093</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.769062</td>\n",
       "      <td>2.035326</td>\n",
       "      <td>0.557740</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.763288</td>\n",
       "      <td>1.420618</td>\n",
       "      <td>0.644349</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.796713</td>\n",
       "      <td>1.883314</td>\n",
       "      <td>0.550983</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.798330</td>\n",
       "      <td>1.415133</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.845569</td>\n",
       "      <td>1.658883</td>\n",
       "      <td>0.584152</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.883485</td>\n",
       "      <td>2.292282</td>\n",
       "      <td>0.485258</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.943648</td>\n",
       "      <td>1.468848</td>\n",
       "      <td>0.617936</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.890720</td>\n",
       "      <td>1.884006</td>\n",
       "      <td>0.547297</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.841567</td>\n",
       "      <td>2.037313</td>\n",
       "      <td>0.520885</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.777616</td>\n",
       "      <td>2.636390</td>\n",
       "      <td>0.372850</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.865880</td>\n",
       "      <td>2.405350</td>\n",
       "      <td>0.455160</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.845174</td>\n",
       "      <td>2.235956</td>\n",
       "      <td>0.477887</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.823526</td>\n",
       "      <td>2.353263</td>\n",
       "      <td>0.465602</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.715966</td>\n",
       "      <td>2.397549</td>\n",
       "      <td>0.470516</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.755550</td>\n",
       "      <td>2.564147</td>\n",
       "      <td>0.434275</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.728361</td>\n",
       "      <td>2.445788</td>\n",
       "      <td>0.414619</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.638530</td>\n",
       "      <td>1.773806</td>\n",
       "      <td>0.570025</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.640538</td>\n",
       "      <td>3.209031</td>\n",
       "      <td>0.420762</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.653341</td>\n",
       "      <td>1.743592</td>\n",
       "      <td>0.581695</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.616666</td>\n",
       "      <td>2.294170</td>\n",
       "      <td>0.466216</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.620103</td>\n",
       "      <td>2.586450</td>\n",
       "      <td>0.428747</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.549766</td>\n",
       "      <td>1.658245</td>\n",
       "      <td>0.618550</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.565185</td>\n",
       "      <td>1.912949</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.530343</td>\n",
       "      <td>2.367749</td>\n",
       "      <td>0.495086</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.515957</td>\n",
       "      <td>2.487015</td>\n",
       "      <td>0.458231</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.474957</td>\n",
       "      <td>1.428162</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.484333</td>\n",
       "      <td>2.016390</td>\n",
       "      <td>0.521499</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.461882</td>\n",
       "      <td>2.460906</td>\n",
       "      <td>0.442260</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.465969</td>\n",
       "      <td>2.428281</td>\n",
       "      <td>0.494472</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.415935</td>\n",
       "      <td>2.131502</td>\n",
       "      <td>0.520270</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.441648</td>\n",
       "      <td>2.033992</td>\n",
       "      <td>0.530713</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.363524</td>\n",
       "      <td>2.207208</td>\n",
       "      <td>0.495700</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.392976</td>\n",
       "      <td>1.778233</td>\n",
       "      <td>0.571867</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.299499</td>\n",
       "      <td>1.758946</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.346857</td>\n",
       "      <td>1.582724</td>\n",
       "      <td>0.610565</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.307177</td>\n",
       "      <td>1.654715</td>\n",
       "      <td>0.611179</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.278040</td>\n",
       "      <td>1.373844</td>\n",
       "      <td>0.667076</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.281041</td>\n",
       "      <td>1.494962</td>\n",
       "      <td>0.659705</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.243977</td>\n",
       "      <td>1.276561</td>\n",
       "      <td>0.689803</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.214366</td>\n",
       "      <td>1.300063</td>\n",
       "      <td>0.708231</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.233880</td>\n",
       "      <td>1.367676</td>\n",
       "      <td>0.675061</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.202526</td>\n",
       "      <td>1.370997</td>\n",
       "      <td>0.684889</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.172391</td>\n",
       "      <td>0.882025</td>\n",
       "      <td>0.785627</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.165985</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.776413</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.146543</td>\n",
       "      <td>1.085242</td>\n",
       "      <td>0.747543</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.143583</td>\n",
       "      <td>1.318799</td>\n",
       "      <td>0.685504</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.121944</td>\n",
       "      <td>1.029146</td>\n",
       "      <td>0.753685</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>1.459969</td>\n",
       "      <td>0.664005</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.089296</td>\n",
       "      <td>0.753597</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.059408</td>\n",
       "      <td>0.709561</td>\n",
       "      <td>0.830467</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.088715</td>\n",
       "      <td>0.865357</td>\n",
       "      <td>0.794840</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.047906</td>\n",
       "      <td>0.672157</td>\n",
       "      <td>0.842138</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.061920</td>\n",
       "      <td>0.671866</td>\n",
       "      <td>0.838452</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.051187</td>\n",
       "      <td>0.641023</td>\n",
       "      <td>0.843980</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.039101</td>\n",
       "      <td>0.669958</td>\n",
       "      <td>0.845823</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.034366</td>\n",
       "      <td>0.530986</td>\n",
       "      <td>0.883907</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.025978</td>\n",
       "      <td>0.533045</td>\n",
       "      <td>0.883907</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.019229</td>\n",
       "      <td>0.555965</td>\n",
       "      <td>0.878993</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.017344</td>\n",
       "      <td>0.557618</td>\n",
       "      <td>0.875307</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>0.481233</td>\n",
       "      <td>0.892506</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.009192</td>\n",
       "      <td>0.459987</td>\n",
       "      <td>0.899263</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.010587</td>\n",
       "      <td>0.460161</td>\n",
       "      <td>0.898034</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.011326</td>\n",
       "      <td>0.434576</td>\n",
       "      <td>0.906020</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.435591</td>\n",
       "      <td>0.904177</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.010707</td>\n",
       "      <td>0.433890</td>\n",
       "      <td>0.902334</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>0.434710</td>\n",
       "      <td>0.903563</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.437142</td>\n",
       "      <td>0.903563</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.904791</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.434451</td>\n",
       "      <td>0.902948</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-1\n",
    "epochs = 80\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_squish_80epochs_delextraBN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4805546, tensor(0.8992)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_fp32().validate(img_data_test.train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, Squish Resize, 40 Epochs, lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms()\n",
    "sz = (300, 300)    #Squish Resize if a tuple is defined\n",
    "bs = 32\n",
    "img_data = ImageDataBunch.from_df(train_path, train_df,\n",
    "                                  ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0.2, bs=bs)\n",
    "img_data_test = ImageDataBunch.from_df(test_path, test_df,\n",
    "                                  ds_tfms=None, size=sz, fn_col=0, label_col=1, valid_pct=0., bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[-0.0239, -0.0177,  0.0071,  ...,  0.0104,  0.0427,  0.0418],\n",
      "        [ 0.0114, -0.0531,  0.0295,  ...,  0.0074,  0.0542, -0.0335],\n",
      "        [ 0.0402,  0.0255,  0.0226,  ..., -0.0102,  0.0198, -0.0280],\n",
      "        ...,\n",
      "        [ 0.0772,  0.0457,  0.0292,  ...,  0.0304, -0.0328,  0.0189],\n",
      "        [ 0.0131,  0.0357, -0.0120,  ..., -0.0017, -0.0066, -0.0547],\n",
      "        [-0.0423, -0.0165,  0.0178,  ..., -0.0440,  0.0151, -0.0741]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n_class = 196\n",
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012,Geo Metro Convertible 1993,Dodge Journey SUV 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Dodge Ram Pickup 3500 Quad Cab 2009,Toyota Camry Sedan 2012,Hyundai Sonata Hybrid Sedan 2012,Mercedes-Benz E-Class Sedan 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6c8609b400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(img_data, eff_net, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.150686</td>\n",
       "      <td>3.233071</td>\n",
       "      <td>0.257985</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.930309</td>\n",
       "      <td>1.783571</td>\n",
       "      <td>0.523342</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.542841</td>\n",
       "      <td>3.070554</td>\n",
       "      <td>0.357494</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.664267</td>\n",
       "      <td>3.180680</td>\n",
       "      <td>0.313882</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.837202</td>\n",
       "      <td>2.871533</td>\n",
       "      <td>0.321253</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.105239</td>\n",
       "      <td>4.499258</td>\n",
       "      <td>0.104423</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.230788</td>\n",
       "      <td>3.966949</td>\n",
       "      <td>0.164005</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.349035</td>\n",
       "      <td>5.836237</td>\n",
       "      <td>0.047297</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.433221</td>\n",
       "      <td>5.261829</td>\n",
       "      <td>0.064496</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.432935</td>\n",
       "      <td>5.841343</td>\n",
       "      <td>0.030713</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.404061</td>\n",
       "      <td>6.122451</td>\n",
       "      <td>0.024570</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.388162</td>\n",
       "      <td>8.265894</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.294418</td>\n",
       "      <td>6.372668</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.145016</td>\n",
       "      <td>6.457858</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.098132</td>\n",
       "      <td>6.308825</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.967750</td>\n",
       "      <td>6.629152</td>\n",
       "      <td>0.015971</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.951567</td>\n",
       "      <td>6.031148</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.808609</td>\n",
       "      <td>6.947966</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.837846</td>\n",
       "      <td>7.245969</td>\n",
       "      <td>0.028256</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.737472</td>\n",
       "      <td>6.287237</td>\n",
       "      <td>0.010442</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.600521</td>\n",
       "      <td>8.739149</td>\n",
       "      <td>0.007371</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.513090</td>\n",
       "      <td>5.954179</td>\n",
       "      <td>0.074324</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.371446</td>\n",
       "      <td>5.639269</td>\n",
       "      <td>0.072482</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.271040</td>\n",
       "      <td>6.944672</td>\n",
       "      <td>0.047912</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.206336</td>\n",
       "      <td>6.828535</td>\n",
       "      <td>0.066953</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.109218</td>\n",
       "      <td>6.086686</td>\n",
       "      <td>0.062039</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.903845</td>\n",
       "      <td>4.323419</td>\n",
       "      <td>0.151106</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.799120</td>\n",
       "      <td>4.167167</td>\n",
       "      <td>0.123464</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.719425</td>\n",
       "      <td>5.144617</td>\n",
       "      <td>0.106265</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.603715</td>\n",
       "      <td>3.541459</td>\n",
       "      <td>0.254914</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.493461</td>\n",
       "      <td>2.011450</td>\n",
       "      <td>0.504914</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.399017</td>\n",
       "      <td>2.299665</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.294785</td>\n",
       "      <td>1.698228</td>\n",
       "      <td>0.582310</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.227661</td>\n",
       "      <td>1.078412</td>\n",
       "      <td>0.707617</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.198262</td>\n",
       "      <td>0.759536</td>\n",
       "      <td>0.797912</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.125752</td>\n",
       "      <td>0.641913</td>\n",
       "      <td>0.830467</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.090840</td>\n",
       "      <td>0.512268</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.082811</td>\n",
       "      <td>0.465849</td>\n",
       "      <td>0.874693</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.059948</td>\n",
       "      <td>0.458960</td>\n",
       "      <td>0.884521</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.064988</td>\n",
       "      <td>0.457593</td>\n",
       "      <td>0.885135</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXl8VNX5/99nsodskIQECJCwy76DoIgbiri0rli3WlurtnVvxfqtSquW2v60tXWpVat1V1BRAVFAQBHQsIc1QAIJgZCFbGRPzu+PM5N9mUlmTZ7365XXzNx77r1PMpPPnPucZ1FaawRBEATfxeJpAwRBEITOIUIuCILg44iQC4Ig+Dgi5IIgCD6OCLkgCIKPI0IuCILg44iQC4Ig+Dgi5IIgCD6OCLkgCIKP4++Kk8bExOjExERXnFoQXMfpXCjMgLjR4BfgaWuEbsaWLVtytdaxHTnWJUKemJhIcnKyK04tCK5j+W/h+5fh1hdh4AxPWyN0M5RSRzp6rLhWBMFGfpp5LMjwrB2C4CAi5IJg45RVyAuPetYOQXAQEXJBAKitgVPWO1uZkQs+hkt85ILgcxQdg9oq87xQhNzdVFVVkZmZSXl5uadNcTnBwcEkJCQQEOC8BXURckGAev94SC+ZkXuAzMxMwsPDSUxMRCnlaXNchtaavLw8MjMzSUpKctp5xbUiCFDvH088CwozQRquuJXy8nKio6O7tIgDKKWIjo52+p2HCLkggJmRWwJgwHSoLoPSPE9b1O3o6iJuwxW/pwi5IADkH4aeAyFqoHldIJErgu8gQi4IYFwrPZMgqr95LQue3YqCggJeeOEFh4+75JJLKCgocIFFjiFC3tVJXQX7v/C0Fd6N1pCfDr2SINIq5LLg2a1oTchramraPG758uVERUW5yiy7kaiVrs7qhVBVBsMv9rQl3ktpHlQWmxl5SE8IDJMZeTdjwYIFHDp0iPHjxxMQEEBYWBh9+vRh+/bt7Nmzhx/96EdkZGRQXl7OPffcw+233w7UlyMpKSlh7ty5nHXWWXz33Xf069ePpUuXEhIS4hb7Rci7MrW1kHcQqsuNmAe450Plc9hCD3sNAqXMrFxm5B5j4We72ZNV5NRzjuwbwWOXjWp1/6JFi0hJSWH79u2sXbuWefPmkZKSUhci+Nprr9GrVy/KysqYMmUKV111FdHR0Y3OkZqayrvvvst//vMfrr32WpYsWcKNN97o1N+jNcS10pUpOgZVpaBrIWe/p63xXmyhh72scb1R/SVNv5szderURnHezz33HOPGjWP69OlkZGSQmpra7JikpCTGjx8PwKRJk0hPT3eXufbNyJVS9wE/BzSwC7hVa931U7B8ndwD9c+zd0Pf8Z6zxZvJTwNUfcRKZH/I+N6jJnVn2po5u4sePXrUPV+7di2rVq1i48aNhIaGMnv27BbjwIOCguqe+/n5UVZW5hZbwY4ZuVKqH3A3MFlrPRrwA+a72jDBCdiEXPnByT2etcWbyT8MEX0hINi8juoP5QVQUexZuwS3ER4eTnFxy+93YWEhPXv2JDQ0lH379rFp0yY3W9c+9vrI/YEQpVQVEApkuc4kwWnkHoDgSLOIl53iaWu8F1vooY2GkStxIz1jk+BWoqOjmTlzJqNHjyYkJIS4uLi6fRdffDEvvfQSY8eOZfjw4UyfPt2DlrZMu0KutT6mlPobcBQoA77UWn/pcsuEzpObCjHDIWYYpMpb1ir5aTBsTv3rqAHmsVCEvDvxzjvvtLg9KCiIFStWtLjP5gePiYkhJaV+svTggw863b62sMe10hO4AkgC+gI9lFLNlmKVUrcrpZKVUsk5OTnOt1RwnNwDRsTjRsHpk1Ai70szKkrM36bFGbkseAq+gT1RKxcAaVrrHK11FfAR0KwPltb6Za31ZK315NjYDrWdE5xJWQGUZEPM0PpZ5cndnrXJGzmVbh57NRDysDhTd6Uw0yMmCYKj2CPkR4HpSqlQZaq9nA/sda1ZQqfJO2geY4aZZsJgIleExpxqEENuw2KByH6SFCT4DO0KudZ6M7AY2IoJPbQAL7vYLqGz2OLGY4ZBjxjo0RuyJXKlGbZkoJ5NakNLUpDgQ9gVtaK1fgx4zMW2CM4k94BxD/RMNK/jRkrkSkucSjNp+SFN6mVEDYBDazxjkyA4iGR2dlVyUyF6MPhZv6vjRkPOPtObUqgn/3Dz2TiYGXnxCaiudL9NguAgIuRdldwDZqHTRu+RpuaKzZUgGPLTGi902ojqD2gokgVPoWXCwsIAyMrK4uqrr25xzOzZs0lOTna5LSLkXZGaKuMyiBlWvy3OmvYs7pV6aqpMZEprM3IQP7nQLn379mXx4sUetUGEvCuSnwa11Y2FPHY4KIuk6jek4CjomjZm5EjkSjfioYcealST/PHHH2fhwoWcf/75TJw4kTFjxrB06dJmx6WnpzN6tIkMKysrY/78+YwdO5brrrvObfVWpIxtVyTXFrHSwLUSEALRQyQEsSGnWolYAYhIAJTMyD3BigVwYpdzzxk/BuYuanPI/Pnzuffee7nrrrsA+OCDD/jiiy+47777iIiIIDc3l+nTp3P55Ze32nfzxRdfJDQ0lJ07d7Jz504mTpzo3N+jFUTIuyK2YlkNZ+Rg/OTHd7jfHm8lv0n52ob4B0J4vMzIuxETJkzg5MmTZGVlkZOTQ8+ePenTpw/33Xcf69evx2KxcOzYMbKzs4mPj2/xHOvXr+fuu+8GYOzYsYwdO9YttouQd0VyUyG8LwSFN94eNxr2fGLS0oPCPGObN3EqHfxDIKzlf0oTSy5p+m6nnZmzK7n66qtZvHgxJ06cYP78+bz99tvk5OSwZcsWAgICSExMbLGEbUNam627EvGRd0WaRqzYsKXq5+xzrz3eSn6aibO3tPJvENVfZuTdjPnz5/Pee++xePFirr76agoLC+nduzcBAQF8/fXXHDlypM3jZ82axdtvvw1ASkoKO3fudIfZIuRdDq2tVQ+HNd8nkSuNyT/cslvFRmR/KDxmWuYJ3YJRo0ZRXFxMv3796NOnDzfccAPJyclMnjyZt99+mxEjRrR5/J133klJSQljx47l6aefZurUqW6xW1wrXY2SbKgoalnIIweYxsKSqm++8E6lw+DzWh8TmQC1VeZvGtHHbaYJnmXXrvqF1piYGDZu3NjiuJKSEsA0YLaVsA0JCeG9995zvZFNkBl5VyOnhYgVGxaLWfCUyBVr1mZZ2zPyhnXJBcGLESHvatgiVmKHt7w/bqQpZ6u1+2zyRtoKPbQhdckFH0GEvKuRm2rcJ+GtuALiRkPZKSg+7l673EFBhv1fUG2FHtqQpCC3orvJ5MIVv6cIeVfDFrHSWghUb2vkSlfyk2sNq/8Efx8NO96175hTaSbT1TbrbomgcAiOkqQgNxAcHExeXl6XF3OtNXl5eQQHBzv1vLLY2dXITYXEma3vt4UgZqfA0AvcY5MrqamCT++GHe+Ysr3b34HxP2n/uPw0s5jpH9j2OAlBdAsJCQlkZmbSHdpEBgcHk5CQ4NRzipB3JSpKTLW+lhY6bYT0hIh+XaPmSkUxvH8THP4azn3ElOhd9xcoyoKIvm0feyqtcVeg1ogcYMIUBZcSEBBAUlIbbi6hTexpvjxcKbW9wU+RUupedxgnOEheqnmMaWWh00bcKN+PXCk+Af+dC2nr4Yrn4ZzfwZhrAA0pH7V/fGt1yJtim5F38Vt+wbexp9Xbfq31eK31eGASUAp87HLLBMfJtQl5CzHkDek90oQp1lS53iZXkLMfXrkQ8g7DTz6ACTea7TFDoO8E2PVh28eXFZgF37YWOm1E9ofKEjNeELwURxc7zwcOaa3bzlMVPEPuAVB+7QtU3GiT6GITfl/iyEZ4dY5pknHrsuZ+/jHXwPHtbf9u9oQe2pDIFcEHcFTI5wN2hgUIbif3gKkd4h/U9jjbgqev+cn3fAr/u8I0k/75V2b23ZRRVwIKdrVR6N+e0EMb0mBC8AHsFnKlVCBwOdDifatS6nalVLJSKrk7rDx7Ja3VWGlK9FAT4eFLfvI9n8IHN0OfcfCzL+ubSjclog8kngUpi1v3a9fNyFs5R0Pqsjud1PKt6Dh8+FPY/G8oznbOOYVujyMz8rnAVq11i58+rfXLWuvJWuvJsbGxzrFOsJ/aGsg72HbEig3/QCP4viTk3z1nfrdbPoUe0W2PHXON+Vsc397y/vw06BHbvMxvS4RGm1K3znKtpCyB3R/Dit/BMyPgjcthyxtQmu+c8wvdEkeE/HrEreK9nEqHmsrWU/ObEjfKd1wruQch8wezqBkQ0v74kZebO47W3Cun0u3zj4NJrIpMcF6aftp6c0d01yY4+0HzBfHZ3fC3YfDOdbDzAxNWKQgOYJeQK6VCgQsBO+K6BI9gb8SKjbiRRkTKClxnk7PY+Z7JwhxzrX3jQ3rC0Dlm9ltb03x/vp0x5DaclRRUUwVHNkDSLOh9Bpz3CPxmK9y+FqbfYdqbffQL+OsQ2OH+CnqC72KXkGutS7XW0VrrQlcbJHQQW7Gs6CH2jY8zzWI5udc19jiL2lrY+T4Mmu1YKdkxV5t6Mkc2NN5eVQ5Fx+xb6LQR2d85i51Z200oY9Ks+m1KmUXbOU/AvSnws5UQOwK+egyqKzt/TaFbILVWugq5B4zfN7SXfeN7N0jV92aObjRujXHXO3bcsItN8bCm7pWCI4C237UCZkZemguVpY7Z0JS0deYx8eyW91ssMGA6nP8olJwwC7aCYAci5F0FeyNWbET0NQWhvN1PvuNdI8gj5jl2XGCoOWbPUqiuqN/uSOihjUgnRa6krYe4Me0v1g4+D3qPgu/+KRmlgl2IkHcVcg84JuRKeX+qflUZ7P4ERl4BgT0cP37MNVBeAAdX129zJBnIRl1SUCcWPKvKIWNzY7dKaygFM35jvmQb2i4IrSBC3hU4nQtl+Y4JOViFfI/rZ32HvjYp9TkHHDtu3zKoLIZx8zt23UGzTfhgw5T9/DQzw+8RY/95nJEUlPmDyUa1R8gBRl9lasp/91zHryl0G0TIuwK2hU5Hhbz3SCOUruyAs38FvHMtZH4PKx927Ngd70FEAgw8q2PX9guAUT82NlSY/oqcSjOz8dbqtbdEeB9T+qAzkStp6805Bs6wb7x/IEy7w/jVj+/o+HWFboEIeVegTsjtSAZqSF3kiov85ClL4P0bIX4MzPotHFwFqavsO7Y4Gw6thnHXmUXAjjL6atObc/9y8zo/DXolOnYOP39T+rczM/K09SY6JTjC/mMm/dTcPXz3r45fV+gWiJB3BXJTwT+47W43LdF7hHl0ReTK1jdh8W3Qfxrc9IkR8p5J8OX/QU11+8fv+hB0LYztoFvFRv9p5u+y60MTU+5IMlBDOhNLXlECx5Ltd6vYCImCibeYL0RnlQgQuiQi5F2B3APW+ikOvp1B4abeSGtt30pOGhFZscB03mkY/dEWm16CT39toi9uWGxmof5BcOEfIWcvbPtf++fY8R70mwSxDrqLmmKxGH/zwdVwYqep+uhIMpCNyP4dF9Ojm6C22nEhB5MoBLDpxY5dW+gWSIegrkDuASN6HaF3g8iV03lw5FtI+wbSv4GcfWa7JcAI4KrHYcovYPLPWg+hW/83WPMnGHEpXP1a40qMZ1wGA2bAmieNy6M1N8OJXZC9Cy75W8d+p6aMuQY2/B2+fda8diT00EZUf9iVZe4m/Bz8t0lbB36B5u7A4esOMH7+LW+Y5hnBkY6fQ+jyyIzc16kqg1NHHF/otBE3ynQWemEG/HWQqTC4/R3jE77gcfj5GnjkONz0sfF1f/0EPDsSPrvHNHiwoTWsWmhEfMy1cM0bzcvpKgUXPWmSa759pnWbdrwHFn9rSVonEDcKYs8wFRShY66VyATQNVCc5fixaeshYaqJbe8IM35jFqW3vNGx44Uuj8zIfZ28Q4B2fKHTxuBzIflVE4533v9B4izoN9FEfDQad575ObkPNr1gxHbL6zDkQjjzLjiwEja/ZBbo5j3bupun30Tj9974Aky6FXoObLy/ptr4s4de1H7ijL0oZVL21/zJ3F1EdqDxbcMQRFtpW3soO2WiTmY7GLHTkL7jjVtm04smkqW9htFCt0Nm5L5OR0MPbQycAb87bMrDzvotDJjWXMQb0nsEXP4c3LfbNDw+vgPe/LER8TN/DZf+vX1f/fl/MEWwVi9svi9tLZRkdzx2vDVGX2UeowaAxc/x4+vqkju44Jm+AdAd8483ZMbd5m5gt9StE5ojQu7r5KYCyv5iWc6iR4zx2d6XAj96CS77hyn8ZE98dmSCcRekLIGM7xvv2/GeKR0w7CLn2tsrySQIdXQtwTaLdzQEMW09BIR2/Lo2hlxgimlJ2r7QAiLkvk7uATNbtKdOtyvwD4Lx1xuXiiNJNjPvgbA4WPn7emEqL4K9n5vZc3vt6jrCDYvhxy917NiAEFOUzNE0/bT1MODMzrtDbGn72Slw+OvOnUvocoiQ+zq5+zvuVvEkQWFw3h9M6rrNXbD3U5O842ilQ3vxC+iYW8WGo+VsS06acMvOulVsjLnGfPl990/nnE/oMoiQ+zK1taZ7ji8KOcD4n5hqgF89bopK7XgPeg2GhMmetqxlHE0KSltvHp0l5P5BMO2XcGgNnPDy8sOCW7G3Q1CUUmqxUmqfUmqvUupMVxsmtENtDXz5iJnB9hnraWs6hsUPLnrCuCtW/t7Ero+73jEXjTuxJQXZ66NOWw9BkaZhtLOYdCsE9ICNkrYv1GPvjPwfwBda6xHAOMDL28p0ccoLTX/HTS/AtDtNco2vMmg2DJtrQiABxtrZzs0TRA0wFQxP59g3Pm09JM7snDunKaG9TP2ZlI9M6zhBwA4hV0pFALOAVwG01pVaax9o9NhFyU+DV+eYBa9Ln4W5ixzPNPQ25vzJJAANnNk8rtybcKScbcFRU2nRWW6VhgyYATUVjROyhG6NPQowCMgB/quUGgdsAe7RWp92qWVCc9I3mGqCuhZu/AgGneNpi5xDzFC4/v36Bg7eSl2DiQxIaCecMO0b8+gKIbe50k7shPjRzj+/4HPY41rxByYCL2qtJwCngQVNBymlbldKJSulknNy7Lz1FOxn65vwvytMo4RfrOk6Im5j6AUQO9zTVrRN1ABAmV6a7VVwTFsPoTGmNICziR4C/iGmJo0gYJ+QZwKZWuvN1teLMcLeCK31y1rryVrrybGxsc60sXtTW2NKv376a0g8C36+CqIHe9qq7klwpGmMvPczU5OmqrzlcVobIU86u3O11FvD4mfqxxzf6fxzCz5Ju58yrfUJIEMpZZsunQ94ecdeL6E0v3PHVxTDez8xccNTfmESWkKinGOb0DHOvt9UZdy/DN65xrxHTck7ZNLpXeFWsdFnrJmRS5angP1RK78B3lZK7QTGA0+5zqQuQvYeeHoQ7Frc8XOsWACpXxnhmPc331/U7CpM/QX8+GWzZvG/K5p/Yafb4sdd6P6KHwsVhaZRhtDtsUvItdbbrW6TsVrrH2mtT7naMJ8n83tAG7eIrV+kIxzbAtvfgjN/ZYRD8C7GXQfXvWkSc16fB8Un6velrTdlgDvSwMJeGi54Ct0eyex0Fdm7TcnU4uPwzf9z7NjaWljxEPTobSoSCt7JiHlww4emHvxrF5nZcW2tiVhJmuXaxKbeI00zZ1nwFBAhdx3Zu02z3XHXmyy8vEP2H7vrQ1OD5ILHHWvWK7ifQefALZ+ZJK3XLoY9H5vGGa70j4Mp4hUzTBY8BUCE3DVobarUxY82YuwXCCsfse/YihJY9Rj0nei64lGCc0mYBD9dbt73xT8z2xLPdv11+4wV14oAuEjISytrXHFa36HomJmhxY2C8HjjHjmwwixctse3zxh3zNy/uCZ0TXANcSPhZysgaqDpg+qO5Kb4seazUiJ5G90dlyhFVU2tK07rO9iaGcdZs+6m32mq+n2xAKorWz8uPw2++xeMvQ76T3W9nYJz6TUI7toEP/3cPderW/Dc4Z7rCV6LTPlcQba1xGhva1affxBcvAjyDpqWaK3x5f+ZmiMXPO5qCwVXERhqClu5g/gx5lH85N0elwh5t09RyN5t0rmDI+u3DZtjGgqvexqKs5sfc3gt7PvcJJxE9HWbqYIPE9LTfM4kcqXb4xIhLy7v5uU1s3fXu1UacvGfTRnUpk2Ha6pN8k/UQNPAWBDsJV4WPAUXCXlBaTcW8qpy0xA5blTzfdGDTYLP9rchM7l+e/JrpiXYRU9CQLD7bBV8n/ixJrS1I0lnQpfBZT7yI3ndtMpt7n7QNS0LOcCsByEsHpb/1iSPlObD10+adO4Rl7rXVsH36TMW0PXrMkK3xGVCPvtva6nujtErTSNWmhIUDhf+EbK2wo53jIhXFJvFUG9tcSZ4L/HWyBVZ8OzWuETIgwP80BqWbM10xem9mxMp4B/cdp2NsddCwlQTpZL8Gky5zcQhC4KjRPQ1NeolBLFb4xIhH9o7jGFxYbz7vQMdx7sK2Skm7LCtPo1KwSVPQ1mBiWyZ/bD77BO6FkpZFzwlcqU74zLXyk+mDmB7RgFr9rUQatdVsaXmt+Yfb0jfCfCjF+HaN90Xdyx0TeLHwMm90oy5G+MyIb9h+kD6RAZ3r1l5yUkozWvdP96U8debLjKC0Bn6jIOaSsjZ52lLBA/hMiEP8LNw0ah41h3IoaC0jbT0roQtcsBeIRcEZ+CKBc/9K+Dfs1pvZyd4FXYJuVIqXSm1Sym1XSmV3P4RhsvG9aWyupYNB/M6bqEvURexYodrRRCcRfRgCAh1bmLQ5pfg+A7xvfsIjszIz9Vaj9daT7b3gHEJkYQF+fPdodwOmOaDZO+G8L7i8xbci8XP3AU6a0ZectJ0OQLTqUrwelxaNMvfz8KMwdF8kXKCiupuUNo2e7fMxgXPYGvGXOuE3I09S0HXgn+IyXcQvB57hVwDXyqltiilbm9pgFLqdqVUslIqOSenvj7yVZMSyDtdyY6MQieY68XUVJnFJhFywRPEj4HKYihI7/y5di02NdUHnyczch/BXiGfqbWeCMwFfqWUatbHSmv9srVB8+TY2Ni67dOTogH4eNsxJ5jrxeSmQm2VLHQKnsFZC54FGZCxCUZfCf0mmtLLZQWdt09wKXYJudY6y/p4EvgYsLvrQWRoABHB/qTndvHaK7LQKXiSumbMnRTy3R+bx9FXQr9J5nnWts6dU3A57Qq5UqqHUirc9hyYAzhUoWfe2L7sOV6E1l24Unl2ClgCIGaopy0RuiMBwRA7ovMz8pQlpl9sr0EmaQ3EveID2DMjjwO+VUrtAL4Hlmmtv3DkIiP7RlBYVsWxgrKO2OgbZO82/0h+AZ62ROiudLYZc94hOL4dRl9lXodEQfQQOCYLnt5Ou0KutT6stR5n/RmltX7S0YuM6hsBwPdp+R0w0UeQiBXB08SPhZLsljtQ2UPKR+Zx1I/rt/WbJDNyH8AtPTtHxIcDsPd4kTsu535K86E4S4Rc8Cy2Hp4dTeJJWQIDZkBkv/ptfSdCyQkoyuq8fYLLcIuQhwb6M6BXKBn5XdS1IgudgjdQJ+QdKGmbvcd0qRpzVePttgVPmZV7NW4RcoDh8eGkddXIFamxIngDIVGm72tHFjxTFpuolzOuaLw9fgxY/EXIvRy3CXlSTA/S8k5TW9sFI1eyU6BHLITHedoSobvTkQVPrY1bZdA5EBbbeF9AsJmgiJB7NW4V8srqWrIKu6B7RRY6BW8hfhzkH4ZyB9ajsrbCqfT6aJWm9JsIWdudk/4vuAS3CXlidA8A0nNL3XVJ91BbY4r6i1tF8Ab6WDM8bes29pDykcmBaK35d79JUFFksjwFr8RtQj4wOhSAI/k+4CfXGt6ZD1teb39s/mGoLpcZueAd1C142uleqa01Qj70QuNjbwlZ8PR63Cbk8RHBBPpbOJrvAzPyoiw4sAJWLID8tLbH1i10ipALXkB4HwiNsX/BM2OTCZ1tza0CEDMMAnpIJUQvxm1CbrEo+vcM4YgvuFZsH9iaClh2v5mht0b2brPaHzPcPbYJQlsoZV3wtDMEMWWJKVc77OLWx1j8TLq+zMi9FrcJORg/eXqeD7hWjm01IVcXLIRDa2DXh62Pzd5t6qsEBLvPPkFoi/ixcHIfVLfTYrGmGnZ/AsMvhqCwtsf2m2gSjaornGen4DTcKuQDokM5ml/q/cWzsraaanJn/gr6TYYvHjbZmy2RnSJuFcG76DPWlFRO/6btcWnroDS3bbeKjX6TTIPnbIfq5Qluwu0z8tLKGnJKvPhbXWtTtrPfRHNLedk/oLwAvvxD87HlhVBwVIRc8C4GzoTgKHjrSnj7WjjyXcvuwZSPICgChlzY/jn7TTSPUkDLK3HvjLyXiVzx6lT9/MNGoG0lPONHw4zfwPa34PC6xmNP7jWPEnooeBPh8XD3Npj9eziWDP+dC6/OgX3L6mPBqytg72cm5NAet2Bkf5P0JkLulbhVyOMizAfmZFG5Oy/rGLYPat+J9dvOeQh6JsHn90JVgy8hiVgRvJXQXjD7Ibg3Beb+1RS+eu8n8MJ02PYW7F8BFYX2uVXALKJKJUSvxc1CHgRAtjcLedY28A+G3mfUbwsIgUufNbP19X+r3569G4IjIaJf8/MIgjcQGArTboffbIMrXwG/QFj6K/jwpxDSy6Tl20vfiZB7wLGsUcEtuFXIe4YGEuCnOFHkxT7yrK1m1b9pg4jB58LY+bDh76ZSHFhT80eb2YogeDN+/jD2GrjjG7hxCQy5AM6+37FGKP0mAdo0nxC8CruFXCnlp5TappT6vMMXsyh6hwd7r2ulphqO76hf2GnKRU+axaHP7jGp+dl7xD8u+BZKGRG/cbFZ+3GEugVPca94G47MyO8B9nb2gnERQWQXe6mQ5+6HqtLG/vGG9IiBi56CzO9h1eNQWSz+caH7ENrLrBWJkHsddgm5UioBmAe80tkLxkUEc6LQS4XcttDZ2owcYNx8SDoHvnvOvJYZudCd6DcRjm3ztBVCE+ydkf8d+B3Qah1LpdTtSqlkpVRyTk5OqyeKiwjmpLf6yLO2GtdJr8Gtj1HKLHz6BwMKeo9wm3mC4HH6TYKiTCiwpZl2AAAgAElEQVQ+4WlLhAa0K+RKqUuBk1rrNu+ntNYva60na60nx8bGtjqud0QQxRXVnK6odtxaV3NsK/QdD5Z2/izRg2Hu0zDhBgjs4R7bBMEbqKuEKPHk3oQ9M/KZwOVKqXTgPeA8pdRbHb1gvC2WvNjLZuXVFSYKpTX/eFMm3QJXPO9amwTB24gfa4rEiZ/cq2hXyLXWD2utE7TWicB8YI3W+saOXtCWFOR1fvITKaY+hS2jUxCE5gSGmjpEUtLWq3BrHDnUJwWd9LbIlSw7FjoFQbAueG5pu7yz4FYcEnKt9VqtdSv9oOyjt7fOyLO2mYL8kf09bYkgeDf9Jpl6RPmHPW2JYMXtM/LwIH+CAyzkeJuP/NhWM9OQLE1BaBtJDPI63C7kSpnsTq8qZVtRYpKB7F3oFITuTOwZpquQRK54DW4XcoDY8CDviiU/vgN0rfjHBcEe/PxNmK7MyL0Gjwi516XpZ7VQulYQhNbpOxFO7ISaKk9bIuAhIY+PCOFEYbn3tHw7ttUscoa1nsgkCEID+k2E6nI4ucfTlgh4SMj7RAZTWllDUbmXZHdmbZX4cUFwBFuGZ2ayZ+0QAE8JeZQJQTxe6AUt30rz4VS6+McFwRF6JkJotPjJvQSPzcgBjntDLHmdf1xm5IJgN0pBwlTI+N7Tlgh4ykceGQJ4SVKQrSRnn/GetUMQfI2EyZCXau5qBY/iESHvHR6ERcHxAi9wrWRtheghEBLlaUsEwbdImGIeJZ7c43hEyAP8LMSGB3mJa2WbhB0KQkfoNxGUBTJ/8LQl3R6PCDlAn8gQzwt50XEoPi4LnYLQEYLCTSXETPGTexp/t19x/xdg8adPZE8OZBe7/fKNkEQgQegcCZMh5WOorW2/IYvgMtz/l1/7Z/j2WeIjgznuqqSg2hr7Smwe22qK5MePcb4NgtAdSJgCFYVm0VPwGO4X8gHT4dgWEsL9nZsUVF0BB1bCJ3fB04Pg+amQn9b2MVlbza1hYKhzbBCE7kbCVPMoYYgexZ6encFKqe+VUjuUUruVUgs7dcUB06G6jGHa1DLuVAhiVRns/RyW/AL+OgTeuda8HnohnM6B1y4ynX9aQmuz0NlP4scFocNED4HgSFnw9DD2+MgrgPO01iVKqQDgW6XUCq31pg5dsf90ABJLU4CRpOedZnh8uGPnOLQGtr5pZuBVpyGkJ4y8HEb+CJLOAf9AOLkP3vwxvH4JXP8+DDyz8TlOpUHZKUkEEoTOYLFAv8mSqu9h7OnZqbXWJdaXAdafjju2I/pA1EDiC7cDcCTvtGPHF2TAW1dB2noYew3c9DE8mGoaIQ+90Ig4QO8RcNtK6BFrBP3AysbnOSYLnYLgFBKmmOJZFR4OXujG2OUjV0r5KaW2AyeBr7TWmzt11QHTCTi2mchgfzLyHUwKSltnaoff8ilc9g8YfB74BbQ8NmoA/GwlxA6Hd6+HHe/X78vaBn5BEDeq47+HIAjQfwqgpe6KB7FLyLXWNVrr8UACMFUpNbrpGKXU7UqpZKVUck5OTtsnHDAdTucwMfyU44WzDq8zs+zeI+0b3yMGbvkMEmfCx7fDphfN9mNbTbRKa18CgiDYR10lRPGTewpHmy8XAGuBi1vY97LWerLWenJsbDt1va1+8rMCD3KswIHFTq3NjDxplmO9NYMj4CcfwhmXwRcLYPUfTVcgSQQShM4T0hNihomf3IPYE7USq5SKsj4PAS4A9nXqqrEjIDiS8ewjPfc0NbV2utxz9kNJtlnQdJSAYLjmDZh4M3zz/8wiqfjHBcE5JEw1M3JvaRbTzbBnRt4H+FoptRP4AeMj/7xzV7VA/2kMqdhNWVUNx07Z6V5JW2ceB3VAyAEsfnDZc3DW/RAUYdwtgiB0noTJUJoH+Yc9bUm3pN3wQ631TsD5MXr9pxGZ+iVRFHMot4QB0XYk5RxeB1EDTVH7jqIUXPAYnPuIaSIrCELnsVVCzEyG6MGetaUb4rniCANMXPckywHScuwIQayphvRvOz4bb4qIuCA4j95nQGCYLHh6CM8Jeb+JaEsAMwNTOZxb0v744ztMTYeO+McFQXAtFj8TPCCVED2C54Q8IATVdzzT/Q9y2J4Zedpa8yhCLgjeScIUUxKjstTTlnQ7PFt3sv80htWkciTbjlZRaeuh9ygIaye0URAEz5AwBXQNHN/uaUu6HZ4V8gFn4q+riD+9j+LyqtbHVZXD0U3O848LguB86hY8xU/ubjw+IweYbDnAkbw2bscyv4fqcnGrCII30yMGeiZJSVsP4FkhD4ulMjKJyZb9pJ5so+DO4XWmAcTAGe6zTRAEx0mYIolBHsDjvZn8E2cw2ZLKnmOFrQ9KW2fqOQRHuM8wD6G1JnHBMhIXLOOXb7ac8qy1pqgtV5QgeIr+U032dWGmpy3pVnhcyC0Dp9NTFXMqY3fLA8qLTIGrpFnuNczFpBwrJHHBMv697hBr958EoLqmlg0H8+rGrNydXSfm/1qTyrBHVpBVUEbSw8sZ+/iXJC5Yxll/WeOadnmC0BESJptH8ZO7FY8LuS0xKOLklpYF6cgGsxLexRY6L/3ntwD8ecU+fvrfH8guKuecv67lxlcbVwheuTubHz2/gb99eYDKmlpmLFrTaH/mqTJeWHsIgC1H8jlZVF+ETGvNAx/sYPXebBf/NoJgJW40+AeLkLsZzwt59BDKA3pyRtUeslpq+3Z4nflg2HoD+gi1tcZF8sLag5wsKufGVzaTVVDGf9YfJnHBsmbjpz21mmMF9TVn0hfN48bpAwDYnlHQbPxz19dXTfjryv18k5rDVS9uZOpTq3n4o10kLlhG0sPLWbI1k9veaN1FU1LhpJ6pggCmLHTfCSLkbsbzQq4UJXGTmGzZz84WBIu0daZ+eUCw+23rBOsOmJrsT3+xn6lPrebbg7nMWLSGJ5fvrRvz9s+ntXjs67eaMK6HLh7RaPviO8zdy8DoUC4f15f0RfPq9t30an2kwLvfH212TpsrJ3HBMgpKKykorSTp4eWMfmxli18sgtBhEqaYTOzqirbHaW3aLQqdxisKjkQOO4uYzFUsTz8MY/rU7yg5aVpIjbnGc8a1g00E+0YGc8fswVwzqT/PfLWf/3yT1uZxi+84k8mJvdjx2Bze+/4oH209xhf3no1qUGc9PLi+6cXqB85hcGwYaX++pNGYQ09dwuDfL697/acrRvGHpc3XG2yuHIDxf/yq2f6TReX0jvCtL0vBS0mYAt89Byd21fvMm1JdCZ/dAzvfh1uXm8ma0GG8QsgDEk1YYe3RzUCD0rJp682jl/nHtdb8+IXviAypF9qswnIeXbqbR5uI6MLLR7E7q5DK6lo+2Z4F0EiMI0MC+OU5g/nlOS1XjEv78yXklFTQO9yIrGrSUMPPonjnF9P4yX8289Zt0zhraAwzh8SQGN0Di0WxK7OQy/71bUunBiC6RyB5pyt574cM7j5/qON/DEFoii0xKOP7loW8NB/evwmOfGsKba38Pdy2ypS3FjqEVwg5fcdTpQKIPbWt8fa0dRAcCX3Ge8auFnDEDbH59+cTZ53lllfV8Mn2LF65eXIzMW4LpVSdiLfGjMExjdwsg2LD6p6PSYjkljMH8sbGIzx+2Uh+OjOJA9nFBPlb6BsVgr9FkfTwcp756gC/OW+IQ7YJQotE9IHI/i37yfMPw9vXQMFRuPI/UFMFS++C3R/BmKvdb2sXwTuE3D+InIhRDD+1h/zTlfTqEWi2H14HiWebympeQGsivuvxOYQHB6C15rUN6Uwe2JNx/aMajQkO8Gsktu5k4RWjWXhFfZvVYXHhjfaP7x/F9owCkh42LppfnTuYpduz8LMoxveP4u7zh5IY3QM/i4i8YCcJk5u3fju6yTRBB7h5qUnwq62FzS/CqoUw4lKfWwvzFuxp9dZfKfW1UmqvUmq3Uuoel1jS/0xGqzS2HTLuB06lQ8ERj6Xl/29jOgWllXWvn//6YN3zUX0j+Pahc0n78yUceuqSOl+2UorbzkpqJuLezgs3NG559/zXh8g8VcaRvFKWbs/i/P+3jsG/X87QR5Y3ChHVWvPwRzt5dGkKO1paqBa6LwlToPAoFJ8wr3cthjcuM/09f76qPkvbYoE5T5qxm1/0nL0+jj1OqWrgAa31GcB04FdKKTtb2NtPzMhZBKgaju/ZYDYc7mRbt05wy2vf8+jS3Yz/41dorfnvhjT+unI/YCJKlt19Ngk9Q1FKdYlZat+okLrnvzxnUKvjqmo0SQ8v561NRwDYllHAu99n8L+NR7ji+Q3U2tt7Vej6NPSTr3saltxmtv18VfMOQoPOgWFzYf3/g5Ic99vaBVCOZgUqpZYC/9JaNw99sDJ58mSdnOxgR+3SfHg6iaerruW3T7yMWnIbpG+AB/aZ9mxuoKSimtGPrWxzjKfcI66mrLKG7KJyEmN6UFpZTWig8bplF5Wz6XAe97zXfmnS12+dwuzhvSmvqsHfoli97yS/fHNLXYSO0I2oroA/J5g1rtM5MPY6uPyf4B/U8vicA/DCdJj0U7j0Gbea6i0opbZorVsJ82nnWEeEXCmVCKwHRmuti1ob1yEhB7L/PI49pZGkX/Q6t26cA4PPgytfdvg8HeWiZ9ezP9sU7wrwU1TVNP7bdFURt5fW1ghe++lkfvZ62+/3wSfn4u8nUQndilcuMAues38P5/yu/QnZsgch+TW4ayPEDnePjV5EZ4Tc7v8spVQYsAS4tyURV0rdrpRKVkol5+R07PYo+oxZTLKk8sGyL8y3uJv841prDueU1Ik4wOr7Z9c9f+cX0zj81CVuscWbSV80j/RF87hifN+6bavun8V5I+IY0Kvt5tlDHlnBm5uOsHT7MRIXLKOw1BT9+u5gLr//2GSiDntkhUvtF9zMpc+aRc3ZD9l3Vz17AQT2gC//4Hrbuhh2zciVUgHA58BKrXW79z0dnZGz/V345A7eq57NfP+1cN9uiExw/DwO8v4PR3loyS4AHpwzjF+fJ/HUjnLTq5v5JjWXkAA/9vzxIgrLqjhVWkVEsD+TnljV4jGPXHJGo0xXgB2PziEyNKDF8UI3YMM/4KtHzRfAoNmetsatuNS1okxg8RtAvtb6XntO2mEhzz8Mz02gSvtRGzmAoPvd0zLqocU7eT85A4CUhRcRFuQdUZm+RHVNLbuzilqM2DldUc2972/nqz2tF++KjwjmRFE5F42K40RRBTdNH8jVk1z/JS54GVXl8PwUCIqEX67zmtBjd+Bq18pM4CbgPKXUduuPa/wMPZOoDu1toleiXVMk6/J/fUvigmWMW/glVTW1VNfU1ol4+qJ5IuIdxN/P0mrYZY8gf166cRKLrhzDzsfnsPePFzfan75oHt8+dC5gqj3uyCjgwQ93kLhgGSUV1SzdfqzOFdMaJwrLGfnoF6Rmt9GgRPB+AoLhgschexdsf8fT1vgM7aqW1vpbwD1hI0qh+k+D/Z+xK3ACiU4+/cvrD7Ez0zSwKCyr4q1NR5hijaaICBYBdyV+FsX8qQPqXjddOG5tIbRpFNF5I3qzZp+p3/7lfbPqkpteWneI0soa3tiYzhM/GtPsPNU1tbLY6iuMuhI2vQhrnoBRP4agsPaP6eZ43Sfbb9gFlBHMqjLn+6mfWr6v0euFn+2pKyb19s+laI+nSV80j5X3zuLgk3NZ+quZLY6xiTjAnGfX8+xXB0g5Vsjr36UDcLygeSnki/++niGPrOCN79Ipr6pxie2CE1HKJAmVnIDv/ulpa3wCrxNyJtzMwiEf8EO2c28CVuw6DkBMWCDpi+Y1S3wZkxDp1OsJHWN4fHidmyZ90Tzeum0a/711CoefuoRXbm7uPvzH6tRGlR23ZxQ0yj6trqll3wnjbnns092M+MMXrv8lhM4zYJqZjX/3HBQd97Q1Xo/3CbnFQmL/BLIKyzl1urL98U3QWjPxT19x97v1Bbhe+eYwd769FYCP7zIzvYfnnlG3/7/W+t+C93HW0BjOHd4bi0Vxwcg4lt19Fut+O5tDT13S7Mv4L1eNIe90JbuzTHTsh8kZ/HbxzmbnlFm5j3DB41BbDV8/4WlLvB6vdAyP6muaLO85XsTMITEOHfvtwVzyT1fy6Y4s/njFKDYdzueJZSbELTzIn/4N4p1Tn5xLanYJI/t2/abOXYVRfevvnB6cM5xvU3NRChbfMYOiMrMg2nCGbuPQU5fwzvdH+cMnKTy0ZCf/mF/fYamyupZh/7eC/r1C+MO8kcwZFe/6X0Ron56JMPV22PQCnPlr6H1Gu4d0V7xvRg6M7GMV8qxWk0ebobWmuqa2Uaec8X/8ijve2gLA7OGxbHv0wkbHBPhZRMR9mAA/C8vuPpvPf3M2wQF+rTbGeOcX0/CzKK6f0h+Apda68DZetPY8zcgv4/Y3t1BdU+tawwX7OfsBCAyHVY972hKvxiuFPDosiPiIYHZnFTbbt/XoKRIXLOOut7fUbdPaFHMaYs0MbBqBEuhv4fVbp0rUQjdg98KLmDywJwAr753FzsfnMGOwuavz97PU3e0lLljG0bxSlmzJ5NlVBxqd41DOafcaLbROaC8461448IWpvSS0iNcq25iESL49mNdo4WrDwVyufOE7AJbvOkF67mmuf3lTXR1tGyvvm8WaB85hamIvNj18PgeemOtW2wXP0SPIn8V3ziB90TyGx4cTEdw4S/QvV42tez7rr1/zwIc7ALhz9mA+tPZEff+HjBbPnXmqlB+/sIEtR/JdZL3QItPvhPC+JuPTwSJ/3QWvFfKZg6PJLalg69H65qw3vLK50ZhPd2Sx8XBe3esz+kTwwyMX0CcyhEGxYXxwx5nER0qheqGe0f0iWX732Y22zR0dzwMXDqubyb+2IY2HP9pVt7+8qoblu45z1l++ZtvRAq56cSNV4n5xHwEhcO7v4Vgy7FnqaWu8EofL2NpDh1P0G3CisJzpf17N3ecP5f4Lh3Egu5g5z5oenml/voSxC7+kuLwagBumDeB3F42QGh2C3dTUak6VVnIkr5RJVgEH+NPne3j127YbZwM8e904/r3uMPtOFLPq/nMY0luSVlxKbQ28OBNqKuFXm8Gv6/2vu6X6obuJjwxmdL8InludSnlVDde/vAmArx+cjVKKf980qW7sEz8aLSIuOISfRRETFtRIxAEemDOsbrG9KX+4dGRdeYH73t9RF59+wTPrSFywrO4nI7/UtcZ3Ryx+Jhwx/xBsed3DxngfXjsjB/jghwx+t6RxHHDD1O5/rUllUGwYl4zp0+lrCUJD3t58hA9+yODeC4Zx9tCYRgvlf191gL+vSm3z+B2PzSEyRCYXTkVreH0e5B6Au7dBUHj7x/gQbmssYS/OEnJbNIqNt38+zeG4ckFwBbklFUT3CKSgtIoJfzLNsgL9LFRafec3nzmQPzZoeG3jl28mM3t4b65vUHdGcIDMZHjlfDhnAZz7sKetcSpdVsjB+DL3nyhmUGwPggO6T0lLwXexdVKy1VYvLq8it6SSvceLuMuaYfzVfbMYGte1ZpRu44ObIXWVmZWHx3naGqfRJX3kNvwsipF9I0TEBZ9h7miTGfrYpyl8k5rDmMe/5Ny/ra0TcYALn11PaWW1p0z0bc5/DGoqYN1fPG2J1+D1Qi4IvsaLN04iJiyIT7ZnNco0BhjTr77EwAMf7KC4vHGd9dLKahIXLOPNTUfcYqtPEj3YNGne8jrkHvS0NV6B17tWBMEXSTlWWFfz5Z2fT+PMwdGUVdUQEuCH1jDo92btJzIkgPW/O5dxC79sdo4Xb5jI3CYL+TW1moz8UvpGhRDo343nYSUn4bkJpkH7dW962hqn4OpWb68BlwIntdbNV29aQIRcEKCqppbTFdVEhQY229dSRFZrvHf7dKYPiia7qJxpT60GjMvxUHdvCL52Eaz9M9y2Cvr7fgVTV/vIXwcubm+QIAiNCfCztCjiANdO6c+q+2c12rb90QvrSvQ+OGdY3fb5L2/imS/314k4mJl5e+3vujxn/hp6xMIXC6Cye8fu2+VaUUolAp/LjFwQnEtFdQ3llbUtJrQlp+fz5PK9bDta0Gj7kjvP5KoXN/LMteO4cmI3b1Cd8hEs/hkMOBN+8j4E+2410y4dtSIIXZkgf79Ws5InJ/bi47tmctP0gQDcf+Ew0hfNY0L/nvSLCuHjbcfcaap3MvpKuPpVyPwe/nc5lHbPgmZOE3Kl1O1KqWSlVHJOTo6zTisI3Z4//Wg06Yvmcff5po+txaK4dGwfNh3Oo8ga9ZKRX8rK3Se4+91t3a8D0uir4Lq3IHsP/PcSKD7haYvcjrhWBMEHSU7P5+qXNnLrzEQOZBez4WBeszH7n7iYIP9ulH9xeC28+xOTJHTzUojyrexZca0IQjdjwgBT7Ou/G9JbFHGA578+RFll/ez8i5TjJC5Y1nXrqQ+aDTd/Aqfz4LW53SrG3J7ww3eB2UAMkA08prV+ta1jZEYuCK5ny5FTXPWiabSy8eHz6BMZAkBtra6LU2+Nt26bxllDu2jdouM74c0fg7LATR9DvF2OBI/TpWutCILgOM+tTuWZrw60OeZv14zj6kldNOol5wD87wqoKoUbP4KESe0f42FEyAVBaJHK6lp+9c5WThaV88mvZqKUYvGWTB78cAfBARZ2PDaH4vJqKqtrCQ/25w+fpHDx6D7MGRlHrda+3ef2VDq8cTmU5sHEW2DMVdB3IijlactaRIRcEASH+CLlOHe8tbXdcdv+cCE9e7Sc1OQTFGXB8t9C6pemu1CvQTDmGhh9NcQOa/94NyKLnYIgOMTFo+1rxtKwd6lPEtEX5r8NDx6Ay/8Jkf1h3dPw/BR46WzY8A8ozPS0lZ1GZuSC0E05WVTOv9cf5jfnDSE00J/sonLiIoLrinH9bvEOPkjOZOW9sxge34VqpxefgN0fw64P4dgWsy3xbJhwE4y83DR79gDiWhEEwenYGqAD/OLsJKYPiiYyJIDHP9tNyrEiAG47K4n/m3cGykv9zu2SdwhSlsD2d+BUGgRFwpirYcKN0HeCW/3pIuSCILiEdQdyuOW179sckxTTgzUPnOO7Yg5QWwtHNsC2N2HPUqguh7jRZpY+9loI7eVyE0TIBUFwGRn5pZz99NcE+llAwTPXjuPCkXH4Wyzc/NpmNhzMIzjAwuaHLyAyNIDyqhp2ZhZy7b83svqBcxgcG+bpX8Exygth12Ij6lnbwC8QBp9vFkd7JpkF015JENEPLM7LnBUhFwTBI9TUaq568Tu2Z5gKjWFB/pRU1LewiwoNYPEdMxgc28M3Z+wnUmDbW3BwFRQcMZEvNvwCIWqgEfWeiRDYAywBZrufv/V5AFj86x9RVndNk0elUGOuFiEXBMFz/OQ/m/juUONSAXNHx7MixRSwGhEfzhl9IvjxhH4E+FkI8FNMTnS9u8Kp1NaYcMb8w8afnn8Y8tPM81NHTfJRbcdrxKuFRSLkgiB4nq1HTzGgVygxYUEAfJOaw22vJ1NZU9vqMT88cgGx4UHuMtG1aA211VBTZUS9ptr6WGm+CNBmjG1s3WuN6j1ChFwQBO/l29Rc/vrlfnZkFNA7PIiTxRV1++aN6cPzN0z0oHXeQWd85P7ONkYQBKEpZw2NabFI1/NfH+SvK/ez/5l1jOkXSUigH7+cNYiwIH80sGpPNheOjCM6rIvM2F2EzMgFQfAYVTW1DH1kRbvjfjojkTtnDyYuIpjK6lrKq2sI9LMQ5G/xzUXUFpCoFUEQfJrVe7P5ak82CT1DKKmoYc2+bHqGBnK8sJyj+W03Vr7lzIE8etko/CwtC7rW2ifEXoRcEIQuy6nTlSzZmslnO4+zwxrmmBTTg7Tc043GxYQF8qcrRjNjcAwni8vZnJbPmn0nWbPvJAD/vH4CF42KrytB4G2IkAuC0C3RWvPqt2k8sWyv3cfERwRzzeQEhsaFExMWSGxYEIkxPQjwcMlelwu5Uupi4B+AH/CK1npRW+NFyAVBcDdVNbVsOXKKrUdPUWKtsf7LcwYTE2ZcNC+vP0x63mnWHcihqexZFEwfFE1CzxB6hwcTGuRHr9BAYsODCAvyJzY8iOgw87wlF051TW2na7e7NGpFKeUHPA9cCGQCPyilPtVa7+nIBQVBEFxBgJ+F6YOimT4outm+vlEhPH75qLrXZZU1pJ4sJqugjOyiClKOFbIto4CdmYWcrqxuJvQ2woL8iQj2JyzYn0B/C0dySym2ZrL2iwphQK9QevUIRCkICfAjKjSAiOAAqmo1sWGBBPn70SPIn+raWk5X1FBdW0t5VQ35pzueSAT2hR9OBQ5qrQ8DKKXeA64ARMgFQfBJQgL9GJsQxdiEqGb7CsuqKCytory6htMV1ZRUVJN5qozi8irSck9z6nQVGs3pihpGjI4gLMgfpSC7qJzMU2UcLyyjulZTXF5NeVUNFdWtJ0PZCPDr3GKsPULeD8ho8DoTmNapqwqCIHgpkSEBRIYEOOVcWmsqa2rRGtNSr6aWorIqAvwUoYH+BPhZCPS3EBbkj/9THb+OPULe0ldFsxsPpdTtwO3WlxVKqZSOm+UWYoBcTxvRDmKj8/AFO8VG5+CrNg7s6MnsEfJMoH+D1wlAVtNBWuuXgZcBlFLJHXXauwux0Tn4go3gG3aKjc6hO9pozzLrD8BQpVSSUioQmA986iwDBEEQhM7R7oxca12tlPo1sBITfvia1nq3yy0TBEEQ7MKuolla6+XAcgfO+3LHzHErYqNz8AUbwTfsFBudQ7ez0SWZnYIgCIL78M6iA4IgCILdOFXIlVIXK6X2K6UOKqUWOPPcdlz7NaXUyYZhj0qpXkqpr5RSqdbHntbtSin1nNXOnUqpiQ2OucU6PlUpdYuTbeyvlPpaKbVXKbVbKXWPl9oZrJT6Xim1w2rnQuv2JKXUZus137cufqOUCrK+Pmjdn9jgXA9bt+9XSl3kZDv9lFLblFKfe6N91vOnK1vRWE8AAASJSURBVKV2KaW2K6WSrdu87f2OUkotVkrts342z/QmG5VSw61/P9tPkVLqXm+yscH577P+z6Qopd61/i+5/nOptXbKD2Yh9BAwCAgEdgAjnXV+O64/C5gIpDTY9jSwwPp8AfAX6/NLgBWYGPnpwGbr9l7AYetjT+vznk60sQ8w0fo8HDgAjPRCOxUQZn0eAGy2Xv8DYL51+0vAndbndwEvWZ/PB963Ph9p/RwEAUnWz4efE+28H3gH+Nz62qvss14jHYhpss3b3u83gJ9bnwcCUd5mYwNb/YATmJhrr7IRkzyZBoQ0+Dz+1B2fS2f+gc8EVjZ4/TDwsLPfyHZsSKSxkO8H+lif9wH2W5//G7i+6TjgeuDfDbY3GucCe5diath4rZ1AKLAVk82bC/g3fb8xEU1nWp/7W8eppp+BhuOcYFcCsBo4D/jcej2vsa/BOdNpLuRe834DERjxUd5qYxO75gAbvNFG6rPge1k/Z58DF7njc+lM10pLqfz9nHj+jhCntT4OYH3sbd3emq1u+x2st1ETMLNdr7PT6rbYDpwEvsLMCgq01tUtXLPOHuv+QiDaxXb+HfgdYCtkEe1l9tnQwJdKqS3KZD+Dd73fg4Ac4L9WN9UrSqkeXmZjQ+YD71qfe5WNWutjwN+Ao8BxzOdsC274XDpTyO1K5fcSWrPVLb+DUioMWALcq7UuamtoK/a43E6tdY3Wejxm5jsVOKONa7rVTqXUpcBJrfWWhpvbuJYn3++ZWuuJwFzgV0qpWW2M9YSd/hiX5Ita6wnAaYybojU89re0+pYvBz5sb2grtrjURquP/gqMO6Qv0APzvrd2TafZ6UwhtyuV381kK6X6AFgfT1q3t2ary38HpVQARsTf1lp/5K122tBaFwBrMb7GKKWULfeg4TXr7LHujwTyXWjnTOBypVQ68B7GvfJ3L7KvDq11lvXxJPAx5kvRm97vTCBTa73Z+noxRti9yUYbc4GtWuts62tvs/ECIE1rnaO1rgI+Ambghs+lM4XcG1P5PwVsK9O3YHzStu03W1e3pwOF1luzlcAcpVRP67frHOs2p6CUUsCrwF6t9TNebGesUirK+jwE8wHdC3wNXN2KnTb7rwbWaOPc+xSYb12dTwKGAt931j6t9cNa6wStdSLmc7ZGa32Dt9hnQynVQykVbnuOeZ9S8KL3W2t9AshQSg23bjofU6Laa2xswPXUu1VstniTjUeB6UqpUOv/uu1v6frPpZMXIi7BRGIcAh5x9kJHO9d+F+OXqsJ8o92G8TetBlKtj72sYxWmWcYhYBcwucF5fgYctP7c6mQbz8LcIu0Etlt/LvFCO8cC26x2pgCPWrcPsn6gDmJub4Os24Otrw9a9w9qcK5HrPbvB+a64H2fTX3UilfZZ7Vnh/Vnt+1/wgvf7/FAsvX9/gQT0eFtNoYCeUBkg21eZaP1/AuBfdb/mzcxkScu/1xKZqcgCIKPI5mdgiAIPo4IuSAIgo8jQi4IguDjiJALgiD4OCLkgiAIPo4IuSAIgo8jQi4IguDjiJALgiD4OP8fFvKj2BdVPWIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "wd = 1e-1\n",
    "epochs = 40\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_squish_40epochs_delextraBN_lr1e-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45584378, tensor(0.8777)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_fp32().validate(img_data_test.train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, Squish Resize, 40 Epochs, lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms()\n",
    "sz = (300, 300)    #Squish Resize if a tuple is defined\n",
    "bs = 32\n",
    "img_data = ImageDataBunch.from_df(train_path, train_df,\n",
    "                                  ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0.2, bs=bs)\n",
    "img_data_test = ImageDataBunch.from_df(test_path, test_df,\n",
    "                                  ds_tfms=None, size=sz, fn_col=0, label_col=1, valid_pct=0., bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0199,  0.0376,  0.0024,  ..., -0.0224, -0.0216,  0.0478],\n",
      "        [-0.0051,  0.0227, -0.0222,  ...,  0.0029, -0.0075,  0.0368],\n",
      "        [ 0.0533,  0.0496, -0.0542,  ...,  0.0442,  0.0206, -0.0109],\n",
      "        ...,\n",
      "        [-0.0150,  0.0203, -0.0239,  ...,  0.0131,  0.0330, -0.0460],\n",
      "        [ 0.0706,  0.0174,  0.0312,  ..., -0.0285, -0.0359, -0.0253],\n",
      "        [ 0.0132, -0.0506,  0.0547,  ...,  0.0034,  0.0494, -0.0249]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n_class = 196\n",
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Daewoo Nubira Wagon 2002,Suzuki Aerio Sedan 2007,Cadillac Escalade EXT Crew Cab 2007,Chrysler Sebring Convertible 2010,Rolls-Royce Phantom Sedan 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6c8609b400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(img_data, eff_net, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.334305</td>\n",
       "      <td>5.216760</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.036322</td>\n",
       "      <td>4.857697</td>\n",
       "      <td>0.084152</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.126465</td>\n",
       "      <td>3.599284</td>\n",
       "      <td>0.280713</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.580923</td>\n",
       "      <td>1.956789</td>\n",
       "      <td>0.579853</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.309401</td>\n",
       "      <td>1.159186</td>\n",
       "      <td>0.705774</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.725808</td>\n",
       "      <td>0.993882</td>\n",
       "      <td>0.722973</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.549538</td>\n",
       "      <td>1.022389</td>\n",
       "      <td>0.725430</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.553513</td>\n",
       "      <td>1.106877</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.501554</td>\n",
       "      <td>1.408859</td>\n",
       "      <td>0.666462</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.518499</td>\n",
       "      <td>1.027107</td>\n",
       "      <td>0.733415</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.518735</td>\n",
       "      <td>1.472559</td>\n",
       "      <td>0.648034</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.400007</td>\n",
       "      <td>1.156806</td>\n",
       "      <td>0.712531</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.393844</td>\n",
       "      <td>1.121247</td>\n",
       "      <td>0.728501</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.361206</td>\n",
       "      <td>0.949794</td>\n",
       "      <td>0.754914</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.326045</td>\n",
       "      <td>0.909206</td>\n",
       "      <td>0.768427</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.296854</td>\n",
       "      <td>1.232149</td>\n",
       "      <td>0.716830</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.262943</td>\n",
       "      <td>1.139272</td>\n",
       "      <td>0.738944</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.236378</td>\n",
       "      <td>1.072468</td>\n",
       "      <td>0.752457</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.216267</td>\n",
       "      <td>1.136208</td>\n",
       "      <td>0.736486</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.169434</td>\n",
       "      <td>0.798931</td>\n",
       "      <td>0.803440</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.167945</td>\n",
       "      <td>0.911275</td>\n",
       "      <td>0.788698</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.149316</td>\n",
       "      <td>1.013474</td>\n",
       "      <td>0.769656</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.121019</td>\n",
       "      <td>0.862781</td>\n",
       "      <td>0.807125</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.101191</td>\n",
       "      <td>0.751512</td>\n",
       "      <td>0.826167</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.084284</td>\n",
       "      <td>0.789231</td>\n",
       "      <td>0.821867</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.082108</td>\n",
       "      <td>0.732027</td>\n",
       "      <td>0.833538</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.055996</td>\n",
       "      <td>0.643356</td>\n",
       "      <td>0.853808</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.044317</td>\n",
       "      <td>0.693114</td>\n",
       "      <td>0.855037</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.041419</td>\n",
       "      <td>0.683677</td>\n",
       "      <td>0.850123</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.034893</td>\n",
       "      <td>0.737947</td>\n",
       "      <td>0.855037</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.025408</td>\n",
       "      <td>0.623701</td>\n",
       "      <td>0.874079</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.018904</td>\n",
       "      <td>0.566078</td>\n",
       "      <td>0.888821</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.014688</td>\n",
       "      <td>0.598480</td>\n",
       "      <td>0.886978</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.555986</td>\n",
       "      <td>0.895577</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.536453</td>\n",
       "      <td>0.899877</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.550237</td>\n",
       "      <td>0.900491</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.538795</td>\n",
       "      <td>0.901720</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.006646</td>\n",
       "      <td>0.541064</td>\n",
       "      <td>0.901720</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>0.543774</td>\n",
       "      <td>0.904177</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.543393</td>\n",
       "      <td>0.903563</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-1\n",
    "epochs = 40\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_squish_40epochs_delextraBN_lr1e-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5068277, tensor(0.9059)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_fp32().validate(img_data_test.train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, Squish Resize, 40 Epochs, lr = 3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms()\n",
    "sz = (300, 300)    #Squish Resize if a tuple is defined\n",
    "bs = 32\n",
    "img_data = ImageDataBunch.from_df(train_path, train_df,\n",
    "                                  ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0.2, bs=bs)\n",
    "img_data_test = ImageDataBunch.from_df(test_path, test_df,\n",
    "                                  ds_tfms=None, size=sz, fn_col=0, label_col=1, valid_pct=0., bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0619,  0.0118,  0.0394,  ...,  0.0528, -0.0217,  0.0045],\n",
      "        [-0.0109, -0.0185,  0.0061,  ...,  0.0224,  0.0183,  0.0421],\n",
      "        [-0.0757,  0.0118, -0.0022,  ...,  0.0165,  0.0484, -0.0731],\n",
      "        ...,\n",
      "        [-0.0152, -0.0237, -0.0134,  ...,  0.0189, -0.0294,  0.0908],\n",
      "        [-0.0811,  0.0209, -0.0265,  ...,  0.0463, -0.0048,  0.0106],\n",
      "        [ 0.0372,  0.0302,  0.0257,  ..., -0.0519, -0.0107, -0.0106]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n_class = 196\n",
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "HUMMER H3T Crew Cab 2010,Volkswagen Beetle Hatchback 2012,Ford Expedition EL SUV 2009,Rolls-Royce Ghost Sedan 2012,Rolls-Royce Ghost Sedan 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7f6c8609b400>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(img_data, eff_net, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.389894</td>\n",
       "      <td>5.279595</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.311106</td>\n",
       "      <td>5.209822</td>\n",
       "      <td>0.015356</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.163714</td>\n",
       "      <td>5.068162</td>\n",
       "      <td>0.042383</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.807583</td>\n",
       "      <td>4.623600</td>\n",
       "      <td>0.130835</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.044182</td>\n",
       "      <td>3.624057</td>\n",
       "      <td>0.281941</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.868596</td>\n",
       "      <td>2.445607</td>\n",
       "      <td>0.507371</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.792531</td>\n",
       "      <td>1.578334</td>\n",
       "      <td>0.663391</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.028901</td>\n",
       "      <td>1.043203</td>\n",
       "      <td>0.751843</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.600283</td>\n",
       "      <td>0.852224</td>\n",
       "      <td>0.769656</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.334568</td>\n",
       "      <td>0.754088</td>\n",
       "      <td>0.787469</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.254646</td>\n",
       "      <td>0.737526</td>\n",
       "      <td>0.802826</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.192730</td>\n",
       "      <td>0.703923</td>\n",
       "      <td>0.820639</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.153392</td>\n",
       "      <td>0.805804</td>\n",
       "      <td>0.793612</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.141094</td>\n",
       "      <td>0.784370</td>\n",
       "      <td>0.804668</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.110233</td>\n",
       "      <td>0.804034</td>\n",
       "      <td>0.802211</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.097700</td>\n",
       "      <td>0.703230</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.114803</td>\n",
       "      <td>0.782073</td>\n",
       "      <td>0.801597</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.077849</td>\n",
       "      <td>0.767445</td>\n",
       "      <td>0.814496</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.070734</td>\n",
       "      <td>0.819808</td>\n",
       "      <td>0.811425</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.047811</td>\n",
       "      <td>0.719668</td>\n",
       "      <td>0.825553</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.052843</td>\n",
       "      <td>0.746983</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.037930</td>\n",
       "      <td>0.707228</td>\n",
       "      <td>0.840295</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.035062</td>\n",
       "      <td>0.686915</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.036607</td>\n",
       "      <td>0.686084</td>\n",
       "      <td>0.843980</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.716655</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.018475</td>\n",
       "      <td>0.686973</td>\n",
       "      <td>0.853808</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.022767</td>\n",
       "      <td>0.647964</td>\n",
       "      <td>0.855037</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.014828</td>\n",
       "      <td>0.609974</td>\n",
       "      <td>0.864251</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.014326</td>\n",
       "      <td>0.617926</td>\n",
       "      <td>0.865479</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.595728</td>\n",
       "      <td>0.880835</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.610535</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.006535</td>\n",
       "      <td>0.607243</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>0.585833</td>\n",
       "      <td>0.880221</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.587258</td>\n",
       "      <td>0.881450</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>0.584271</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.598433</td>\n",
       "      <td>0.877764</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.585932</td>\n",
       "      <td>0.879607</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.580401</td>\n",
       "      <td>0.881450</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.578998</td>\n",
       "      <td>0.878993</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>0.580120</td>\n",
       "      <td>0.878993</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8XHW9//HXd5Zksu972qYbtE2bbqGUtiAVZKuASoWyiVcBr+CCetVyvSr8vN6LXq/icgUqoAhlUUBRQCpbZbFbUtqQ7lvS7GuzNevMfH9/nJM0aZMmTWdyZvk8H495nFnOnHlPZvI53/me7zlHaa0RQggRvGxWBxBCCHF2pJALIUSQk0IuhBBBTgq5EEIEOSnkQggR5KSQCyFEkJNCLoQQQU4KuRBCBDkp5EIIEeQc/lioPTpBOxLSAZiVGY/TrvzxMkIIETKKi4sbtdZp43muXwq5IyGdrNseBKB10P1Pff58VsxM9cdLCiFEUFNKlY/3uX7rWrn3ylmn3HfLY1vIW/sKP9mwz18vK4QQYUf546BZWTPydc3BXQB4vZr99e00tPdw62NbB+a5Zelk7rs6H4fdhtYapaT7RQgRvpRSxVrrwnE91x+FfPHiQl1cXDTsY+VNx/nI/2w85f6Pzcng/25ahNOupKgLIcJOwBXywsJCXVQ0fCEH6PN4+d+/7+fhfxwa9vE1503ivz81Twq6EGGir6+PyspKuru7rY7idy6Xi9zcXJxO55D7g6uQl2+C+GxImjLQpdLd5+HzT2zj/YNNA7Mtn5HCU58/X4q5EGHgyJEjxMXFkZKSEtL/81prmpqaaG9vZ+rUqUMeO5tC7pdRKyPSGl66G5oPQfYiVP4nYM61uJLyWH/7UrTWvHewkV+9dZD3DzYx9d5XWX/7+SyfISNdhAhl3d3d5OXlhXQRB1BKkZKSQkNDg0+XO7E7BCkFtzwPl94H2guvfw9+Ph/WXQzvPYhqKefCmWk88bklA0+5+VFjpMvu6rYJjSqEmFihXsT7+eN9TvyencnTYMXX4Av/gK/sgEvvN+5/4/tGUX/kI7iKHqbsPz/Gw7csHnjaVb94l6c2j3uYpRBChCxrd9FPngor7oE7N8JXS+BjPwCbHTb8O/xmJVek1FP2wCr++qUVAPzHn0vJW/sKJZUtlsYWQoSWlpYWfv3rX5/x86666ipaWqyvR4FzrJWkKbD8K3DHW3Djs3C8AX6zEjb+iHlZ0bz7rZUDs17zq/epPNZpYVghRCgZqZB7PJ7TPu/VV18lMTHRX7HGLHAK+WDnXgl3bYb8T8LG/4JHL2FSXxllD6zix6sLAPj874pwe7wWBxVChIK1a9dy6NAhFixYwHnnncfKlSu56aabmDdvHgCf+MQnWLx4Mfn5+axbt27geXl5eTQ2NlJWVsbs2bO54447yM/P57LLLqOrq2vC8k/sqJUzEZ0M1z0Ks6+Gl78O6z4CF9/L9cu+QoTdxj3P7eDprUf5zAV5VicVQvjQ/X/d5fPBDXOy4/n+1fkjPv7AAw9QWlrKjh072LhxI6tWraK0tHRgiODjjz9OcnIyXV1dnHfeeVx33XWkpKQMWcaBAwd45pln+M1vfsP111/PCy+8wC233OLT9zGSwGyRDzbnWrh7C5xzBbx5Pzx+OdfmdrBsego/fX0/bd19VicUQoSYJUuWDBnn/Ytf/IL58+ezdOlSKioqOHDgwCnPmTp1KgsWLABg8eLFlJWVTVTcsbXIlVJlQDvgAdzjHbQ+bjGpcP3vofQFePXfUA9fyA8vf5xLDivuXr+dJz9//oTGEUL4z+lazhMlJiZm4PrGjRt544032LRpE9HR0Vx88cXD7oEaGRk5cN1ut09o18qZtMhXaq0XTHgR76cUzFsNd22B+Cym7vgJqxfl8O6BRl4orrQkkhAiNMTFxdHe3j7sY62trSQlJREdHc3evXvZvHnzBKcbXeB3rZwsLgOW3wPVH/Cf841d+v9YXGFxKCFEMEtJSWH58uXMnTuXb37zm0Meu+KKK3C73RQUFPDd736XpUuXWpRyZGM61opS6ghwDNDAI1rrdaebf7SDZp01dw88WABp5/B/k3/G/2zYxx0XTuU7q+b47zWFEH6zZ88eZs+ebXWMCTPc+z2bY62MtUW+XGu9CLgSuFspddHJMyil7lRKFSmlinx9HIFTOCLhgrvhyDt8Ls9olf/m3SMcaTzu39cVQogANKZCrrWuNqf1wJ+AJcPMs05rXai1LkxLG9dp585M4b+AK5GoLb/gwRuMLcUrf7KRrt7TD+AXQohQM2ohV0rFKKXi+q8DlwGl/g42qsg4WHIn7H2ZT+S0c9fF0wF4bttRi4MJIcTEGkuLPAN4Tym1E9gKvKK1fs2/scbo/H8FZzS8/yDfvPxc5ubE8/TWo/jjGOtCCBGoRi3kWuvDWuv55iVfa/3DiQg2JjEpsOg2+PCPqNYKbl06hf11HfxYTu4shAgjwTf88GTLvgQo+OcvuXZBDgAPbTwkrXIhRNgI/kKekAsFN8D23+PqaebH1xkH1fr1xuHPByqEEL4QGxsLQHV1NatXrx52nosvvhi/DsU2BX8hB+OY5u4e2PIQn1xktMo37Kq1OJQQIhxkZ2fz/PPPW5ohNAp56kzjKIlbH8XZ18EXPjKNPTVtdPS4rU4mhAgS3/72t4cck/y+++7j/vvv55JLLmHRokXMmzePl1566ZTnlZWVMXfuXAC6urpYs2YNBQUF3HDDDRN2vJXAPYztmbrw67DnL1D0GBfNvJVH/nGYbUeaWTkr3epkQogz8be1UPuhb5eZOQ+ufOC0s6xZs4Z77rmHu+66C4A//OEPvPbaa3zta18jPj6exsZGli5dyjXXXDPieTcfeughoqOjKSkpoaSkhEWLFvn2fYwgNFrkANkLYdpK2PRrFmRGohTslFPCCSHGaOHChdTX11NdXc3OnTtJSkoiKyuLf//3f6egoIBLL72Uqqoq6urqRlzGO++8M3AM8oKCAgoKCiYke+i0yMFolT9xNTF7nmNG2kw+rGy1OpEQ4kyN0nL2p9WrV/P8889TW1vLmjVrWL9+PQ0NDRQXF+N0OsnLyxv2ELaDjdRa96fQaZED5F0IOYXw/s+ZnxNDSVWrDEMUQozZmjVrePbZZ3n++edZvXo1ra2tpKen43Q6efvttykvLz/t8y+66CLWr18PQGlpKSUlJRMRO8QKuVJGq7zlKNdFbKGhvYfSKt+eMkoIEbry8/Npb28nJyeHrKwsbr75ZoqKiigsLGT9+vXMmjXrtM//4he/SEdHBwUFBfz4xz9myZJTDkvlF2M6jO2Z8vthbE/H64WHLqDPEcPMI9/gmvnZ/OLGhdZkEUKMiRzGdmIOYxs8bDY490qcdSVkRsNfdlZzXIYhCiFCWOgVcoCcxeDt4/tLvADsrxv+FE5CCBEKQrOQZxtjNxc7DgNwuEFOOCFEoAuXgQn+eJ+hWcjjsyE2k9TWUlJjI3hrX73ViYQQp+FyuWhqagr5Yq61pqmpCZfL5dPlhtY48n5KQc5ibNXbuXT2l3m5pIY+jxenPTTXW0IEu9zcXCorK/H7aSIDgMvlIjc316fLDM1CDpCzCPa9wqXLI3l2m5sPjrawZGqy1amEEMNwOp1MnTrV6hhBK3SbqDmLAVjqqgBgy+EmK9MIIYTfhG4hzzbGjsc27mBWZhzvH2q0OJAQQvhH6BbyqERImQFV27lkdjqbDzdT13b6YyQIIUQwCt1CDkb3SlUxV+RnAbD2hYk57oEQQkyk0C/kHbXMizfGkb9/SPrJhRChJ/QLOUBVMTcumUSv24vb47U2kxBC+FhoF/KMuWBzQlUx52bEAfDuQdnoKYQILaFdyJ0uyMiHqmI+sdA4KfPeGjnuihAitIR2IQeje6V6B4kuB5OTo9lZIad/E0KElvAo5D1t0HSQwrwkNh1uosftsTqVEEL4THgUcoCqYq4uyKa1q49/HpTRK0KI0BH6hTx1JkTEQVUxiyYnAfBySY3FoYQQwndCv5Db7JC9AKqKSYh2AvDC9kqLQwkhhO+EfiEH40iItR+Cu4eZ6bEAdPdJP7kQIjSESSE3Tv1GXSn3XmWcBXvrkWaLQwkhhG+MuZArpexKqQ+UUi/7M5BfDGzw3M6y6akAfObxrRYGEkII3zmTFvlXgT3+CuJX8TkQmwFVxbicdubnJgDQ2NFjcTAhhDh7YyrkSqlcYBXwqH/j+IlSxgmZq4oBuOOiaQCUN3VamUoIIXxirC3yB4FvASMecUopdadSqkgpVRSQ593LWQyN+6G7lampMQDUy/HJhRAhYNRCrpT6OFCvtS4+3Xxa63Va60KtdWFaWprPAvpMziJjWr2DzHjjDNa1UsiFECFgLC3y5cA1Sqky4Fngo0qpp/yayh/MU79RVUxyTATREXbpWhFChIRRC7nW+l6tda7WOg9YA7yltb7F78l8LToZkqdDVTFKKbITo6htlRa5ECL4hcc48n45i6BqOwDpcZE0yKgVIUQIOKNCrrXeqLX+uL/C+F3OYmivhrYaMhNcVLd0WZ1ICCHOWpi1yM0dg6q3k5cSQ01rt+yqL4QIeuFVyDPngc0BVcVMSYkG4GizbPAUQgS38CrkzqiBU7/1jyU/0njc4lBCCHF2wquQg7mH5wdMSYoCoLxJCrkQIriFXyHPWQw9rSR0HSUp2smRRulaEUIEt/As5DDQvXK4ocPaPEIIcZbCr5CnnQvOGKjaTp9Hs+VIM16vtjqVEEKMW/gVcpvd2F2/qnjgbEG7a9osDiWEEOMXfoUcIGch1JZw2/nZgBRyIURwC89Cnr0IPL3kO6qIdNjYV9tudSIhhBi38CzkmfMAcDTsZlZWPLurpUUuhAhe4VnIk6eBwwX1u5mTFc+u6la0lg2eQojgFJ6F3GaH9NlQV8qc7Hjaut1UNMsBtIQQwSk8CzlAej7U7RoYufLnHVUWBxJCiPEJ30KekQ/HGyhM6QOgtavP4kBCCDE+4V3IAUfjHmZlxvHW3nqLAwkhxPg4rA5gGbOQU7eLvbVTAWjv7iPO5bQwlBBCnLnwbZHHpEJsBtTv5j9WzQbgw6pWi0MJIcSZC99CDkarvK6U6xblAlBSKYVcCBF8wruQp8+B+r0kuWxMTo5mZ0WL1YmEEOKMhXchz5gLnh5oPsz8SYlSyIUQQSnMC3n/Bs9S5ucmUN3aTX17t7WZhBDiDIV3IU87F5Qd6nYxf1IiACUV0k8uhAgu4V3IHZGQOhPqd5OfHY/dpthZKd0rQojgEt6FHAZGrkRHOJiWGsOeGjmkrRAiuEghT58DLUehu40Z6bHsr5NCLoQILlLIM+Ya0/o9LJycyNHmThrae6zNJIQQZ0AK+aCRK3OyEgA4IK1yIUQQkUKekAuRCVC3ixnmIW0PNnRYHEoIIcZOCrlSkDEH6neTER9JXKSDA3VSyIUQwUMKOZgjV3ahgFlZceypkXN4CiGCx6iFXCnlUkptVUrtVErtUkrdPxHBJlT6HOhpg9YKzsmI40B9h5zDUwgRNMbSIu8BPqq1ng8sAK5QSi31b6wJ1j9ypW4309Niae3qo7Gj19pMQggxRqMWcm3o7zR2mpfQaq6mG8cjp66U6f0bPOuln1wIERzG1EeulLIrpXYA9cDrWustw8xzp1KqSClV1NDQ4Ouc/uWKh8TJQ0au3PlkkcWhhBBibMZUyLXWHq31AiAXWKKUmjvMPOu01oVa68K0tDRf5/S/jLlQv5vsBBcA7d1uiwMJIcTYnNGoFa11C7ARuMIvaayUkQ+NB1DuHv71I9Nx2hVuj9fqVEIIMaqxjFpJU0olmtejgEuBvf4ONuHS54D2QOM+pqfF0OfRVBzrsjqVEEKMaiwt8izgbaVUCbANo4/8Zf/GssCgkSvT0mIA2LCr1sJAQggxNo7RZtBalwALJyCLtZKngcMFdaWcM2s1ABXNnRaHEkKI0cmenf3sDuOMQXW7iHM5yYiPpMctfeRCiMAnhXwwc+QKwKSkaGmRCyGCghTywTLyoaMOOhqYlBxNpWzsFEIEASnkg6XPMab1u5iUFEVNaxd9MgRRCBHgpJAPNmjkSm5SNF4NNS3d1mYSQohRSCEfLDYNYtKgbhe5yVEAVByTfnIhRGCTQn6yjHyoK2VSUjQAlVLIhRABTgr5yTLmQsNesuKc2G2KimbZ4CmECGxSyE+WPgfc3Thay8hOdEnXihAi4EkhP1lGvjGtKyU3UcaSCyECnxTyk6XNAmWDut04HTa2H22R074JIQKaFPKTOV2QMgPqdpEaEwFAVYv0kwshApcU8uGYI1euW5wLIBs8hRABTQr5cDLyoaWcyTHGXp3STy6ECGRSyIeTbmzwzOo9jN2mKG8+bnEgIYQYmRTy4ZgjVxwNe8hNiqK8SVrkQojAJYV8OImTITIBanYwOTmaI43SIhdCBC4p5MNRCiafD+WbmJ+byN7adjp73VanEkKIYUkhH8mUZdC4j6UZXjxezQdHW6xOJIQQw5JCPpIpywEoVHuIcNjYuK/e4kBCCDE8KeQjyVoAjihc1VuYmR7L/roOqxMJIcSwpJCPxBEBk86D8veZmR7Lvtp2qxMJIcSwpJCfzpTlUFvK/FRFbVs3e2rarE4khBCnkEJ+OlOWAZoLIg4AsGFXrbV5hBBiGFLITyenEGxOzu3+EIAH3zhgcSAhhDiVFPLTiYiGnEWoo/9kbk480RF2qxMJIcQppJCPZsoyqP6AT+Yn0dnr4djxXqsTCSHEEFLIRzNlBXjdLHEeAmDjfhlPLoQILFLIRzNpCSgb0zt3AvDDV/ZYHEgIIYaSQj4aVzxkFhBdsxWHTTEpOdrqREIIMcSohVwpNUkp9bZSao9SapdS6qsTESygTFkOldv4zHmZ7K9tx+uVc3gKIQLHWFrkbuAbWuvZwFLgbqXUHP/GCjBTloG7m+XRFRzv9XBUzhgkhAggoxZyrXWN1nq7eb0d2APk+DtYQJl8AQD5faUA7KqWPTyFEIHjjPrIlVJ5wEJgiz/CBKyYFEibTVpzMQB3P73d4kBCCHHCmAu5UioWeAG4R2t9SpNUKXWnUqpIKVXU0NDgy4yBYcoy7JVbseMBQGvpJxdCBIYxFXKllBOjiK/XWr843Dxa63Va60KtdWFaWpovMwaGKcugt51frnQCUNXSZXEgIYQwjGXUigIeA/ZorX/q/0gBasoyABZ4dwGw9UizlWmEEGLAWFrky4FbgY8qpXaYl6v8nCvwxGdD0lSyWrYT53Kw6VCT1YmEEAIY26iV97TWSmtdoLVeYF5enYhwAWfKctTRTVw2O43XSmvpdXutTiSEELJn5xmZsgy6mlmV1UZ7j5vDjXL6NyGE9aSQnwmzn3yex+gn/+Boi5VphBACkEJ+ZpLyIC6b1KZiUmMj2XxY+smFENaTQn4mlIIpy1Dl/2TRpASKyo5ZnUgIIaSQn7Epy6C9hvOT2qlp7aLH7bE6kRAizEkhP1NTlgPGeHKvhspjsmOQEMJaUsjPVNq5EJ3ClI4dAJQ3Hbc4kBAi3EkhP1NKweQLSGooAqCsUQ5pK4SwlhTy8ZiyHHtrGTNcrZRJi1wIYTEp5ONhjie/PPYwZU3SIhdCWEsK+XhkzoOIOJba90kfuRDCclLIx8Nmh8lLye/dSeUxGYIohLCWFPLxOudykrvKmaUPc7hBWuVCCOtIIR+veZ/Ga4/kRvtb7KtttzqNECKMSSEfr6hEmPMJrrX/k8PV9VanEUKEMSnkZ8FW+FniVBcJh1+xOooQIoxJIT8bky+gLmIShc1/tTqJECKMSSE/G0pxMPdTzNd7OV5ZanUaIUSYkkJ+lrpmX0+ftnP0jUesjiKECFNSyM/S1Lw8XvcuJqf8z+DusTqOECIMSSE/S9PTYnkvbhXxug32ykZPIcTEk0LuAyURC6jUqXiKn7A6ihAiDEkh94Gbl03jD+6LsR/ZCMfKrI4jhAgzUsh94Or52fyZi/Figw+esjqOECLMSCH3gdhIB0c9yWz0FODZ/iR43FZHEkKEESnkPhLncvCcZyX2jlo4+IbVcYQQYUQKuY98eN/lvOldSINOoHfbb62OI4QII1LIfWjtqnk877kIx8HXoa3G6jhCiDAhhdyHbr9wGpsTVmHDAzvWWx1HCBEmpJD72IVLz2eTZw7u4t+D12t1HCFEGJBC7mPnT03hGc9KHK3lUPaO1XGEEGFg1EKulHpcKVWvlJLD+43BvNwENnjPo0XHoLf/3uo4QogwMJYW+e+AK/ycI6TkpCXxJ88KPLv+Ah1y9iAhhH+NWsi11u8AzROQJWT85UsreMpzKR6vxv27q6Gt2upIQogQJn3kfhAb6eCmVR/js33fhpYKeOwyaNhvdSwhRIjyWSFXSt2plCpSShU1NDT4arFBa/XiXDZ58/nzgnXg7obHL4fKYqtjCSFCkM8KudZ6nda6UGtdmJaW5qvFBq2EKCfpcZFs6pwEn9sArnh44uNwQHbfF0L4lnSt+NHMjFgO1rdDynT43N+N6TM3QMkfrI4mhAghYxl++AywCThXKVWplPq8/2OFhpnpcRyo70BrDXEZ8NlXYPIF8OIdsOnXVscTQoSIsYxauVFrnaW1dmqtc7XWj01EsFAwIz2Wzl4Phxo6jDtcCXDz8zD7GthwL7z+fdDa2pBCiKAnXSt+lJ8dD8COitYTdzpd8OnfQeHn4P0H4alPQfkmawIKIUKCFHI/KshNBGDdO4eGPmCzw6qfwuX/DdU74LdXwGOXw76/WXN8Fk/fxL+mL7VWwc7nYMN34PBG+ZUjwo7D6gChzG5TzJ+USEllCx6vxm5TJx5UCi64CxbfZpwe7p+/hGfWQNpsWP5VmLca7E7/BqzYCu/8BA5sgMh4iMs0L1mDplkQmwHuLmMv1Y66QdNB16OS4IIvwYKbjV8dZ6q3Ezy9Rg7bKO2L1kooex/K3oWy9+DYEeN+ZYNNv4KcxXDhN+CcK0dflhAhQGk/tF4KCwt1UVGRz5cbjJ7cXM53/1zKY7cVcsnsjJFn9PRB6YtGd0v9bkiYZBTGRbdCRIzvAmltFL93/geO/AOikmHBTeB1Q3sNtNcax1JvrwHvCC11R5Sx8TY2A2LTISYdanZAVTHEZsKyL0Phv4ye2+sxMux4Gvb81Rhvr2zGtoSopFMvvZ1Q/t6JE1y7EmDKCshbDnkrIGUmlDwL7z0ILeXGSvHCr0P+p8AubRYR2JRSxVrrwnE9Vwq5fzW093DeD9/g8vwMHrl1DJ+R1nDg7/Dez+DoJrA5IDoVolMgJsWYnnxJngqp50Bk3OmXe/BNo4BXbDaK8LKvjFxwtYbOZqOgd9SCM8Yo2rHpEBFr/KI4ef7DG+Hd/zVaylHJsPQuWHIHRCUOnbfxIOx8GnY+C21VRkGeu9oYntl1DLpazOmgS3cLoIxRP3krjEtGvtFNdTKPG3a9CO/+FBr2QOIUWHEPzL/pxK8FreF4o1Hwj5UZl5Zy6G6FtFmQWQCZ8yBx8qnvVQg/kEIe4PLWvgLA3h9cgcs5TOEZydHNsP81o+B0NkNnE3Q2GtOuY6fOH59jFPS0c4dOK7YaBbxmB8TnGkVt4a3j6wIZU+4tRkE/sAEi4mDJ7cbrlb1rtL4rthgt7xmXGr8GzrnSP1m8Xtj/NyNL/6+F7AVwrBxajkLf8aHzx6QZK8NjZaDNbRWuhBNFPbMAMucaK4bION8W+L4uaD4CzYeMqTMKkqcZK7f4XPlFEQakkAe4u5/ezislNVw5N5OHblnsm4V63EYrtaMemg5C437j0rAPGg+cWqSSphr9xgU3gCPCNxlGU1NiFNHdLwHm9yz1XFh4M8y7HuKzJiaH1nDkHXj/50bXUVIeJE0xCnL/NHEyRMYa8/d2Gt1btSXGe6j9EOp2GdsJ+jmjza6lDLObKfPE1BUPKLPQDzP19Bori+ZD0HQImg8b/f6M8L9ocxo5k6dB8nRjmjoDMuYav5BESJBCHgT6W+WvfGUF+dkJ/n0xr9fosmjcZxysKy4DZl9rXauu8QDsfQWmXgjZi4Kzq8LrMVaYtR8af9v2OqPLqaPeWDl01EFP25kt05UIKTOMVnfydGOaYhbq3k6jwDebhb7/0nR46Eo6NsP4tZAx1/zVMM9Y5nBdTiKgSSEPAs9sPcq9L35IpMPGB9/7GNER8lM55PR2mgW9HdDmMMjBU4ypshm/CqKTz/w1tDZWHg17oa4UakuNlUvD3hMbpx0uSJ9jbEPInGdMM/KNDcYiYEkhDxJf/8MOXtxeBcBnl+Vxyex0LpwpBxgTPuDuNX6B9Rf2ug+N612DTiUQn3uiqGfONX4RuLuN/vm+TnPadeK29p4YhhqfY3SFxWWBI/I0OXqGbqx2dxsb7Acu9qG3HRHGqKeIaP//jQKcFPIg0efxculP/0F5U+fAfZ9cmMPPblhgYSoRsrQ2fiHUlhqt97pdxqVxnzHc9HQcLuP5np5TH4tOgbhso8vu5MJ98raZsXIlDNp/IXvQfgwZZhavkUd7h176tyso+0krCvuJ+5SC7jZjm1JXizk9Nuh6iznsNd7Yj8GVcOr1iDhjpWOPNKfDXLfZMLaF2MzLoOv920gGv4/+X2vmdRWVOO5CLr/vJ5DTbmPjv13Ml575gFdKagDYfLjJ4lQiZCl1YievmZeeuN/dY2wY7z1ujI5xRhvF0hlt3Ha4jKKktVHo2mqgvfrE/gVt1Sf2OXBGQeIkyCowx/snDh3773AZ2xe87kHTQRd3t7Gyaa81l10Dje8Y2x9GW9mcjch44xdJVIIx1drY9tG9x9jW0d16YuRSEJAWuYV+8PJuntxczof3XUakQzZOCTHA6zWG2Q7smDa4pXtSi1dr0J6hKww9aKWhvRCZYKxkXIlGK3u0Df9aGyu6njajNd/bYawAPb3GZbjrA78U9NBfDAP3M6iVrga9J+O6Wv5laZEHo6XTUnjsvSMUlx1j2YxUq+MIEThsNohNMy5WUMoYjhoZC/HZE/SiXx73M+VAFBZaPiOFCIeNN/fWWx1FCBHEpJBbKDrCwbLpKby5pw5/dHEJIcKDFHKLfeScNMqaOikqH2aXeyGEGAMp5Ba7cq6xm/r3XtplcRIhRLBixrO1AAAMtUlEQVSSQm6xzAQXF52Txp6aNr7wZBGdvX4cciWECElSyAPAI+aBtDbsqmPO9zYw8zuv0tEjBV0IMTZSyANAVISdN75+0cDtPo9m7vc3kLf2FX77/hELkwkhgoEU8gAxIz2OsgdWse07lzI97cSJHu7/627q27stTCaECHRSyANMWlwkb37jYsoeWEVspLG/1pIfvmlxKiFEIJNCHsBK77+cOVnxANzx+yI83lPHmrs9wXM8CCGEf8ixVgJcd5+HWd99beD2wsmJpMREMDk5hsffP0KEw8bPrl/AqoIJOtuOEMIvzuYwttIiD3Aup53d/+9yZqYbpyH74GgLb+yp53FzI2iv28vXntvB4YYOK2MKISwkLfIg8lppLY++e5hd1W109Xl4+vbzmZIaw2U//QfHez0A5CRGEemwsWRqMs9uqwDg9hVT+Y+Pz7EyuhBiFHJiiTD3pw8q+dpzO087z8O3LOaKuZnDPub1amy2IDyPphAhRAq5oMftYVd1Gy9ur+RYZx+vlNTw/tqP0tzRy+ee2EZDew/zcxP4zW2FpMVGUtXSxYofvT1kGe9+ayWTkoeecuutvXX86q2DfPmjM1k568QZ22tau4iJdBDvck7I+xMi1EkhF6dV39495iGMX7lkJnevnE5nj4fP/m4bOytahjweHWFn5az0gTMczc6KJzU2grVXziI/O2Fc+bxezX+9uofp6bHcuGTyuJYhRLCTQi7G5NmtR1n74ocATEuL4Sefns+iyUlorXnnQCO3P7GNPs+p34f7r8nnv17dQ4/79EMdk6KdXHxuOoumJPHpxbn8rbSGzYea6fN4qTjWyacW5ZKZ4GLR5CSu/uV7HG3uHHY5BbkJ5CZF8YNr55ISa5zo93BDBymxkSREDf0F4DWHZCoFSkn3kAhefi/kSqkrgJ8DduBRrfUDp5tfCnlwcnu8PLutgqc2l7O3tp2vfHQGX7/s3IHHmzp6eHJzOS2dfXzhI9PISoiitauPTYeaeGlHFa/tqiUmwuHT48SkxkbQ3ecdWObHC7K4cGYq1S3dVLV0selQE1UtXUOec+nsdGZmxPH5FVNJNVcEx3vc2JTC5bTx7LYKtIb0uEgWT0kizuXAYbdR1dJFbKTjlJWFx6vp7vMQEykn1BL+49dCrpSyA/uBjwGVwDbgRq317pGeI4U8fLk9XtZvOcpLO6o43uPhT3cvo+pYF7lJ0WzcV8/D/zjEZfmZ2JTihvMmkRjlHLKhtdds9W863MSOoy0cauigtrWbgw0deLyazl73Kb8arpmfTZ/Hy99Ka336Xs7JiKWxo5fm470AxETYWbNkMvvr2pmUHE2f20vz8V6qW7tp6+rjwpmp9Lq9XHROGkumJhPrctDY3kNyTATHOvuoOtZFR4+b9u4+ZmXGk5sUhVJQ1tTJnKx4nHZFeVMnMZEOtNbUtnUzKzOeCIeMEg4H/i7kFwD3aa0vN2/fC6C1/u+RniOFXPhLS2cvmw83EemwU5CbgMtpP6Wl7PVqNu6v549FlVQc66S0qo0r52bS2tWHx6spb+rklzct5JdvHSQn0YXDZqOksoWdla0A2G0Kj1cTE2Gns89D/7+IUjD43yU1NoKUmEhcEXainDb21rbT0tk3rvfltKthu7XA+OWQHBNBd58Hl9NOblI08S4HNa3dpMdHcqTxOE67jWOdvdS2dmNTio4eN3Oy4ol1OUiOjmBySjQH6zvITYriUEMHCVFOshOiyEqM4u+7aslJiiIvJYbU2Eg8WtNyvJe69m4SopxERziIctpx2BVKKWwK2rvdHG7owGm3kRobSWykA1eEnbhIh/ELxu2hq9dDYnQEyTFOnHYbXm2s6Dt63ETYbSilSI6JoL27j6gIO3GRTlxOG067DbdXo7Wmx+3FblM4zdfu83hxezROu42OHjderYmw23B7vcRGOnHYFZ09HpQCp92G065w2m0oZfyystsUEQ4bTpsNjbHDnVcb99uVwm5T2JSitasPh/lcr9Z4NWit8Xqh1+Ohq9dLhMOGw37ieQ678VylwKYU3X0ePF7NcTNPlNNOdIRxknWP1igUbq/x/hSKrMQovxby1cAVWuvbzdu3Audrrb800nOkkItQ1ev20tLZi9NuIykm4pTHjzQe50hjB2WNnTR29BDltON02DjScJzcpCjm5iSQGhtJ5bFOqlq6qG7pxuW0md1HfdS0drPy3HSUguqWLmw2RUN7D00dvbR199HS2YdNQXefl/r2bvo8mtTYSFJjI4hw2EiOiSArwcX+ug76PF60huO9biqaOwdWFJnxLjSaurae075Xl9NGn0cPe2gIgLhIBw674tg4V15iqPIffXzchXwsnX7DbUE65ZNVSt0J3Gne7FFKlY4n0ARKBRqtDjEKyeg7wZAzFWh86gyfVO7n+U8SNH9Hq0OMYriMU8a7sLEU8kpg0qDbuUD1yTNprdcB6wCUUkXjXbNMFMnoG8GQEYIjp2T0jXDMOJatKNuAmUqpqUqpCGAN8BdfBRBCCHF2Rm2Ra63dSqkvARswhh8+rrWWMwULIUSAGNPAWK31q8CrZ7DcdeOLM6Eko28EQ0YIjpyS0TfCLqNf9uwUQggxcWRPAyGECHI+LeRKqSuUUvuUUgeVUmt9uewxvPbjSqn6wcMelVLJSqnXlVIHzGmSeb9SSv3CzFmilFo06Dm3mfMfUErd5uOMk5RSbyul9iildimlvhqgOV1Kqa1KqZ1mzvvN+6cqpbaYr/mcufEbpVSkefug+XjeoGXda96/Tyl1uY9z2pVSHyilXg7EfObyy5RSHyqldiilisz7Au3zTlRKPa+U2mt+Ny8IpIxKqXPNv1//pU0pdU8gZRy0/K+Z/zOlSqlnzP8l/38vtdY+uWBsCD0ETAMigJ3AHF8tfwyvfxGwCCgddN+PgbXm9bXAj8zrVwF/wxgjvxTYYt6fDBw2p0nm9SQfZswCFpnX4zAOfTAnAHMqINa87gS2mK//B2CNef/DwBfN63cBD5vX1wDPmdfnmN+DSGCq+f2w+zDn14GngZfN2wGVz3yNMiD1pPsC7fN+ArjdvB4BJAZaxkFZ7UAtxpjrgMoI5ABHgKhB38fPTsT30pd/4AuADYNu3wvc6+sPcpQMeQwt5PuALPN6FrDPvP4IxvFihswH3Ag8Muj+IfP5Ie9LGMewCdicQDSwHTgfYwcGx8mfN8aIpgvM6w5zPnXyd2DwfD7IlQu8CXwUeNl8vYDJN2iZZZxayAPm8wbiMYqPCtSMJ+W6DHg/EDNiFPIKjBWFw/xeXj4R30tfdq30v4l+leZ9VsrQWtcAmNP+MyOMlHXC3oP5M2ohRms34HKa3RY7gHrgdYxWQYvWuv/QhoNfcyCP+XgrkOLnnA8C3wL6j62bEmD5+mng70qpYmXs/QyB9XlPAxqA35rdVI8qpWICLONga4BnzOsBlVFrXQX8BDgK1GB8z4qZgO+lLwv5mHblDxAjZZ2Q96CUigVeAO7RWredbtYR8vg9p9bao7VegNHyXQLMPs1rTmhOpdTHgXqtdfHgu0/zWlZ+3su11ouAK4G7lVIXnWZeK3I6MLokH9JaLwSOY3RTjMSyv6XZt3wN8MfRZh0hi18zmn3012J0h2QDMRif+0iv6bOcvizkY9qVf4LVKaWyAMxpvXn/SFn9/h6UUk6MIr5ea/1ioObsp7VuATZi9DUmKqX69z0Y/JoDeczHE4BmP+ZcDlyjlCoDnsXoXnkwgPIN0FpXm9N64E8YK8VA+rwrgUqt9Rbz9vMYhT2QMva7Etiuta4zbwdaxkuBI1rrBq11H/AisIwJ+F76spAH4q78fwH6t0zfhtEn3X//Z8yt20uBVvOn2QbgMqVUkrl2vcy8zyeUUgp4DNijtf5pAOdMU0olmtejML6ge4C3gdUj5OzPvxp4Sxude38B1phb56cCM4GtZ5tPa32v1jpXa52H8T17S2t9c6Dk66eUilFKxfVfx/icSgmgz1trXQtUKKX6zyByCbA7kDIOciMnulX6swRSxqPAUqVUtPm/3v+39P/30scbIq7CGIlxCPiOrzd0jPLaz2D0S/VhrNE+j9Hf9CZwwJwmm/Mq4P/MnB8ChYOW8zngoHn5Fx9nXIHxE6kE2GFergrAnAXAB2bOUuB75v3TzC/UQYyft5Hm/S7z9kHz8WmDlvUdM/8+4Eo/fO4Xc2LUSkDlM/PsNC+7+v8nAvDzXgAUmZ/3nzFGdARaxmigCUgYdF9AZTSXfz+w1/y/eRJj5Infv5eyZ6cQQgQ52bNTCCGCnBRyIYQIclLIhRAiyEkhF0KIICeFXAghgpwUciGECHJSyIUQIshJIRdCiCD3/wGn093uE8UY1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-4\n",
    "wd = 1e-1\n",
    "epochs = 40\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_squish_40epochs_delextraBN_lr3e-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6200281, tensor(0.8810)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.to_fp32().validate(img_data_test.train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
