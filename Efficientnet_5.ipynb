{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import time\n",
    "import os\n",
    "from helper import get_car_paths, get_cars_df, get_car_data, get_effnet\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_all(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop, cutout, wd=1e-5, LabelSmoothing, mixup\n",
    "\n",
    "acc = 0.923219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,2.0), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 50), p=0.8)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0718, -0.0658, -0.0117,  ...,  0.0062,  0.0119,  0.0428],\n",
      "        [ 0.0639, -0.0524, -0.0286,  ..., -0.0625,  0.0323, -0.0058],\n",
      "        [ 0.0173,  0.0078, -0.0237,  ...,  0.0203, -0.0095,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0226,  0.0317,  ...,  0.0056,  0.0121, -0.0259],\n",
      "        [-0.0409,  0.0348,  0.0044,  ..., -0.0138, -0.0759, -0.0460],\n",
      "        [-0.0812,  0.0199,  0.0363,  ..., -0.0296, -0.0574,  0.0551]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fe045255158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.261452</td>\n",
       "      <td>5.082067</td>\n",
       "      <td>0.052211</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.779532</td>\n",
       "      <td>4.280972</td>\n",
       "      <td>0.179361</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.994647</td>\n",
       "      <td>3.061420</td>\n",
       "      <td>0.399263</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.234458</td>\n",
       "      <td>2.261507</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.799880</td>\n",
       "      <td>2.046139</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.634579</td>\n",
       "      <td>2.096601</td>\n",
       "      <td>0.628378</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.617093</td>\n",
       "      <td>2.025749</td>\n",
       "      <td>0.657862</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.637721</td>\n",
       "      <td>2.234322</td>\n",
       "      <td>0.604423</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.669004</td>\n",
       "      <td>2.420606</td>\n",
       "      <td>0.573710</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.699150</td>\n",
       "      <td>2.375306</td>\n",
       "      <td>0.552211</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.691556</td>\n",
       "      <td>2.543086</td>\n",
       "      <td>0.544840</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.688857</td>\n",
       "      <td>2.387052</td>\n",
       "      <td>0.586609</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.715963</td>\n",
       "      <td>2.285239</td>\n",
       "      <td>0.597052</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.724162</td>\n",
       "      <td>2.552166</td>\n",
       "      <td>0.526413</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.682731</td>\n",
       "      <td>2.290393</td>\n",
       "      <td>0.615479</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.621208</td>\n",
       "      <td>2.519454</td>\n",
       "      <td>0.570639</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.646888</td>\n",
       "      <td>2.209949</td>\n",
       "      <td>0.625307</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.576465</td>\n",
       "      <td>2.203470</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.452883</td>\n",
       "      <td>1.941743</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.460989</td>\n",
       "      <td>1.972753</td>\n",
       "      <td>0.692260</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.347527</td>\n",
       "      <td>1.906943</td>\n",
       "      <td>0.706388</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.429674</td>\n",
       "      <td>1.690325</td>\n",
       "      <td>0.769656</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.300777</td>\n",
       "      <td>1.791814</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.279803</td>\n",
       "      <td>1.705389</td>\n",
       "      <td>0.762899</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.225774</td>\n",
       "      <td>1.714626</td>\n",
       "      <td>0.764742</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.161813</td>\n",
       "      <td>1.642444</td>\n",
       "      <td>0.786855</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.158433</td>\n",
       "      <td>1.704830</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.135433</td>\n",
       "      <td>1.598937</td>\n",
       "      <td>0.810197</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.106179</td>\n",
       "      <td>1.558067</td>\n",
       "      <td>0.802826</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.043700</td>\n",
       "      <td>1.531253</td>\n",
       "      <td>0.820639</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.063030</td>\n",
       "      <td>1.497350</td>\n",
       "      <td>0.821867</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.987052</td>\n",
       "      <td>1.474756</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.986746</td>\n",
       "      <td>1.464332</td>\n",
       "      <td>0.838452</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.961408</td>\n",
       "      <td>1.419796</td>\n",
       "      <td>0.839681</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.925314</td>\n",
       "      <td>1.389155</td>\n",
       "      <td>0.862408</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.887117</td>\n",
       "      <td>1.399611</td>\n",
       "      <td>0.845209</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.869692</td>\n",
       "      <td>1.332508</td>\n",
       "      <td>0.871007</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.870531</td>\n",
       "      <td>1.322422</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.821248</td>\n",
       "      <td>1.282808</td>\n",
       "      <td>0.886978</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.830050</td>\n",
       "      <td>1.288061</td>\n",
       "      <td>0.882678</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.751463</td>\n",
       "      <td>1.265053</td>\n",
       "      <td>0.895577</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.759053</td>\n",
       "      <td>1.234030</td>\n",
       "      <td>0.902334</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.752386</td>\n",
       "      <td>1.236051</td>\n",
       "      <td>0.896806</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.752096</td>\n",
       "      <td>1.225283</td>\n",
       "      <td>0.898649</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.663390</td>\n",
       "      <td>1.205248</td>\n",
       "      <td>0.904177</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.725611</td>\n",
       "      <td>1.206364</td>\n",
       "      <td>0.909705</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.684809</td>\n",
       "      <td>1.208321</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.675866</td>\n",
       "      <td>1.184342</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.646065</td>\n",
       "      <td>1.170048</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.641240</td>\n",
       "      <td>1.165270</td>\n",
       "      <td>0.920762</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.632530</td>\n",
       "      <td>1.157407</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.595297</td>\n",
       "      <td>1.152337</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.635591</td>\n",
       "      <td>1.159844</td>\n",
       "      <td>0.922604</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.612905</td>\n",
       "      <td>1.154740</td>\n",
       "      <td>0.923219</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.602613</td>\n",
       "      <td>1.151168</td>\n",
       "      <td>0.922604</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.614604</td>\n",
       "      <td>1.145572</td>\n",
       "      <td>0.924447</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.618912</td>\n",
       "      <td>1.144600</td>\n",
       "      <td>0.923833</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.643656</td>\n",
       "      <td>1.142195</td>\n",
       "      <td>0.923219</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.618216</td>\n",
       "      <td>1.143461</td>\n",
       "      <td>0.925061</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.613428</td>\n",
       "      <td>1.142831</td>\n",
       "      <td>0.923219</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fe045255158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"b3_sz300_60epochs_004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.export(\"exported_models/exported.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop, wd=1e-5, LabelSmoothing, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,2.0), do_rand=True)\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0718, -0.0658, -0.0117,  ...,  0.0062,  0.0119,  0.0428],\n",
      "        [ 0.0639, -0.0524, -0.0286,  ..., -0.0625,  0.0323, -0.0058],\n",
      "        [ 0.0173,  0.0078, -0.0237,  ...,  0.0203, -0.0095,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0226,  0.0317,  ...,  0.0056,  0.0121, -0.0259],\n",
      "        [-0.0409,  0.0348,  0.0044,  ..., -0.0138, -0.0759, -0.0460],\n",
      "        [-0.0812,  0.0199,  0.0363,  ..., -0.0296, -0.0574,  0.0551]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f7a9423e158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.245312</td>\n",
       "      <td>5.047501</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.783428</td>\n",
       "      <td>4.216805</td>\n",
       "      <td>0.175061</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.898960</td>\n",
       "      <td>2.922734</td>\n",
       "      <td>0.450246</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.130514</td>\n",
       "      <td>2.259289</td>\n",
       "      <td>0.600123</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.783135</td>\n",
       "      <td>2.181058</td>\n",
       "      <td>0.624079</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.629166</td>\n",
       "      <td>1.959982</td>\n",
       "      <td>0.665233</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.606921</td>\n",
       "      <td>2.161095</td>\n",
       "      <td>0.625307</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.589913</td>\n",
       "      <td>2.249611</td>\n",
       "      <td>0.600737</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.561589</td>\n",
       "      <td>2.191021</td>\n",
       "      <td>0.617322</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.689677</td>\n",
       "      <td>2.371197</td>\n",
       "      <td>0.565725</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.691874</td>\n",
       "      <td>2.550238</td>\n",
       "      <td>0.546683</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.707616</td>\n",
       "      <td>2.473767</td>\n",
       "      <td>0.563268</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.638625</td>\n",
       "      <td>2.472267</td>\n",
       "      <td>0.558354</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.595789</td>\n",
       "      <td>2.386350</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.598348</td>\n",
       "      <td>2.319826</td>\n",
       "      <td>0.580467</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.551180</td>\n",
       "      <td>2.396466</td>\n",
       "      <td>0.584152</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.524808</td>\n",
       "      <td>2.377810</td>\n",
       "      <td>0.579238</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.531762</td>\n",
       "      <td>2.187493</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.417459</td>\n",
       "      <td>2.004126</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.367288</td>\n",
       "      <td>1.968129</td>\n",
       "      <td>0.688575</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.363258</td>\n",
       "      <td>1.834837</td>\n",
       "      <td>0.732187</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.337855</td>\n",
       "      <td>1.827623</td>\n",
       "      <td>0.733415</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.303985</td>\n",
       "      <td>1.902574</td>\n",
       "      <td>0.711302</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.205563</td>\n",
       "      <td>1.804980</td>\n",
       "      <td>0.748157</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.211960</td>\n",
       "      <td>1.635796</td>\n",
       "      <td>0.786855</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.178686</td>\n",
       "      <td>1.792257</td>\n",
       "      <td>0.749386</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.132657</td>\n",
       "      <td>1.704104</td>\n",
       "      <td>0.773342</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.091930</td>\n",
       "      <td>1.543230</td>\n",
       "      <td>0.814496</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.072374</td>\n",
       "      <td>1.628726</td>\n",
       "      <td>0.788698</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.029392</td>\n",
       "      <td>1.497517</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.966174</td>\n",
       "      <td>1.490916</td>\n",
       "      <td>0.820025</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.976289</td>\n",
       "      <td>1.531963</td>\n",
       "      <td>0.816953</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.946278</td>\n",
       "      <td>1.447605</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.907445</td>\n",
       "      <td>1.373739</td>\n",
       "      <td>0.853194</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.883449</td>\n",
       "      <td>1.417004</td>\n",
       "      <td>0.855037</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.905062</td>\n",
       "      <td>1.464468</td>\n",
       "      <td>0.850123</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.843421</td>\n",
       "      <td>1.409097</td>\n",
       "      <td>0.845823</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.798576</td>\n",
       "      <td>1.375229</td>\n",
       "      <td>0.867322</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.799662</td>\n",
       "      <td>1.341294</td>\n",
       "      <td>0.862408</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.755400</td>\n",
       "      <td>1.338293</td>\n",
       "      <td>0.875307</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.759357</td>\n",
       "      <td>1.311938</td>\n",
       "      <td>0.873464</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.743559</td>\n",
       "      <td>1.278190</td>\n",
       "      <td>0.892506</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.720686</td>\n",
       "      <td>1.284979</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.727071</td>\n",
       "      <td>1.258685</td>\n",
       "      <td>0.892506</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.704340</td>\n",
       "      <td>1.240115</td>\n",
       "      <td>0.896806</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.679295</td>\n",
       "      <td>1.236793</td>\n",
       "      <td>0.897420</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.658101</td>\n",
       "      <td>1.236409</td>\n",
       "      <td>0.899877</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.631638</td>\n",
       "      <td>1.221398</td>\n",
       "      <td>0.904177</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.639033</td>\n",
       "      <td>1.224495</td>\n",
       "      <td>0.903563</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.658124</td>\n",
       "      <td>1.212213</td>\n",
       "      <td>0.910934</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.635755</td>\n",
       "      <td>1.204781</td>\n",
       "      <td>0.908477</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.605027</td>\n",
       "      <td>1.204672</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.603657</td>\n",
       "      <td>1.197262</td>\n",
       "      <td>0.911548</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.582472</td>\n",
       "      <td>1.196715</td>\n",
       "      <td>0.911548</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.580027</td>\n",
       "      <td>1.195767</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.617725</td>\n",
       "      <td>1.195449</td>\n",
       "      <td>0.907862</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.607512</td>\n",
       "      <td>1.196046</td>\n",
       "      <td>0.909705</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.588380</td>\n",
       "      <td>1.195697</td>\n",
       "      <td>0.907862</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.589751</td>\n",
       "      <td>1.195661</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.563402</td>\n",
       "      <td>1.195074</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_010\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop 1.2, cutout p0.5, wd=1e-5, LabelSmoothing, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.2), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.5)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0718, -0.0658, -0.0117,  ...,  0.0062,  0.0119,  0.0428],\n",
      "        [ 0.0639, -0.0524, -0.0286,  ..., -0.0625,  0.0323, -0.0058],\n",
      "        [ 0.0173,  0.0078, -0.0237,  ...,  0.0203, -0.0095,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0226,  0.0317,  ...,  0.0056,  0.0121, -0.0259],\n",
      "        [-0.0409,  0.0348,  0.0044,  ..., -0.0138, -0.0759, -0.0460],\n",
      "        [-0.0812,  0.0199,  0.0363,  ..., -0.0296, -0.0574,  0.0551]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f01dd2bf1e0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.255710</td>\n",
       "      <td>5.044384</td>\n",
       "      <td>0.065111</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.651124</td>\n",
       "      <td>4.038998</td>\n",
       "      <td>0.225430</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.637526</td>\n",
       "      <td>2.740393</td>\n",
       "      <td>0.483415</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.849819</td>\n",
       "      <td>2.094747</td>\n",
       "      <td>0.657862</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.478132</td>\n",
       "      <td>1.893231</td>\n",
       "      <td>0.713145</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.332865</td>\n",
       "      <td>1.888494</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.317989</td>\n",
       "      <td>2.151523</td>\n",
       "      <td>0.636978</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.342926</td>\n",
       "      <td>2.263163</td>\n",
       "      <td>0.609337</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.347319</td>\n",
       "      <td>2.330727</td>\n",
       "      <td>0.589066</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.327741</td>\n",
       "      <td>2.168817</td>\n",
       "      <td>0.646192</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.375283</td>\n",
       "      <td>2.213864</td>\n",
       "      <td>0.622236</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.335027</td>\n",
       "      <td>2.462775</td>\n",
       "      <td>0.561425</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.335876</td>\n",
       "      <td>2.095467</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.358171</td>\n",
       "      <td>2.143033</td>\n",
       "      <td>0.660319</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.305856</td>\n",
       "      <td>2.168572</td>\n",
       "      <td>0.649263</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.256836</td>\n",
       "      <td>2.216714</td>\n",
       "      <td>0.630221</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.242120</td>\n",
       "      <td>2.502421</td>\n",
       "      <td>0.552211</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.180745</td>\n",
       "      <td>1.844150</td>\n",
       "      <td>0.738329</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.167159</td>\n",
       "      <td>2.028055</td>\n",
       "      <td>0.679975</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.110309</td>\n",
       "      <td>1.871023</td>\n",
       "      <td>0.717445</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.047775</td>\n",
       "      <td>1.768977</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.036410</td>\n",
       "      <td>1.798943</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.986280</td>\n",
       "      <td>1.728399</td>\n",
       "      <td>0.773342</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.941596</td>\n",
       "      <td>1.711936</td>\n",
       "      <td>0.761671</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.936481</td>\n",
       "      <td>1.774460</td>\n",
       "      <td>0.748157</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.905643</td>\n",
       "      <td>1.605318</td>\n",
       "      <td>0.796069</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.825927</td>\n",
       "      <td>1.572447</td>\n",
       "      <td>0.817568</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.867477</td>\n",
       "      <td>1.526310</td>\n",
       "      <td>0.834767</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.815656</td>\n",
       "      <td>1.469016</td>\n",
       "      <td>0.831695</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.771769</td>\n",
       "      <td>1.525679</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.789269</td>\n",
       "      <td>1.468478</td>\n",
       "      <td>0.840295</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.734169</td>\n",
       "      <td>1.426123</td>\n",
       "      <td>0.850123</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.762069</td>\n",
       "      <td>1.397382</td>\n",
       "      <td>0.854423</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.702991</td>\n",
       "      <td>1.416238</td>\n",
       "      <td>0.851966</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.708272</td>\n",
       "      <td>1.319916</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.669191</td>\n",
       "      <td>1.331500</td>\n",
       "      <td>0.869165</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.681828</td>\n",
       "      <td>1.302895</td>\n",
       "      <td>0.880835</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.678602</td>\n",
       "      <td>1.305604</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.639526</td>\n",
       "      <td>1.265814</td>\n",
       "      <td>0.890663</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.642207</td>\n",
       "      <td>1.280915</td>\n",
       "      <td>0.887592</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.633361</td>\n",
       "      <td>1.264806</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.592956</td>\n",
       "      <td>1.241008</td>\n",
       "      <td>0.888206</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.568672</td>\n",
       "      <td>1.246070</td>\n",
       "      <td>0.893120</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.571923</td>\n",
       "      <td>1.201715</td>\n",
       "      <td>0.898649</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.568891</td>\n",
       "      <td>1.193812</td>\n",
       "      <td>0.907248</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.565264</td>\n",
       "      <td>1.194439</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.521291</td>\n",
       "      <td>1.201434</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.525037</td>\n",
       "      <td>1.186907</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.493758</td>\n",
       "      <td>1.175667</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.504886</td>\n",
       "      <td>1.168077</td>\n",
       "      <td>0.914619</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.519324</td>\n",
       "      <td>1.161227</td>\n",
       "      <td>0.908477</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.495282</td>\n",
       "      <td>1.156567</td>\n",
       "      <td>0.915233</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.512906</td>\n",
       "      <td>1.152666</td>\n",
       "      <td>0.912162</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.478377</td>\n",
       "      <td>1.148958</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.463853</td>\n",
       "      <td>1.139767</td>\n",
       "      <td>0.920762</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.477734</td>\n",
       "      <td>1.144465</td>\n",
       "      <td>0.917076</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.478915</td>\n",
       "      <td>1.144237</td>\n",
       "      <td>0.918305</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.494680</td>\n",
       "      <td>1.142831</td>\n",
       "      <td>0.918305</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.475075</td>\n",
       "      <td>1.141064</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.495837</td>\n",
       "      <td>1.141878</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_011\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop 1.5, cutout 0.7, wd=1e-3, LabelSmoothing, mixup\n",
    "\n",
    "acc = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.5), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.7)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data = get_car_data(dataset='train', tfms=tfms, bs=32, sz=(300, 300), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6515 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1629 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Ford Ranger SuperCab 2011,Toyota 4Runner SUV 2012,Aston Martin V8 Vantage Convertible 2012,Suzuki SX4 Sedan 2012,Audi RS 4 Convertible 2008\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fa0ddab6ea0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.254766</td>\n",
       "      <td>5.070622</td>\n",
       "      <td>0.062001</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.734318</td>\n",
       "      <td>4.097730</td>\n",
       "      <td>0.197667</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.784993</td>\n",
       "      <td>2.701973</td>\n",
       "      <td>0.508901</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.984835</td>\n",
       "      <td>2.050241</td>\n",
       "      <td>0.665439</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.549060</td>\n",
       "      <td>1.855017</td>\n",
       "      <td>0.720074</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.419740</td>\n",
       "      <td>1.975735</td>\n",
       "      <td>0.667281</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.432260</td>\n",
       "      <td>2.220763</td>\n",
       "      <td>0.624309</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.403581</td>\n",
       "      <td>2.125919</td>\n",
       "      <td>0.638429</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.408554</td>\n",
       "      <td>2.324325</td>\n",
       "      <td>0.596071</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.439300</td>\n",
       "      <td>2.115845</td>\n",
       "      <td>0.649478</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.481872</td>\n",
       "      <td>2.247843</td>\n",
       "      <td>0.612646</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.469495</td>\n",
       "      <td>2.719564</td>\n",
       "      <td>0.561080</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.414196</td>\n",
       "      <td>2.152427</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.430461</td>\n",
       "      <td>2.557129</td>\n",
       "      <td>0.542050</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.333509</td>\n",
       "      <td>2.139147</td>\n",
       "      <td>0.650706</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.320890</td>\n",
       "      <td>1.982442</td>\n",
       "      <td>0.710252</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.312397</td>\n",
       "      <td>2.315283</td>\n",
       "      <td>0.607121</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.313888</td>\n",
       "      <td>2.003500</td>\n",
       "      <td>0.679558</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.205683</td>\n",
       "      <td>1.806057</td>\n",
       "      <td>0.747084</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.185329</td>\n",
       "      <td>1.739387</td>\n",
       "      <td>0.773481</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.163521</td>\n",
       "      <td>1.818235</td>\n",
       "      <td>0.731737</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.112114</td>\n",
       "      <td>1.709596</td>\n",
       "      <td>0.764273</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.083760</td>\n",
       "      <td>1.613139</td>\n",
       "      <td>0.796194</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.066505</td>\n",
       "      <td>1.692611</td>\n",
       "      <td>0.778392</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.994632</td>\n",
       "      <td>1.582113</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.955360</td>\n",
       "      <td>1.607374</td>\n",
       "      <td>0.794352</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.911708</td>\n",
       "      <td>1.619827</td>\n",
       "      <td>0.786986</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.931941</td>\n",
       "      <td>1.505489</td>\n",
       "      <td>0.826274</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.877451</td>\n",
       "      <td>1.452706</td>\n",
       "      <td>0.844690</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.870310</td>\n",
       "      <td>1.421360</td>\n",
       "      <td>0.846532</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.839242</td>\n",
       "      <td>1.416235</td>\n",
       "      <td>0.848373</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.825812</td>\n",
       "      <td>1.387186</td>\n",
       "      <td>0.852670</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.806302</td>\n",
       "      <td>1.359850</td>\n",
       "      <td>0.860037</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.772615</td>\n",
       "      <td>1.312548</td>\n",
       "      <td>0.882750</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.744014</td>\n",
       "      <td>1.344470</td>\n",
       "      <td>0.869245</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.722733</td>\n",
       "      <td>1.310857</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.731171</td>\n",
       "      <td>1.313020</td>\n",
       "      <td>0.889503</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.690876</td>\n",
       "      <td>1.274827</td>\n",
       "      <td>0.885819</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.667326</td>\n",
       "      <td>1.315131</td>\n",
       "      <td>0.879681</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.635051</td>\n",
       "      <td>1.264805</td>\n",
       "      <td>0.893800</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.620868</td>\n",
       "      <td>1.268681</td>\n",
       "      <td>0.892572</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.625690</td>\n",
       "      <td>1.245252</td>\n",
       "      <td>0.892572</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.598521</td>\n",
       "      <td>1.192071</td>\n",
       "      <td>0.910988</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.607898</td>\n",
       "      <td>1.196672</td>\n",
       "      <td>0.907305</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.565485</td>\n",
       "      <td>1.196371</td>\n",
       "      <td>0.903622</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.558693</td>\n",
       "      <td>1.173082</td>\n",
       "      <td>0.916513</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.576165</td>\n",
       "      <td>1.165514</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.559584</td>\n",
       "      <td>1.157018</td>\n",
       "      <td>0.920810</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.570680</td>\n",
       "      <td>1.154871</td>\n",
       "      <td>0.920196</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.518353</td>\n",
       "      <td>1.152916</td>\n",
       "      <td>0.921424</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.536917</td>\n",
       "      <td>1.159104</td>\n",
       "      <td>0.918355</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.539845</td>\n",
       "      <td>1.148544</td>\n",
       "      <td>0.920810</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.525857</td>\n",
       "      <td>1.139130</td>\n",
       "      <td>0.921424</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.532696</td>\n",
       "      <td>1.134982</td>\n",
       "      <td>0.922038</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.511543</td>\n",
       "      <td>1.131759</td>\n",
       "      <td>0.921424</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.514707</td>\n",
       "      <td>1.131038</td>\n",
       "      <td>0.921424</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.505446</td>\n",
       "      <td>1.128874</td>\n",
       "      <td>0.921424</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.512719</td>\n",
       "      <td>1.130853</td>\n",
       "      <td>0.922038</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.527143</td>\n",
       "      <td>1.128071</td>\n",
       "      <td>0.920810</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.509807</td>\n",
       "      <td>1.129065</td>\n",
       "      <td>0.920196</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-3\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd, div_factor=25, final_div=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_030\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop 1.5, cutout 0.7, wd=1e-3, LabelSmoothing, mixup, lr5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.5), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.7)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data = get_car_data(dataset='train', tfms=tfms, bs=32, sz=(300, 300), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6515 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1629 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Ford Ranger SuperCab 2011,Toyota 4Runner SUV 2012,Aston Martin V8 Vantage Convertible 2012,Suzuki SX4 Sedan 2012,Audi RS 4 Convertible 2008\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fa0ddab6ea0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.267406</td>\n",
       "      <td>5.062335</td>\n",
       "      <td>0.063229</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.766167</td>\n",
       "      <td>4.138817</td>\n",
       "      <td>0.222836</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.796250</td>\n",
       "      <td>2.711976</td>\n",
       "      <td>0.512584</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.958346</td>\n",
       "      <td>2.077964</td>\n",
       "      <td>0.670350</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.574997</td>\n",
       "      <td>1.902683</td>\n",
       "      <td>0.709638</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.460558</td>\n",
       "      <td>1.957203</td>\n",
       "      <td>0.681400</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.426749</td>\n",
       "      <td>1.978613</td>\n",
       "      <td>0.686925</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.425898</td>\n",
       "      <td>2.251124</td>\n",
       "      <td>0.606507</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.375660</td>\n",
       "      <td>2.055251</td>\n",
       "      <td>0.672192</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.438753</td>\n",
       "      <td>2.298700</td>\n",
       "      <td>0.604665</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.455490</td>\n",
       "      <td>2.624041</td>\n",
       "      <td>0.524248</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.441079</td>\n",
       "      <td>2.449940</td>\n",
       "      <td>0.570902</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.451762</td>\n",
       "      <td>2.209827</td>\n",
       "      <td>0.631676</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.423769</td>\n",
       "      <td>2.114357</td>\n",
       "      <td>0.652548</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.391742</td>\n",
       "      <td>2.206317</td>\n",
       "      <td>0.621854</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.346928</td>\n",
       "      <td>2.026570</td>\n",
       "      <td>0.671578</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.312742</td>\n",
       "      <td>1.931250</td>\n",
       "      <td>0.708410</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.275723</td>\n",
       "      <td>2.023363</td>\n",
       "      <td>0.688766</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.226704</td>\n",
       "      <td>1.893824</td>\n",
       "      <td>0.714549</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.228872</td>\n",
       "      <td>1.825357</td>\n",
       "      <td>0.736034</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.142837</td>\n",
       "      <td>1.826372</td>\n",
       "      <td>0.742173</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.145591</td>\n",
       "      <td>1.771636</td>\n",
       "      <td>0.746470</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.055702</td>\n",
       "      <td>1.663823</td>\n",
       "      <td>0.779619</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.059595</td>\n",
       "      <td>1.635921</td>\n",
       "      <td>0.791897</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.010073</td>\n",
       "      <td>1.672485</td>\n",
       "      <td>0.775936</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.969822</td>\n",
       "      <td>1.546270</td>\n",
       "      <td>0.813382</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.891232</td>\n",
       "      <td>1.558682</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.926777</td>\n",
       "      <td>1.492937</td>\n",
       "      <td>0.836710</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.917305</td>\n",
       "      <td>1.507401</td>\n",
       "      <td>0.821977</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.831613</td>\n",
       "      <td>1.436342</td>\n",
       "      <td>0.852670</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.854348</td>\n",
       "      <td>1.371344</td>\n",
       "      <td>0.860651</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.794134</td>\n",
       "      <td>1.425376</td>\n",
       "      <td>0.839165</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.760867</td>\n",
       "      <td>1.384752</td>\n",
       "      <td>0.858809</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.761452</td>\n",
       "      <td>1.353886</td>\n",
       "      <td>0.869245</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.728609</td>\n",
       "      <td>1.337383</td>\n",
       "      <td>0.873542</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.754104</td>\n",
       "      <td>1.356808</td>\n",
       "      <td>0.868631</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.719821</td>\n",
       "      <td>1.324550</td>\n",
       "      <td>0.873542</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.693889</td>\n",
       "      <td>1.294512</td>\n",
       "      <td>0.885206</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.667001</td>\n",
       "      <td>1.286963</td>\n",
       "      <td>0.891958</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.642935</td>\n",
       "      <td>1.266034</td>\n",
       "      <td>0.899325</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.620760</td>\n",
       "      <td>1.258552</td>\n",
       "      <td>0.884592</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.600690</td>\n",
       "      <td>1.255649</td>\n",
       "      <td>0.892572</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.626197</td>\n",
       "      <td>1.252827</td>\n",
       "      <td>0.892572</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.583126</td>\n",
       "      <td>1.212708</td>\n",
       "      <td>0.907305</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.576912</td>\n",
       "      <td>1.201859</td>\n",
       "      <td>0.899939</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.576804</td>\n",
       "      <td>1.192663</td>\n",
       "      <td>0.911602</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.588048</td>\n",
       "      <td>1.193871</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.542812</td>\n",
       "      <td>1.182459</td>\n",
       "      <td>0.916513</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.542042</td>\n",
       "      <td>1.179569</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.534427</td>\n",
       "      <td>1.162655</td>\n",
       "      <td>0.920810</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.516469</td>\n",
       "      <td>1.158543</td>\n",
       "      <td>0.922652</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.510935</td>\n",
       "      <td>1.159907</td>\n",
       "      <td>0.921424</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.508019</td>\n",
       "      <td>1.149735</td>\n",
       "      <td>0.925721</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.509232</td>\n",
       "      <td>1.151061</td>\n",
       "      <td>0.924494</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.526741</td>\n",
       "      <td>1.152715</td>\n",
       "      <td>0.922652</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.497426</td>\n",
       "      <td>1.149659</td>\n",
       "      <td>0.922652</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.489029</td>\n",
       "      <td>1.150214</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.502664</td>\n",
       "      <td>1.148553</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.515875</td>\n",
       "      <td>1.147830</td>\n",
       "      <td>0.922652</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.519063</td>\n",
       "      <td>1.147654</td>\n",
       "      <td>0.924494</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-3\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd, div_factor=25, final_div=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_031\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop 1.5, cutout 0.7, wd=1e-3, LabelSmoothing, mixup 0.3\n",
    "\n",
    "acc = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.5), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.7)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data = get_car_data(dataset='train', tfms=tfms, bs=32, sz=(300, 300), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6515 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1629 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Ford Ranger SuperCab 2011,Toyota 4Runner SUV 2012,Aston Martin V8 Vantage Convertible 2012,Suzuki SX4 Sedan 2012,Audi RS 4 Convertible 2008\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fa0ddab6ea0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.3, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.3)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.266504</td>\n",
       "      <td>5.083523</td>\n",
       "      <td>0.055249</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.823780</td>\n",
       "      <td>4.208163</td>\n",
       "      <td>0.203806</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.966285</td>\n",
       "      <td>2.819218</td>\n",
       "      <td>0.464088</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.174504</td>\n",
       "      <td>2.127590</td>\n",
       "      <td>0.637815</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.777739</td>\n",
       "      <td>1.827493</td>\n",
       "      <td>0.724985</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.602886</td>\n",
       "      <td>1.929428</td>\n",
       "      <td>0.677716</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.611265</td>\n",
       "      <td>1.959166</td>\n",
       "      <td>0.684469</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.561466</td>\n",
       "      <td>1.977829</td>\n",
       "      <td>0.687538</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.576785</td>\n",
       "      <td>2.160239</td>\n",
       "      <td>0.632904</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.644082</td>\n",
       "      <td>2.198447</td>\n",
       "      <td>0.621240</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.641170</td>\n",
       "      <td>2.181180</td>\n",
       "      <td>0.641498</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.598338</td>\n",
       "      <td>2.094430</td>\n",
       "      <td>0.656845</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.640897</td>\n",
       "      <td>2.226743</td>\n",
       "      <td>0.631676</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.576248</td>\n",
       "      <td>2.398206</td>\n",
       "      <td>0.581952</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.601845</td>\n",
       "      <td>2.323584</td>\n",
       "      <td>0.608963</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.619441</td>\n",
       "      <td>2.086561</td>\n",
       "      <td>0.664211</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.537930</td>\n",
       "      <td>2.094305</td>\n",
       "      <td>0.677103</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.483703</td>\n",
       "      <td>1.886817</td>\n",
       "      <td>0.716390</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.428870</td>\n",
       "      <td>1.953620</td>\n",
       "      <td>0.715163</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.377245</td>\n",
       "      <td>1.791504</td>\n",
       "      <td>0.750153</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.386906</td>\n",
       "      <td>1.700410</td>\n",
       "      <td>0.764886</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.304739</td>\n",
       "      <td>1.690521</td>\n",
       "      <td>0.767342</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.251930</td>\n",
       "      <td>1.765926</td>\n",
       "      <td>0.763659</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.228600</td>\n",
       "      <td>1.658773</td>\n",
       "      <td>0.771639</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.187643</td>\n",
       "      <td>1.648627</td>\n",
       "      <td>0.788827</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.174042</td>\n",
       "      <td>1.564492</td>\n",
       "      <td>0.807244</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.148084</td>\n",
       "      <td>1.518097</td>\n",
       "      <td>0.813382</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.086870</td>\n",
       "      <td>1.421780</td>\n",
       "      <td>0.847759</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.048188</td>\n",
       "      <td>1.561984</td>\n",
       "      <td>0.809699</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.064616</td>\n",
       "      <td>1.385356</td>\n",
       "      <td>0.856967</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.035001</td>\n",
       "      <td>1.406336</td>\n",
       "      <td>0.845304</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.969331</td>\n",
       "      <td>1.378084</td>\n",
       "      <td>0.861265</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.963709</td>\n",
       "      <td>1.336161</td>\n",
       "      <td>0.875384</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.953508</td>\n",
       "      <td>1.356516</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.909586</td>\n",
       "      <td>1.372912</td>\n",
       "      <td>0.866789</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.912535</td>\n",
       "      <td>1.328282</td>\n",
       "      <td>0.868017</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.893669</td>\n",
       "      <td>1.297209</td>\n",
       "      <td>0.883978</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.860714</td>\n",
       "      <td>1.265886</td>\n",
       "      <td>0.891344</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.869175</td>\n",
       "      <td>1.239507</td>\n",
       "      <td>0.898711</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.868820</td>\n",
       "      <td>1.234078</td>\n",
       "      <td>0.904236</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.796199</td>\n",
       "      <td>1.260647</td>\n",
       "      <td>0.892572</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.805196</td>\n",
       "      <td>1.224068</td>\n",
       "      <td>0.899325</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.790794</td>\n",
       "      <td>1.188926</td>\n",
       "      <td>0.912216</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.760109</td>\n",
       "      <td>1.208066</td>\n",
       "      <td>0.912216</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.736044</td>\n",
       "      <td>1.200733</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.747288</td>\n",
       "      <td>1.169833</td>\n",
       "      <td>0.918969</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.724607</td>\n",
       "      <td>1.170568</td>\n",
       "      <td>0.915899</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.741912</td>\n",
       "      <td>1.203744</td>\n",
       "      <td>0.914058</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.744218</td>\n",
       "      <td>1.182402</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.690383</td>\n",
       "      <td>1.157214</td>\n",
       "      <td>0.918355</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.683850</td>\n",
       "      <td>1.144431</td>\n",
       "      <td>0.922652</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.687056</td>\n",
       "      <td>1.152652</td>\n",
       "      <td>0.918969</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.670290</td>\n",
       "      <td>1.150605</td>\n",
       "      <td>0.918355</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.676635</td>\n",
       "      <td>1.153446</td>\n",
       "      <td>0.921424</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.659605</td>\n",
       "      <td>1.145573</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.695671</td>\n",
       "      <td>1.146256</td>\n",
       "      <td>0.921424</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.652722</td>\n",
       "      <td>1.143991</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.667636</td>\n",
       "      <td>1.143918</td>\n",
       "      <td>0.924494</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.634257</td>\n",
       "      <td>1.143309</td>\n",
       "      <td>0.924494</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.668339</td>\n",
       "      <td>1.143511</td>\n",
       "      <td>0.925721</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-3\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd, div_factor=25, final_div=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_033\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop 1.5, cutout 0.7, wd=1e-3, LabelSmoothing, mixup 0.3, lr=5e-3\n",
    "\n",
    "acc = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.5), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.7)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data = get_car_data(dataset='train', tfms=tfms, bs=32, sz=(300, 300), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6515 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1629 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Ford Ranger SuperCab 2011,Toyota 4Runner SUV 2012,Aston Martin V8 Vantage Convertible 2012,Suzuki SX4 Sedan 2012,Audi RS 4 Convertible 2008\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fbc4024eea0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.3, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.3)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.153495</td>\n",
       "      <td>4.735365</td>\n",
       "      <td>0.103745</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.279287</td>\n",
       "      <td>3.265375</td>\n",
       "      <td>0.356047</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.285966</td>\n",
       "      <td>2.252004</td>\n",
       "      <td>0.602210</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.878546</td>\n",
       "      <td>1.970629</td>\n",
       "      <td>0.661142</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.755478</td>\n",
       "      <td>2.073225</td>\n",
       "      <td>0.636587</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.701175</td>\n",
       "      <td>2.384966</td>\n",
       "      <td>0.564150</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.749897</td>\n",
       "      <td>2.377763</td>\n",
       "      <td>0.576427</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.750475</td>\n",
       "      <td>2.753395</td>\n",
       "      <td>0.486188</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.860522</td>\n",
       "      <td>2.464319</td>\n",
       "      <td>0.572744</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.896548</td>\n",
       "      <td>2.681070</td>\n",
       "      <td>0.518109</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.915735</td>\n",
       "      <td>2.614810</td>\n",
       "      <td>0.532228</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.896381</td>\n",
       "      <td>2.386257</td>\n",
       "      <td>0.572744</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.870769</td>\n",
       "      <td>2.959165</td>\n",
       "      <td>0.454880</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.877231</td>\n",
       "      <td>2.656573</td>\n",
       "      <td>0.506446</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.840875</td>\n",
       "      <td>2.447024</td>\n",
       "      <td>0.543278</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.783276</td>\n",
       "      <td>3.003992</td>\n",
       "      <td>0.429711</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.770821</td>\n",
       "      <td>2.282662</td>\n",
       "      <td>0.608349</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.668582</td>\n",
       "      <td>2.319443</td>\n",
       "      <td>0.596685</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.648873</td>\n",
       "      <td>2.105753</td>\n",
       "      <td>0.675261</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.595037</td>\n",
       "      <td>2.153903</td>\n",
       "      <td>0.646409</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.490335</td>\n",
       "      <td>2.000384</td>\n",
       "      <td>0.693063</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.450928</td>\n",
       "      <td>2.688560</td>\n",
       "      <td>0.492327</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.408663</td>\n",
       "      <td>1.775591</td>\n",
       "      <td>0.764886</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.333619</td>\n",
       "      <td>1.699787</td>\n",
       "      <td>0.778392</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.312654</td>\n",
       "      <td>1.629725</td>\n",
       "      <td>0.796194</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.312244</td>\n",
       "      <td>1.618348</td>\n",
       "      <td>0.804788</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.258735</td>\n",
       "      <td>1.772872</td>\n",
       "      <td>0.764886</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.222783</td>\n",
       "      <td>1.604402</td>\n",
       "      <td>0.802333</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.224487</td>\n",
       "      <td>1.561053</td>\n",
       "      <td>0.818293</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.178905</td>\n",
       "      <td>1.471389</td>\n",
       "      <td>0.848373</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.157744</td>\n",
       "      <td>1.511762</td>\n",
       "      <td>0.821977</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.125140</td>\n",
       "      <td>1.465667</td>\n",
       "      <td>0.843462</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.085785</td>\n",
       "      <td>1.437906</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.077959</td>\n",
       "      <td>1.368274</td>\n",
       "      <td>0.864334</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.036908</td>\n",
       "      <td>1.427511</td>\n",
       "      <td>0.857581</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.032339</td>\n",
       "      <td>1.325421</td>\n",
       "      <td>0.871700</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.008816</td>\n",
       "      <td>1.346943</td>\n",
       "      <td>0.874156</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.962671</td>\n",
       "      <td>1.321797</td>\n",
       "      <td>0.885206</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.929941</td>\n",
       "      <td>1.302294</td>\n",
       "      <td>0.890117</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.928973</td>\n",
       "      <td>1.270794</td>\n",
       "      <td>0.898711</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.893616</td>\n",
       "      <td>1.274704</td>\n",
       "      <td>0.891344</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.854272</td>\n",
       "      <td>1.216719</td>\n",
       "      <td>0.910988</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.857031</td>\n",
       "      <td>1.250851</td>\n",
       "      <td>0.905463</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.824081</td>\n",
       "      <td>1.231889</td>\n",
       "      <td>0.906077</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.823787</td>\n",
       "      <td>1.221912</td>\n",
       "      <td>0.914058</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.822783</td>\n",
       "      <td>1.203613</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.794741</td>\n",
       "      <td>1.198833</td>\n",
       "      <td>0.914672</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.789561</td>\n",
       "      <td>1.173531</td>\n",
       "      <td>0.918969</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.778926</td>\n",
       "      <td>1.183437</td>\n",
       "      <td>0.919583</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.768025</td>\n",
       "      <td>1.181300</td>\n",
       "      <td>0.918969</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.734928</td>\n",
       "      <td>1.162619</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.717331</td>\n",
       "      <td>1.152862</td>\n",
       "      <td>0.923266</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.743201</td>\n",
       "      <td>1.156755</td>\n",
       "      <td>0.922038</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.726744</td>\n",
       "      <td>1.151000</td>\n",
       "      <td>0.926335</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.726251</td>\n",
       "      <td>1.144003</td>\n",
       "      <td>0.929405</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.708615</td>\n",
       "      <td>1.143839</td>\n",
       "      <td>0.926335</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.703958</td>\n",
       "      <td>1.143724</td>\n",
       "      <td>0.927563</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.745173</td>\n",
       "      <td>1.145087</td>\n",
       "      <td>0.926949</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.717891</td>\n",
       "      <td>1.146716</td>\n",
       "      <td>0.927563</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.704117</td>\n",
       "      <td>1.144567</td>\n",
       "      <td>0.926949</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 5e-3\n",
    "wd = 1e-3\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd, div_factor=25, final_div=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_034\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 40 Epochs, normalize(imagenet_stats), zoom_crop 1.5, cutout 0.7, wd=1e-3, LabelSmoothing, mixup 0.3, lr=5e-3\n",
    "\n",
    "acc = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.5), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.7)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data = get_car_data(dataset='train', tfms=tfms, bs=32, sz=(300, 300), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6515 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1629 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Ford Ranger SuperCab 2011,Toyota 4Runner SUV 2012,Aston Martin V8 Vantage Convertible 2012,Suzuki SX4 Sedan 2012,Audi RS 4 Convertible 2008\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fbc4024eea0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.3, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.3)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.136203</td>\n",
       "      <td>4.721169</td>\n",
       "      <td>0.109269</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.107844</td>\n",
       "      <td>2.958656</td>\n",
       "      <td>0.402701</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.290184</td>\n",
       "      <td>2.494793</td>\n",
       "      <td>0.526090</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.979613</td>\n",
       "      <td>2.770826</td>\n",
       "      <td>0.456108</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.007500</td>\n",
       "      <td>3.031933</td>\n",
       "      <td>0.404543</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.050385</td>\n",
       "      <td>2.681997</td>\n",
       "      <td>0.471455</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.105515</td>\n",
       "      <td>3.239372</td>\n",
       "      <td>0.392265</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.117231</td>\n",
       "      <td>3.378519</td>\n",
       "      <td>0.336403</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.102044</td>\n",
       "      <td>2.989763</td>\n",
       "      <td>0.427256</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.122391</td>\n",
       "      <td>3.488028</td>\n",
       "      <td>0.319214</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.086718</td>\n",
       "      <td>3.175580</td>\n",
       "      <td>0.379988</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.980826</td>\n",
       "      <td>2.612686</td>\n",
       "      <td>0.508287</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.873186</td>\n",
       "      <td>2.468044</td>\n",
       "      <td>0.558011</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.790735</td>\n",
       "      <td>2.338598</td>\n",
       "      <td>0.600368</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.723048</td>\n",
       "      <td>2.229018</td>\n",
       "      <td>0.615715</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.610479</td>\n",
       "      <td>2.025296</td>\n",
       "      <td>0.680172</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.528302</td>\n",
       "      <td>1.922532</td>\n",
       "      <td>0.715163</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.522595</td>\n",
       "      <td>1.786981</td>\n",
       "      <td>0.751381</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.404865</td>\n",
       "      <td>1.687888</td>\n",
       "      <td>0.785144</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.378444</td>\n",
       "      <td>1.585660</td>\n",
       "      <td>0.799263</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.315062</td>\n",
       "      <td>1.559329</td>\n",
       "      <td>0.817680</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.230869</td>\n",
       "      <td>1.556890</td>\n",
       "      <td>0.817680</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.184558</td>\n",
       "      <td>1.429747</td>\n",
       "      <td>0.852670</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.171194</td>\n",
       "      <td>1.432423</td>\n",
       "      <td>0.847145</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.084162</td>\n",
       "      <td>1.396381</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.041270</td>\n",
       "      <td>1.342561</td>\n",
       "      <td>0.879681</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.035925</td>\n",
       "      <td>1.300666</td>\n",
       "      <td>0.881522</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.975616</td>\n",
       "      <td>1.277750</td>\n",
       "      <td>0.895028</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.948539</td>\n",
       "      <td>1.267252</td>\n",
       "      <td>0.898711</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.908505</td>\n",
       "      <td>1.220886</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.916794</td>\n",
       "      <td>1.224881</td>\n",
       "      <td>0.907305</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.874756</td>\n",
       "      <td>1.193770</td>\n",
       "      <td>0.918355</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.816442</td>\n",
       "      <td>1.191700</td>\n",
       "      <td>0.925107</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.868719</td>\n",
       "      <td>1.181109</td>\n",
       "      <td>0.920810</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.792960</td>\n",
       "      <td>1.175570</td>\n",
       "      <td>0.930632</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.801337</td>\n",
       "      <td>1.173635</td>\n",
       "      <td>0.923880</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.774198</td>\n",
       "      <td>1.167532</td>\n",
       "      <td>0.930632</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.830044</td>\n",
       "      <td>1.166694</td>\n",
       "      <td>0.928177</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.752482</td>\n",
       "      <td>1.165915</td>\n",
       "      <td>0.926949</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.780336</td>\n",
       "      <td>1.166652</td>\n",
       "      <td>0.925721</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 5e-3\n",
    "wd = 1e-3\n",
    "epochs = 40\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd, div_factor=25, final_div=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_035\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B0, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop 1.5, cutout 0.7, wd=1e-3, LabelSmoothing, mixup 0.3, lr=5e-3\n",
    "\n",
    "acc = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.5), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.7)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data = get_car_data(dataset='train', tfms=tfms, bs=32, sz=(300, 300), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b0\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6515 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1629 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Ford Ranger SuperCab 2011,Toyota 4Runner SUV 2012,Aston Martin V8 Vantage Convertible 2012,Suzuki SX4 Sedan 2012,Audi RS 4 Convertible 2008\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1280, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fbc4024eea0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.3, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "  (3): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "  (11): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (12): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (13): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (14): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "  (19): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (20): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (21): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (22): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "  (27): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (28): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (29): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (30): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "  (35): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (36): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (37): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (38): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "  (43): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (44): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (45): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (46): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (51): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (52): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (53): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (54): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (57): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (59): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (60): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (61): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (62): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "  (67): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (68): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (69): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (70): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (73): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (75): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (76): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (77): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (78): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (81): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (83): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (84): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (85): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (86): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (89): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "  (91): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (92): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (93): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (94): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (97): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (99): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (100): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (101): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (102): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (105): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (107): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (108): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (109): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (110): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (113): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (115): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (116): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (117): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (118): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (121): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "  (123): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (124): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (125): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (126): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (129): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Dropout(p=0.5)\n",
       "  (131): Linear(in_features=1280, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b0\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.3)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.186445</td>\n",
       "      <td>4.891098</td>\n",
       "      <td>0.082259</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.503729</td>\n",
       "      <td>3.740111</td>\n",
       "      <td>0.241252</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.647822</td>\n",
       "      <td>2.722270</td>\n",
       "      <td>0.481891</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.098663</td>\n",
       "      <td>2.139467</td>\n",
       "      <td>0.618785</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.839889</td>\n",
       "      <td>2.361413</td>\n",
       "      <td>0.571516</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.843032</td>\n",
       "      <td>2.207134</td>\n",
       "      <td>0.594843</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.764859</td>\n",
       "      <td>2.475400</td>\n",
       "      <td>0.537753</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.887105</td>\n",
       "      <td>2.697722</td>\n",
       "      <td>0.521179</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.875844</td>\n",
       "      <td>2.881434</td>\n",
       "      <td>0.464088</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.909638</td>\n",
       "      <td>2.962913</td>\n",
       "      <td>0.419890</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.902011</td>\n",
       "      <td>2.910778</td>\n",
       "      <td>0.455494</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.938634</td>\n",
       "      <td>2.915372</td>\n",
       "      <td>0.503376</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.937510</td>\n",
       "      <td>3.399860</td>\n",
       "      <td>0.344383</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.907484</td>\n",
       "      <td>2.277827</td>\n",
       "      <td>0.613874</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.863278</td>\n",
       "      <td>3.002165</td>\n",
       "      <td>0.431553</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.828533</td>\n",
       "      <td>2.834379</td>\n",
       "      <td>0.483118</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.810392</td>\n",
       "      <td>2.441270</td>\n",
       "      <td>0.585021</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.779226</td>\n",
       "      <td>2.583429</td>\n",
       "      <td>0.545734</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.674166</td>\n",
       "      <td>2.337313</td>\n",
       "      <td>0.599754</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.583357</td>\n",
       "      <td>2.675117</td>\n",
       "      <td>0.529159</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.584075</td>\n",
       "      <td>2.121308</td>\n",
       "      <td>0.667281</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.532199</td>\n",
       "      <td>1.972398</td>\n",
       "      <td>0.712707</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.436660</td>\n",
       "      <td>2.019005</td>\n",
       "      <td>0.680172</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.446073</td>\n",
       "      <td>1.880927</td>\n",
       "      <td>0.734807</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.389572</td>\n",
       "      <td>1.777086</td>\n",
       "      <td>0.763659</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.392842</td>\n",
       "      <td>1.785815</td>\n",
       "      <td>0.755064</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.314304</td>\n",
       "      <td>1.713354</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.292658</td>\n",
       "      <td>1.724364</td>\n",
       "      <td>0.759975</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.283425</td>\n",
       "      <td>1.641843</td>\n",
       "      <td>0.787600</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.223107</td>\n",
       "      <td>1.586317</td>\n",
       "      <td>0.810927</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.220695</td>\n",
       "      <td>1.612344</td>\n",
       "      <td>0.812155</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.167168</td>\n",
       "      <td>1.540454</td>\n",
       "      <td>0.829957</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.139427</td>\n",
       "      <td>1.536738</td>\n",
       "      <td>0.827502</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.141011</td>\n",
       "      <td>1.460158</td>\n",
       "      <td>0.852670</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.110106</td>\n",
       "      <td>1.441167</td>\n",
       "      <td>0.861265</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.104154</td>\n",
       "      <td>1.448516</td>\n",
       "      <td>0.845918</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.033172</td>\n",
       "      <td>1.429669</td>\n",
       "      <td>0.868017</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2.030737</td>\n",
       "      <td>1.384585</td>\n",
       "      <td>0.870473</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.013593</td>\n",
       "      <td>1.382305</td>\n",
       "      <td>0.881522</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.965042</td>\n",
       "      <td>1.298733</td>\n",
       "      <td>0.902394</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.961968</td>\n",
       "      <td>1.295688</td>\n",
       "      <td>0.897483</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.927205</td>\n",
       "      <td>1.294833</td>\n",
       "      <td>0.883978</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.915658</td>\n",
       "      <td>1.286897</td>\n",
       "      <td>0.895642</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.910650</td>\n",
       "      <td>1.263703</td>\n",
       "      <td>0.903008</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.902579</td>\n",
       "      <td>1.251657</td>\n",
       "      <td>0.909761</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.835436</td>\n",
       "      <td>1.237358</td>\n",
       "      <td>0.914058</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.839297</td>\n",
       "      <td>1.241637</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.855937</td>\n",
       "      <td>1.222826</td>\n",
       "      <td>0.911602</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.803311</td>\n",
       "      <td>1.217796</td>\n",
       "      <td>0.918355</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.853981</td>\n",
       "      <td>1.220042</td>\n",
       "      <td>0.918355</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.816182</td>\n",
       "      <td>1.215118</td>\n",
       "      <td>0.920810</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.760730</td>\n",
       "      <td>1.210936</td>\n",
       "      <td>0.919583</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.785095</td>\n",
       "      <td>1.209359</td>\n",
       "      <td>0.922652</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.797741</td>\n",
       "      <td>1.207603</td>\n",
       "      <td>0.918355</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.785566</td>\n",
       "      <td>1.202885</td>\n",
       "      <td>0.922652</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.793170</td>\n",
       "      <td>1.195681</td>\n",
       "      <td>0.922038</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.781996</td>\n",
       "      <td>1.198770</td>\n",
       "      <td>0.918969</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.773759</td>\n",
       "      <td>1.198970</td>\n",
       "      <td>0.920196</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.776528</td>\n",
       "      <td>1.199029</td>\n",
       "      <td>0.920810</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.791740</td>\n",
       "      <td>1.199112</td>\n",
       "      <td>0.920810</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 5e-3\n",
    "wd = 1e-3\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd, div_factor=25, final_div=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b0_sz300_60epochs_040\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B0, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop 1.5, cutout 0.7, wd=1e-3, LabelSmoothing, mixup 0.3, lr=3e-3\n",
    "\n",
    "acc = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.5), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.7)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data = get_car_data(dataset='train', tfms=tfms, bs=32, sz=(300, 300), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b0\n",
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6515 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1629 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Ford Ranger SuperCab 2011,Toyota 4Runner SUV 2012,Aston Martin V8 Vantage Convertible 2012,Suzuki SX4 Sedan 2012,Audi RS 4 Convertible 2008\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1280, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fbc4024eea0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.3, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "  (3): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "  (11): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (12): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (13): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (14): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "  (19): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (20): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (21): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (22): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "  (27): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (28): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (29): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (30): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "  (35): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (36): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (37): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (38): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "  (43): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (44): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (45): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (46): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (51): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (52): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (53): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (54): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (57): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (59): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (60): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (61): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (62): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "  (67): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (68): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (69): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (70): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (73): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (75): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (76): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (77): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (78): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (81): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (83): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (84): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (85): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (86): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (89): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "  (91): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (92): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (93): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (94): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (97): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (99): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (100): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (101): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (102): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (105): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (107): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (108): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (109): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (110): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (113): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (115): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (116): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (117): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (118): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (121): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "  (123): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (124): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (125): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (126): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (129): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Dropout(p=0.5)\n",
       "  (131): Linear(in_features=1280, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b0\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.3)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.263177</td>\n",
       "      <td>5.107558</td>\n",
       "      <td>0.042971</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.909036</td>\n",
       "      <td>4.375433</td>\n",
       "      <td>0.146102</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.199895</td>\n",
       "      <td>3.171041</td>\n",
       "      <td>0.392265</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.435989</td>\n",
       "      <td>2.355312</td>\n",
       "      <td>0.581952</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.004150</td>\n",
       "      <td>2.092425</td>\n",
       "      <td>0.642726</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.770062</td>\n",
       "      <td>1.949086</td>\n",
       "      <td>0.697360</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.664863</td>\n",
       "      <td>2.141079</td>\n",
       "      <td>0.639042</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.635767</td>\n",
       "      <td>2.117833</td>\n",
       "      <td>0.658072</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.651011</td>\n",
       "      <td>2.084347</td>\n",
       "      <td>0.650092</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.645886</td>\n",
       "      <td>2.141390</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.649668</td>\n",
       "      <td>2.540971</td>\n",
       "      <td>0.581952</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.634799</td>\n",
       "      <td>2.300688</td>\n",
       "      <td>0.591774</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.673123</td>\n",
       "      <td>2.754274</td>\n",
       "      <td>0.489871</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.666374</td>\n",
       "      <td>2.184882</td>\n",
       "      <td>0.635973</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.657019</td>\n",
       "      <td>2.171164</td>\n",
       "      <td>0.651934</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.598729</td>\n",
       "      <td>2.233725</td>\n",
       "      <td>0.647023</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.525481</td>\n",
       "      <td>2.000071</td>\n",
       "      <td>0.705341</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.510898</td>\n",
       "      <td>2.062145</td>\n",
       "      <td>0.679558</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.517400</td>\n",
       "      <td>2.109246</td>\n",
       "      <td>0.672192</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.374446</td>\n",
       "      <td>1.836423</td>\n",
       "      <td>0.742173</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.408368</td>\n",
       "      <td>1.703935</td>\n",
       "      <td>0.785758</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.328464</td>\n",
       "      <td>2.131903</td>\n",
       "      <td>0.664211</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.299542</td>\n",
       "      <td>1.742627</td>\n",
       "      <td>0.761817</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.276937</td>\n",
       "      <td>1.727257</td>\n",
       "      <td>0.781461</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.208793</td>\n",
       "      <td>1.720984</td>\n",
       "      <td>0.773481</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.232925</td>\n",
       "      <td>1.665853</td>\n",
       "      <td>0.798036</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.227834</td>\n",
       "      <td>1.608176</td>\n",
       "      <td>0.812155</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.174150</td>\n",
       "      <td>1.606814</td>\n",
       "      <td>0.815838</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.174199</td>\n",
       "      <td>1.593110</td>\n",
       "      <td>0.820135</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.119617</td>\n",
       "      <td>1.478934</td>\n",
       "      <td>0.836096</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.080723</td>\n",
       "      <td>1.536606</td>\n",
       "      <td>0.840393</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.032709</td>\n",
       "      <td>1.476329</td>\n",
       "      <td>0.848373</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.018005</td>\n",
       "      <td>1.394126</td>\n",
       "      <td>0.865562</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.025004</td>\n",
       "      <td>1.432627</td>\n",
       "      <td>0.864948</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.005816</td>\n",
       "      <td>1.418165</td>\n",
       "      <td>0.869245</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.963072</td>\n",
       "      <td>1.362488</td>\n",
       "      <td>0.872314</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.965847</td>\n",
       "      <td>1.362333</td>\n",
       "      <td>0.883364</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.917064</td>\n",
       "      <td>1.316265</td>\n",
       "      <td>0.896869</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.917340</td>\n",
       "      <td>1.323456</td>\n",
       "      <td>0.884592</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.884306</td>\n",
       "      <td>1.288222</td>\n",
       "      <td>0.898711</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.842236</td>\n",
       "      <td>1.295888</td>\n",
       "      <td>0.899939</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.843614</td>\n",
       "      <td>1.289113</td>\n",
       "      <td>0.896869</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.837879</td>\n",
       "      <td>1.249634</td>\n",
       "      <td>0.909147</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.852561</td>\n",
       "      <td>1.252893</td>\n",
       "      <td>0.905463</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.800744</td>\n",
       "      <td>1.240663</td>\n",
       "      <td>0.905463</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.803099</td>\n",
       "      <td>1.229613</td>\n",
       "      <td>0.910374</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.796835</td>\n",
       "      <td>1.229633</td>\n",
       "      <td>0.909147</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.762928</td>\n",
       "      <td>1.222616</td>\n",
       "      <td>0.916513</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.750958</td>\n",
       "      <td>1.223408</td>\n",
       "      <td>0.909147</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.743998</td>\n",
       "      <td>1.205909</td>\n",
       "      <td>0.915285</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.758300</td>\n",
       "      <td>1.204690</td>\n",
       "      <td>0.920810</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.731856</td>\n",
       "      <td>1.198035</td>\n",
       "      <td>0.925107</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.730992</td>\n",
       "      <td>1.195780</td>\n",
       "      <td>0.923266</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.723275</td>\n",
       "      <td>1.192095</td>\n",
       "      <td>0.926949</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.696975</td>\n",
       "      <td>1.197612</td>\n",
       "      <td>0.926335</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.744160</td>\n",
       "      <td>1.192112</td>\n",
       "      <td>0.926949</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.699242</td>\n",
       "      <td>1.190419</td>\n",
       "      <td>0.928791</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.690545</td>\n",
       "      <td>1.190562</td>\n",
       "      <td>0.928177</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.705488</td>\n",
       "      <td>1.189359</td>\n",
       "      <td>0.928791</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.700334</td>\n",
       "      <td>1.189919</td>\n",
       "      <td>0.928177</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-3\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd, div_factor=25, final_div=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"b0_sz300_60epochs_041\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"exported_models/b0_sz300_09282\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
