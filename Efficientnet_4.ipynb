{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import time\n",
    "import os\n",
    "from helper import get_car_paths, get_cars_df\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_all(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "    elif type(m) == nn.BatchNorm1d:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "def split_effnet(m):\n",
    "    blocks_length = len(m._blocks)\n",
    "    return ([m._conv_stem, m._bn0] + list(m._blocks.children())[:blocks_length//2], \n",
    "            list(m._blocks.children())[blocks_length//2:] + [m._conv_head, m._bn1],\n",
    "            list(m.children())[5]\n",
    "            )\n",
    "def get_effnet(name=\"efficientnet-b0\", pretrained=True, n_class=None):\n",
    "    \n",
    "    assert n_class != None, \"Please specify the number of output classes `n_class`\"\n",
    "    \n",
    "    if pretrained == True:\n",
    "        print(f\"Getting pretrained {name}\")\n",
    "        m = EfficientNet.from_pretrained(name)\n",
    "    else:\n",
    "        print(f\"Getting random initialized {name}\")\n",
    "        m = EfficientNet.from_name(name)\n",
    "    \n",
    "    n_in = m._fc.in_features\n",
    "    m._fc = nn.Sequential(\n",
    "        nn.Dropout(p=0.5), \n",
    "        nn.Linear(n_in, n_class))\n",
    "    m._fc.apply(init_weights)\n",
    "    return m\n",
    "\n",
    "def get_train_test_data(tfms=None, bs=32, sz=224, padding_mode='reflection', normalize=None):\n",
    "    train_path, test_path = get_car_paths()\n",
    "    train_df = get_cars_df('cars_train_annos.mat')\n",
    "    test_df = get_cars_df('cars_test_annos_withlabels.mat')\n",
    "    train_val_data = ImageDataBunch.from_df(train_path, train_df,\n",
    "                                      ds_tfms=tfms, size=sz, fn_col=0, label_col=1, valid_pct=0.2, bs=bs, padding_mode=padding_mode)\n",
    "    test_data = ImageDataBunch.from_df(test_path, test_df,\n",
    "                                      ds_tfms=None, size=sz, fn_col=0, label_col=1, valid_pct=0., bs=bs, padding_mode=padding_mode)\n",
    "    if normalize is not None:\n",
    "        if normalize == \"imagenet\":\n",
    "            train_val_data.normalize(imagenet_stats)\n",
    "            test_data.normalize(imagenet_stats)\n",
    "        elif normalize == \"batch_stats\":\n",
    "            train_val_data.normalize()\n",
    "            test_data.normalize(train_val_data.batch_stats)\n",
    "        else:\n",
    "            print(\"No normalization\")\n",
    "    return train_val_data, test_data\n",
    "\n",
    "def get_learner(databunch, model, fp16=True):\n",
    "    learn = Learner(databunch, model, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "    if fp16: learn.to_fp16()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Untar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path, test_path = get_car_paths()\n",
    "train_df = get_cars_df('cars_train_annos.mat')\n",
    "test_df = get_cars_df('cars_test_annos_withlabels.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=300x300, 20 Epochs, normalize(imagenet_stats)\n",
    "\n",
    "acc = 0.891278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms()\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300,300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0036,  0.0113,  0.0279,  ...,  0.0231, -0.0258, -0.0206],\n",
      "        [-0.0325, -0.0087,  0.0006,  ..., -0.0435,  0.0108, -0.0030],\n",
      "        [ 0.0416, -0.0010, -0.0384,  ...,  0.0164,  0.0056,  0.0534],\n",
      "        ...,\n",
      "        [-0.0491,  0.0066,  0.0417,  ..., -0.0047, -0.0481,  0.0211],\n",
      "        [-0.0211,  0.0488, -0.0081,  ...,  0.0428, -0.0212,  0.0288],\n",
      "        [-0.0225,  0.0208, -0.0377,  ..., -0.0118, -0.0290, -0.0037]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = get_learner(train_val_data, eff_net, fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.076705</td>\n",
       "      <td>4.647521</td>\n",
       "      <td>0.123464</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.693317</td>\n",
       "      <td>1.924430</td>\n",
       "      <td>0.489558</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.645522</td>\n",
       "      <td>2.356622</td>\n",
       "      <td>0.436732</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.650899</td>\n",
       "      <td>3.283628</td>\n",
       "      <td>0.289312</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.500285</td>\n",
       "      <td>2.418230</td>\n",
       "      <td>0.424447</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.343168</td>\n",
       "      <td>2.673287</td>\n",
       "      <td>0.369165</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.153504</td>\n",
       "      <td>2.338114</td>\n",
       "      <td>0.436732</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.025597</td>\n",
       "      <td>3.413372</td>\n",
       "      <td>0.290541</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.899928</td>\n",
       "      <td>2.236967</td>\n",
       "      <td>0.467445</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.769692</td>\n",
       "      <td>1.819411</td>\n",
       "      <td>0.539926</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.634977</td>\n",
       "      <td>1.411595</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.463131</td>\n",
       "      <td>1.338535</td>\n",
       "      <td>0.656634</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.357499</td>\n",
       "      <td>1.218008</td>\n",
       "      <td>0.676904</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.233548</td>\n",
       "      <td>0.797800</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.182491</td>\n",
       "      <td>0.674593</td>\n",
       "      <td>0.825553</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.098016</td>\n",
       "      <td>0.521005</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.057856</td>\n",
       "      <td>0.508971</td>\n",
       "      <td>0.861179</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.041999</td>\n",
       "      <td>0.453307</td>\n",
       "      <td>0.883907</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.028458</td>\n",
       "      <td>0.435915</td>\n",
       "      <td>0.890663</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.028313</td>\n",
       "      <td>0.431806</td>\n",
       "      <td>0.891278</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-1\n",
    "epochs = 20\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300x300_20epochs_normal-imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=300x300, 20 Epochs, normalize(imagenet_stats), zoom_crop\n",
    "\n",
    "acc = 0.901106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms(xtra_tfms=zoom_crop(scale=(0.75,2), do_rand=True))\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300,300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0178,  0.0437,  0.0047,  ..., -0.0637,  0.0454, -0.0054],\n",
      "        [ 0.0510,  0.0463, -0.0109,  ..., -0.0373, -0.0324,  0.0469],\n",
      "        [-0.0769,  0.0438, -0.0188,  ..., -0.0370, -0.0153, -0.0492],\n",
      "        ...,\n",
      "        [ 0.0292, -0.0003, -0.0333,  ...,  0.0025, -0.0236, -0.0471],\n",
      "        [-0.0240, -0.0395,  0.0017,  ..., -0.0302, -0.0120,  0.0135],\n",
      "        [-0.0413,  0.0344,  0.0430,  ..., -0.0167, -0.0475,  0.0610]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = get_learner(train_val_data, eff_net, fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.106598</td>\n",
       "      <td>4.729920</td>\n",
       "      <td>0.100737</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.273760</td>\n",
       "      <td>2.394213</td>\n",
       "      <td>0.410934</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.169043</td>\n",
       "      <td>2.690168</td>\n",
       "      <td>0.356265</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.203341</td>\n",
       "      <td>2.849426</td>\n",
       "      <td>0.320639</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.212690</td>\n",
       "      <td>3.229796</td>\n",
       "      <td>0.277641</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.070830</td>\n",
       "      <td>2.715203</td>\n",
       "      <td>0.338452</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.844345</td>\n",
       "      <td>2.874846</td>\n",
       "      <td>0.313882</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.637539</td>\n",
       "      <td>2.358532</td>\n",
       "      <td>0.415848</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.381504</td>\n",
       "      <td>1.737738</td>\n",
       "      <td>0.549754</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.300062</td>\n",
       "      <td>1.946208</td>\n",
       "      <td>0.524570</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.074841</td>\n",
       "      <td>1.492398</td>\n",
       "      <td>0.605037</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.961650</td>\n",
       "      <td>1.188623</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.796424</td>\n",
       "      <td>1.248578</td>\n",
       "      <td>0.666462</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.632200</td>\n",
       "      <td>0.767869</td>\n",
       "      <td>0.782555</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.504154</td>\n",
       "      <td>0.635153</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.385479</td>\n",
       "      <td>0.537955</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.327031</td>\n",
       "      <td>0.468846</td>\n",
       "      <td>0.871007</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.254795</td>\n",
       "      <td>0.382981</td>\n",
       "      <td>0.896192</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.211391</td>\n",
       "      <td>0.369916</td>\n",
       "      <td>0.901720</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.232014</td>\n",
       "      <td>0.365622</td>\n",
       "      <td>0.901106</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4VFX6wPHvmVRSSSOFAKGXhB66IogKAhaUReyrrrqWn2VXd1nLWnbFtqu7risu9oKgYsECKiiISBOkhR4gQChpkJCEtJk5vz/uJKRnEqYm7+d5eDJz750771ySNyfnvPccpbVGCCGE9zK5OwAhhBBnRxK5EEJ4OUnkQgjh5SSRCyGEl5NELoQQXk4SuRBCeDlJ5EII4eUkkQshhJeTRC6EEF7O1xknDY+I1D27d3PGqYUQolXauHFjrtY6piWvdUoij4pLZMOGDc44tRBCtEpKqYMtfa1TulasMn+LEEK4jFMSucUqiVwIIVxFErkQQng5p/SRl1ZYnXFaIUQrVVFRQWZmJqWlpe4OxekCAwNJTEzEz8/PYed0SiIvLjdzILeYYwUlpHaJxN9XqhyFEA3LzMwkNDSUpKQklFLuDsdptNbk5eWRmZlJ165dHXZepyRygPH/WFH1eN7vRjCmR7Sz3koI4eVKS0tbfRIHUEoRFRVFTk6OQ8/rkqbyta+v44GPt3Awr9gVbyeE8EKtPYlXcsbndEoiT4oK5qc/jWf/7Mn87bJkAnxNLNyYyXnPr+Dtnw9gtkgfuhBCOIpTEnlooC+dIoMwmRTXj0pixYPjuCq1EwG+Jh7/cgc9Hl7C/PWHnPHWQgjRbPn5+bzyyivNft3kyZPJz893QkTN45Kulfjwdjw7fQA7n5zEY5f0IzTAl798uo0HPt5ChbTOhRBu1lAit1gsjb5u8eLFtG/f3llh2c2l5SQmk+KmMV3Z/NhF3HJOVxZuzGTaKz+TXdj6S46EEJ5r1qxZ7Nu3j0GDBjFs2DDGjx/PNddcQ//+/QG4/PLLGTp0KMnJycydO7fqdUlJSeTm5pKRkUHfvn259dZbSU5O5qKLLqKkpMRl8TutaqUxPibFo1P70bNDCI99sZ27P9jEB78bga+PlCkK0dY98eV2dhw95dBz9ksI47FLkhvc/8wzz5CWlsbmzZtZsWIFU6ZMIS0trapE8M033yQyMpKSkhKGDRvGlVdeSVRUVI1z7N27l/nz5/Paa68xY8YMPvnkE6677jqHfo6GuDVzzhzemaem9Wf9gRMMe2oZWaekZS6EcL/hw4fXqPN+6aWXGDhwICNHjuTw4cPs3bu3zmu6du3KoEGDABg6dCgZGRmuCtc9LfLqrhzSkdPlZv66aDsjZn/Pt/eNpXdcqLvDEkK4SWMtZ1cJDg6uerxixQqWLVvGmjVrCAoKYty4cfXegRoQEFD12MfHx6VdK27vy1BKccOoJOZcOwSAe+ZvkrlahBAuFRoaSmFhYb37CgoKiIiIICgoiF27drF27VoXR9c0tyfyShf3j+fJy5LZnVXIB1KaKIRwoaioKMaMGUNKSgoPPvhgjX2TJk3CbDYzYMAAHn30UUaOHOmmKBumtBPmDk9NTdUtWViiwmKl58NL6BsfxpJ7z3V4XEIIz7Rz50769u3r7jBcpr7Pq5TaqLVObcn5PKZFDuDnY+KRKX3ZeewUh0+cdnc4QgjhFexK5EqpDKXUNqXUZqWUU9dwG9vLWLJuVXquM99GCCFajea0yMdrrQe1tOlvr54dQogNC5BELoQQdvKorhUwqljG9IhmdXouVqleEUKIJtmbyDXwnVJqo1LqtvoOUErdppTaoJTacLZz7Z7bM5qTpyvY7uC7u4QQojWyN5GP0VoPAS4G7lJKja19gNZ6rtY6VWudGhMTc1ZBVS5C8VO6YydfF0KI1siuRK61Pmr7mg18Bgx3ZlAdQgPpExfKqr3STy6E8EwhISEAHD16lOnTp9d7zLhx42hJKXZzNZnIlVLBSqnQysfARUCaswM7t2c0GzJOUlLe+DSSQgjhTgkJCSxcuNCtMdjTIo8FVimltgDrga+11t84Nyw4p2cM5RYr6zNOOPuthBCCP//5zzXmJH/88cd54oknmDBhAkOGDKF///4sWrSozusyMjJISUkBoKSkhJkzZzJgwACuuuoql8230uSkWVrr/cBAF8RSw/CkSAL9THz2aybn9Tq7PnchhBdZMguOb3PsOeP6w8XPNHrIzJkzue+++7jzzjsB+Oijj/jmm2+4//77CQsLIzc3l5EjR3LppZc2uO7mnDlzCAoKYuvWrWzdupUhQ4Y49nM0wO2zHzaknb8PE5PjWLEnh3KzFX9fj6uUFEK0IoMHDyY7O5ujR4+Sk5NDREQE8fHx3H///axcuRKTycSRI0fIysoiLi6u3nOsXLmSe+65B4ABAwYwYMAAl8TusYkc4OKUeBZtPsqvh04ysltU0y8QQni/JlrOzjR9+nQWLlzI8ePHmTlzJvPmzSMnJ4eNGzfi5+dHUlJSvVPYVtdQa92ZPLqZO6p7FCYFP+2VMkQhhPPNnDmTBQsWsHDhQqZPn05BQQEdOnTAz8+P5cuXc/DgwUZfP3bsWObNmwdAWloaW7dudUXYHprITxsDnOHt/OiXEMZ7axq/eEII4QjJyckUFhbSsWNH4uPjufbaa9mwYQOpqanMmzePPn36NPr6O+64g6KiIgYMGMBzzz3H8OFOrdSu4nldKz//G5Y+Bn/JhIAQRnWLIu3IKTJPniYxIsjd0QkhWrlt284MtEZHR7NmzZp6jysqKgKMBZjT0oyK7Hbt2rFgwQLnB1mL57XIo3oAGrJ3ADAjtROA3BwkhBAN8LxEHtff+GorP+rRIYSE8ECW7cxyY1BCCOG5PC+Rh3eCwHDIMv5UUUpxYb9Yfk7Po8JidXNwQghnccZqZZ7IGZ/T8xK5UhCbAsfPzAIwvGsUJRUWmQ1RiFYqMDCQvLy8Vp/Mtdbk5eURGBjo0PN63mAnGIl80/tgtYLJxLCuEQD8cuAEgzq1d3NwQghHS0xMJDMzk7OdAtsbBAYGkpiY6NBzemYij0uBimI4eQCiutMhNJCkqCB+yTjBrWO7uTs6IYSD+fn50bVrV3eH4bU8r2sFjBY51JhvYXjXSNbsy6PMLLMhCiFEdZ6ZyDv0BWWqGvAEuKhfHIVlZjZknHRjYEII4Xk8M5H7tYPoXjUGPEd1j8LPR/GT1JMLIUQNnpnIweheqdYiDw7wpVt0COnZRW4MSgghPI/nJvK4FCg4DCVnulK6xQSzJTMfq7V1lygJIURzeG4ij628w/NMq/z8Ph3IKSwjPUda5UIIUclzE3mcrXKlWvdKalIkgAx4CiFENZ6byENiISi6Ros8KSqIqGB/NhyUdTyFEKKS5yZypYxWeda2apsUqUkRbDwoLXIhhKjkuYkcjJkQs3eBxVy1aUjnCA7mneZEcbkbAxNCCM/h2Yk8tj9YyiBvb9Wm/onhAGw7UuCuqIQQwqN4diKvHPCs1k/ev6ORyLcezndHREII4XE8O5FH9wIf/xr95KGBfiRFBbHjmExpK4QQ4OmJ3McPYnrXmDwLoF9CmCRyIYSw8exEDkY/ebWuFYDkhHAO5p0mp7DMTUEJIYTn8PxEHpcCxdlQlF21aVT3KAB+PSRliEII4QWJvOZizAC9Y0MB2HO80B0RCSGER/H8RB5b91b94ABfQgN8Wbozy01BCSGE57A7kSulfJRSm5RSXzkzoDqCIiGsY51+coCtmVJLLoQQzWmR3wvsdFYgjao1NznAtSO7AJBXJAOeQoi2za5ErpRKBKYArzs3nAbEpUDObqgordp0To9oAHZJP7kQoo2zt0X+L+BPgNWJsTQsNgW0BXJ2VW3qE28MeO6UenIhRBvXZCJXSk0FsrXWG5s47jal1Aal1IacnByHBQicqVyp1r0SHRJAdEiAtMiFEG2ePS3yMcClSqkMYAFwvlLq/doHaa3naq1TtdapMTExjo0yshv4BdUZ8OwbH8qu49IiF0K0bU0mcq31X7TWiVrrJGAm8IPW+jqnR1adyQc69Ksz4Nk3Pow9WUWYLe7p8RFCCE/g+XXkleJSjJuC9JmFl3vHhlJutpKRV+zGwIQQwr2alci11iu01lOdFUyjYlOgNB9OHana1DM2BIC9WbIYsxCi7fKiFnndW/V7dDAS+boDsoanEKLt8p5EHptsfK024Bnk70t0iD87jsqApxCi7fKeRB4QChFJNRaZAJjcP560owUy4CmEaLO8J5GD0b1SqwRxaJcITpdbpJ5cCNFmeVcij+0PJ/ZD+ZkqlQGJ7QHYflQm0BJCtE3elcjjUgANWTuqNnWJDCIkwJft0k8uhGijvCuRV81Nfqaf3GRS9IsPI+2ItMiFEG2TdyXy9p0hILzOYszJHcPYeawQi1U38EIhhGi9vCuRK2WUIdYa8ByQGE5JhYU9WTLgKYRoe7wrkYPRT561Haxnyg0HdYoAYPPhfHdFJYQQbuN9iTw2BSqK4eSBqk1JUUG0D/Jj8yFJ5EKItsf7Enk9c5MrpRiY2F5a5EKINsn7EnmHvqBM9faT784q5FRphZsCE0II9/C+RO7XDqJ61pmbPKVjOAA/7nbw6kRCCOHhvC+Rg21u8pqJfFzvGPx8FDtkDU8hRBvjnYk8NgUKDkHJyapNAb4+9IkLY2um9JMLIdoW70zkVQOe22ts7p8YztbMAqxyY5AQog3xzkReeat+7ZkQO0dQWGpmT7bcGCSEaDu8M5GHxkFQdJ25yQd1NmZC3Jop864IIdoO70zkStU74Nk1KpiQAF+ZQEsI0aZ4ZyIHo3sleydYzFWbTCZFckIY76096MbAhBDCtbw3kcf1B0sZ5KXX2Nw5MgitIbeozE2BCSGEa3lvIq8a8KzZT37VsE4AfLnlqKsjEkIIt/DeRB7dC0x+dQY8K+/w/OTXTHdEJYQQLue9idzXH2L61BnwDPTz4aJ+seQVlbspMAc6uAZ++DtYZP4YIUTDvDeRg9FPXmvOFYB+CWEcP1VKmdnihqAcZNtCePdSWPk8LPkTaLnJSQhRPy9P5ClQlAVFNSfK6hJlDHgePlHipsDOgtaw+j/wyS3QMRWG3w4b3oT1r7k7MiGEh/J1dwBnpfpizCHnV23uHBkMwKETxfToEOKOyFrGaoFvH4J1r0K/y2Ha/8DHHwoy4Zs/Q1R36DHB3VEKITyMl7fIbXOu1Oon7xZtJPJ92cWujqjlKkrg498aSXzkXTD9LfALBJMJrpgLHZLh45sgZ7e7IxVCeBjvTuRBkRCaUKcEMSLYn9iwAHZ6y5S2p0/Au5fDzi9h4myYNNtI4JUCQuDq+cYA7wdXGccLIYRNk4lcKRWolFqvlNqilNqulHrCFYHZLS6l3gHPvvFh3jE3+ckMeOMiOLoJfvMWjLqr/uPad4KZH8Cpo/Dh9WBuBVU5QgiHsKdFXgacr7UeCAwCJimlRjo3rGaITYHcPWCueSdnn7gw9uUUUW62uikwOxzdDK9fCMU5cMPnkDyt8eM7DYfLXoaDq2DxA1LJIoQA7Ejk2lBke+pn++c5GSSuP1jNkLOrxuZuMcFUWDRH8z20ciV9Gbw9BXwD4JbvoMto+143YAac+0f49R1YO8e5MQohvIJdfeRKKR+l1GYgG1iqtV7n3LCaoYEBz86RQQBk5HnggOem92HeDIjsCrcshZjezXv9+Eegz1T47mHY851zYhRCeA27ErnW2qK1HgQkAsOVUim1j1FK3aaU2qCU2pCT48IFkCO7gW+7Ov3kvWNDAUjPLqrvVe6hNax4FhbdBV3Hwm8XQ1h8889TWckSmwwLbzZmgRRCtFnNqlrRWucDK4BJ9eybq7VO1VqnxsTEOCg8O5h8ILZfvZUr4e38OJDrIS1yixm+vAdWzIaB18C1H0NgWMvP5x8MVy8A/yCjkqU413GxCiG8ij1VKzFKqfa2x+2AC4Bdjb/KxWJTjERea/Cve0ywZ7TIy4pgwdXw67sw9kG4/BXw8Tv784Ynwsz5xt2tH15XZ8BXCNE22NMijweWK6W2Ar9g9JF/5dywmimuP5Tmw6kjNTb3ig11fyIvyoZ3phqDm1P/Bec/Yqxw5CiJQ+Gy/8KhNfDVH6SSRYg2qMlb9LXWW4HBLoil5aovxhyeWLW5Z2woC345THZhKR1CA10fV246vH+FUV44cz70rtMj5Rj9pxslmD8+awycjrnHMectzoO0hbBjEQy5EQZe5ZjzCiEcyrvnWqkUm2x8zdpWI1mmJBh90NuPnKJDHxcm8tx02DIfNrwBygdu/MpoOTvTebOM2/eX/hWie0Lvi1t2HnM57P3OiH/Pt2CtgMBwY4A2vCMknePYuIUQZ611JPLAMIhIqlOCmGxbZGLbkQLG9+ng3BhKTkLap7BlAWSuB2WC7hNg8nNGZY2zmUxw+RzjTtFPfgc3f2vc9WoPreHYZtg832iBn86D4A4w4nYYeLXxV87rFxh3lN76g1E2KYTwGK0jkYPRvVKrBDEkwJdu0cFsO1LgnPe0mGHf97D5A9i9xFhDNKYvXPgk9J/RstLCs+EfZMzJ8tr5MH+mkXRDGvkFVngctn5oJPCcncZMi70nw6BrjF9CPtW+Pa758Mx5b1l6dhU3QgiHaj2JPK4/7PoayouN0jyblI7hrN6Xh9WqMZkcNMh4fJuR/LZ9ZPR/B0VB6k1G6zV+oGMHM5srLMGYk+WtyUYlyw1fGLMoVqooMa7Tlvmw7wfQVkgcDlNegJQroF1E/eeN6g5XvQfvTTPmSr96gVH6KYRwu9aTyGNTAA1ZO6DTsKrNo7tH8cWWo+zLKaKn7SahFinKhq0fGV0nWduM9UJ7TzKSd48LjZkJPUXHITBtjjEt7pf3Gl0umeuNvxy2fw5lBRCWCOfcb8Qf3dO+83YdC5Ofh6/uN/riJz7l1I8hhLBP60nkcdUWmaiWyId3jQRgw8GTzU/kFaWwZ4nR+k5fBtoCCUNg8j8g5UpjGl1PlTwNcvfC8qdg/3Kj1twvCPpeCoOuhqSxNafKtVfqzZC9C9a8bFTIDLnB8bELIZql9STy9l0gIKzOgGfX6GCigv35JeMEVw/vbN+5ygph+WzYPA9KC4w5z0f/n9F33Nx5Udxp7INGAs/dCxMeg36XQsBZ/FVSaeJsyNtr1K1HdoekMWd/TiFEi7WeRK5UvQOeSinO7RnNd9uzMFus+Po00QrN+Bk+/72xvFrKlUby7nqed/YHKwVT/un48/r4GisYvX6B0Q8vlSxCuJV3rxBUW1wKZG0Ha805yMf36UBRmZndWYUNv7aiFL592JhaVvnATUvgyteh+/nemcSdrV17o5JFW41KllIvWMRDiFaqdSXy2BQoL4L8jBqbh3YxKjFW7W1gYqljW2DuOKPfN/Um+P0q6Ow5a2d4rKjuMONdyEs3KlmsFndHJESb1LoSeVy1W/WrSYwIYmiXCOavP4TVWm0uEosZVj5v1EeXnIRrF8LUF401MoV9up1nVLLs/c6oZBFCuFzrSuQd+hl3VNazhucNo7qQkXean/fZWuW56fDmRPjh70Ylx51roOeFLg64lUi9GYbfbvxF8+u77o5GiDan9Qx2Avi1g6gedeYmB5jQNxaAZduPce7Jz+G7R41l1q58w5h0SpwdqWQRwm1aV4scbHOT122RhwT40s0/nwkb7zQWLu4y2miFSxJ3jMpKlogko5LlxAF3RyREm9H6Enlcfyg4BCX5Z7ZpDVs/4tuAP5Nq2sPG/o/CdZ8Yt7MLx5FKFiHconUmcjDKEMGYU/vjG+HTW/GN7cs1vv/khZPnuHc+lNZMKlmEcLnWl8grF5nISjPm054zCnYthgmPoW7+Bv+YHvycnsdPe124QHRb0+08uPg5qWQRwkVaXyIPjTNmI1z5D/hgBgRFw23L4dw/gMmHxy7tB8C9Cza7OdBWbtgtUskihIu0vkSuFCQMNqaXHXOvkcQru1uA5IRwLuwXy4nictKcNU+5MEycbdwZ+9UfjKkPhBBO0foSOcAlLxkVKRc+aZQY1vLw5L4ATP3PKvY2dtu+ODu1K1nyD7s7IiFapdaZyMM7Qoe+De5Oig4mMaIdABe+uJI1+/LIKSxzVXRtS2Uli6UcPr+jzjw4Qoiz1zoTuR1euyG16vHVr61l2FPL0Fo38grRYlHdYdLTkPETrJvj7miEaHXabCLvGx/Gzicn1di26XB+A0eLszb4emM90GVPQPZOd0cjRKvSZhM5QDt/Hz6/awxPTTNKFu98/1c3R9SKKWWMXQSEwqe3grnc3REJ0Wq06UQOMKhTe64d0YUeHUI4fqqUt39u2a3lZWYLV89dy8o9OazZl8f6AyfYfvTsqmK01pSbW1GfckgMXPqSMRfOj8+4OxohWo02n8grffL70QA89+3uFvWVX/PaOtbsz+OGN9dz9WtrmfG/NUx5aRUFJRUtjun5b3fT65EllJS3orsj+0yBwdfBqhfh0Dp3RyNEqyCJ3CY8yI9Hp/bjdLmFcf9YwezFOzlVal8S3nH0FBsPnqx337dpx1sc0ysr9gHw66H6z+21Jj4N4Ynw2W1QVuTuaITwepLIq7licEcADuadZu7K/Vzxymq7XnfDm+sBeP+WEWQ8M4XNf72Qj24fRWxYAD/uaf5UACeLy+n18JKq5z+nN7CykbcKDINp/4OTB+G7h90djRBeTxJ5NRHB/hx4ejKptqXhfE1NT6yltSa3yKhBP6dnNADtg/wZ3jWSkd2i2GRna/qnvTkkzfqapFlfM/hvSym3nOkbf2XFvtbVVw7GNMJj7oGNbxtz4gghWkwSeS1KKRbeMZrfjk5i1/FC3lzV+ODnoROnAfjzpD519vWND+NoQSn7chruPjiaX8IfPtrM9W+sr7Pvw9tG8tvRSQA89sX2ZnwKLzH+YWOSs0V3Q3Er+6tDCBdqMpErpToppZYrpXYqpbYrpe51RWDudse47gC80UgiLzdbuWf+JgCmDoivs3987w4AfL7pSIPnmPLST3z665n9oQG+zEhNZP/syYzoFsWjU41JvuavP4TF2rxB2KxTpYyYvaxF3Tsu4RtgdLGU5sNX9xnzxgshms2eFrkZ+KPWui8wErhLKdXPuWG5X2xYIFMGxHMkv4TswlLA6LtesTubpFlf8/mmI/R6ZAlbMo0Sw06RQXXO0TsuFID//JBOXlHNKQCKysykHSng5OkzA6obH7mAbU9M5LnpAzHZunV8TIqHJhut/T9+ZP+Mja+t3M+I2d+TdaqMG99cz4Hc4mZ8eheKS4HzH4GdX8KWBe6ORgivpJpbaqeUWgS8rLVe2tAxqampesOGDWcbm9st3JjJAx9vAaBffBg7jtW/4s28341gTI/oevc9s2QXr/5oVJ8ceHoySilOFpcz+G9La7w+JSGc8CC/es9htljp8fASYsMCWPfQBQ3Gu3pfLte8Vn9J33UjO/P3y/vXu8/trBZ4e6pRX37namjf2d0RCeFySqmNWuvUpo+sq1l95EqpJGAw0CYKgK8c0pHkhDCABpP49388r8EkDvDARb2qHleWEVZP4gBjekQ3mMQBfH1MPHBRL7JOlXGyuO4dkRUWK90fWlxvEt8/ezIA6/afaPD8bmfygWlzAA2f3ykTawnRTL72HqiUCgE+Ae7TWtfJakqp24DbADp3bh0tKqUUn9wxmj6PfgPA1/ecQ/eYEJSCAF8fu87h62Ni5YPjGfv8cmZ9so2IYP+qfbeP7cb/Tehp13mG2CppBv9tKTeNSeLwiRIemtyHbjEh3Pz2LzX6z5Oignj1+qH0iTN+Cd0xrjtzVuxj9b5cRnePZl9OEZ0igvD3rft7/HS5mR935zApJQ7lyuXwIpLg4mdh0V2w9hUYfbfr3lsIL2dX14pSyg/4CvhWa/1CU8e3lq4VR3r08zTeW3uw6vkPfzyPbjEhdr++qMxMymONl+nteHIiQf51fzcfKyhh1NM/AHDP+T146Yd0EsID6ZcQxpzrhuLncyah3/TWepbvzmFgYjiL7j7H7vgcQmtYcC2kL4XbfoRYBw7FFB6HtXOgfScY9jvHnVcIB3Fq14oymmVvADvtSeKifn+ZfKY88cu7z2lWEgcICfDl0ztHN7h/cv+4epM4QHx4O8611bi/9EM6AEcLSlm2M5ueDy8hwzYQuvHgSZbvNipctmQWMO755c2K8awpBZf8GwLD4dPbHDOxVv4h+PqP8K8B8PO/jMdrZSpd0bo02SJXSp0D/ARsAyo7Lx/SWi9u6DXSIq/ftswCjuSXMCklzmHnu+TlVQztEsHHt4+qqnSpj9WqmfDCjw1Wr9w1vjv/Xb6vzuNVfx5PYkTdihyn2rUYFlwN5/wBLnisZefI2werXrBVwigYdA2Mvge+f9yokLn0ZRhyvSOjFuKsnE2LvNlVK/aQRO65yswWAnx90FqjlCJp1td1jjnw9GTeX3uQRxcZNyE9P30Av0nt5NpAF90Nm+fBTUug80j7X5e9E376J6R9Aj7+MORG4w7S8ERjv7kM5l8N+36A6W9AypXOiV+IZnJZ1YrwfpWDtJUDmftmT+bJy5Kr9qc/dTFKqRqJ+8GFW9l1vP6qHaeZ9DSEd4LPbocyO9ZVPbrZWBf0lZFGi37U3XDvVpj83JkkDsZNSFe9D51HGd03u79x3mcQwkUkkbdxPibFVcOMpH3lkER8bQOfgX4+ZDwzhfP7GHenzlt7yLWBBYSemVjr20Ym1jq8HubNgLnnwf6VMPZPcH8aXPQ3CI2t/zX+QcY6onH94aMb4MBK53wGIVxEulZEk254cz0r9+SQ8cwU17/50seMQcqrF0Dvi41tWkPGKlj5PBz4EdpFwqi7YPitxkCpvU6fgLcmGwOiNyyCTsOc8xmEsIN0rQin6h1rVNj0b6L80SnGP2RMrPXF/xkTa+1dBm9OgnemQs4uuOgpuG8bjH2geUkcICgSbvjcaLnPuxKObXXOZxDCySSRiyZV3rRUWGbmRD13ljqVbwBcMRdKC+ClIUbCLciEyf+Ae7cYNw4FNK+Us4bQOKM17h8C702D3L2Oi10IF5FELpoUFuhXVcP+0143zKQYmwyTnjHmYLn0P3DPJqMbxa+dY84CUZOFAAAVrElEQVTfvjPc8IVRx/7uZUa/vBBeRBK5sEtKgtFtce+CzXy2KRNrE1PqvrnqAN/vzGrR+qf1GnYL3LEKhtwAvv5NH99c0T3g+s+hvBjevRROHXP8ewjhJDLYKew2/h8ratxQtOtvk3jp+71cNqgj8e0DGfP0DzxxWTL7coqqbigCuH5kF0Z0i2TqgAR3hN08mRuMVnl4Ivx2MQRHuTsi0UbIDUHCJcrMFno/Un/ddWxYAFmnyurdV6mhuWA8zoGfYN50iOkDN37R/EFUIVpAqlaESwT4GrXlB56eXGdf7SQ+e1p//nf9UM7rFVO1rd9fv8Vs8YIparueCzPeg6zt8MFVRneLEB5MWuSiRTZknGD6q2tqbPvl4QuICvbn5OlyokICqraXVliqpgLu3zGcL//PxbMqttT2z2DhzdD1POMGIt+Apl8jRAtJ14pwi2MFJcSEBLB2/wkS2gc2OqOjsX7o94CxqPSIbl7S97xpHiy6E/pMhd+8Az5e0DUkvJJ0rQi3iA9vh6+PiXN6Rjc5LW9sWCD/njkIgKvmrm32QtJuM/hauPg52PWVkdBl9SLhgSSRC5e5bFBHYkKN7onuDy1mT5Ydk2F5ghG3w/mPwtYPYfEfjSkChPAg8neicKn1D02g9yPfUG6xctGLxmRV6x+ewKkSMx9vOExKx3B2HT/F1AEJ9I0Pc3O01Yx9AMqLYNWLxl2mU16Adu3dHZUQgPSRCzc4VVrBgMe/a/K4+y/oxZr9uVw9vDOXDerogsiaoLUx1/ny2RCWANNehSQvGbgVHk8GO4VX2nI4n2e/2cXqfXlNHpv+1MVVU+y6XeZG+PRWOLEfzrkPxj3knLtNRZsiiVx4tYzcYnxMik6RxpJyFRYrE19cyf5qd5G6ZZWixpQVwbcPwa/vQPxAuOJ1iOnl7qiEF5NELlqtcrOVXo8sAeDu8T3440W9qlY38gg7vzKm2K0ogYl/h9RbjMm3hGgmKT8UrZa/r4nBnY1BxZeXp9Pj4SVujqiWvlPhzjXQZTR8/UeYPxOK3DBDpGjTJJELj7fw96OZmGws22axaorKzPUelzTr6xqLSecUlnHJf1aRNOtrzv/nCsrNTqoBD42DaxfCpGdh33KYMwr2uGERDtFmSSIXHs/HpPjf9am8MGMgABNfrLvG5ntrMqoeJ836mr99tYNhTy1j25ECAPbnFNPrkSW8v9ZJc42bTDDy93D7jxASCx/MMFro5aed835CVCOJXHiNK4YkAnAkv4RtmQV8tOEwO4+dQmvN3J/21zj2jVUH6j3HI5+nkXnSicm1Q1+49QcYdTf88rqxKPTRzc57PyGQwU7hZTYdOsm0V1bXu+/SgQn89ZJ+DHtqGVrDwt+PIjUpEgCrVXP5Kz+zNbOAcb1jePum4c4Pdv8K+OwOKM6B8x+G0feAyadl5yovhpMZRsnjif1Gq3/AVTKw2oqczWCn3NkpvMrgzhEMTAxnS2ZBnX03ju5CdEgAB56eUmefyaR47YZURsz+nhW7c/gl4wTDbEneabqNgzt+hq/uh2WPGwtHT3sV2jdQRlmSDycPnEnWJzLOPC46Xvf4wmNwzv3Oi194DWmRC690qrSCsEC/Zr/u/bUHeeTzNMBY4SjQr4Ut5ObQGrbMh8UPgvKBCx8Hv6BqCduWvEtO1HxdaDxEdoOIrhDZ1Xgc2RUikuDrByBtIUz7Hwyc6fzPIJxO6siFsJPWmheW7uE/P6QT3s6PjY9cQEmFhdBAPyxWzeebjjC4c3uC/H2xaE3H9g5a4BmMhP3pbZC53niuTMaScpHdqiXsysdJ4B/U8LnMZcYqRgdXG3Ol97jAcXEKt5BELkQzVS9TBPjTpN48983uOsc9d+UAfpOa6LibkCxmOLIBgqKhfeezu7W/9BS8Ndlozd/0NSQMdkyMwi0kkQvRTPWtcNQYH5Ni198m4ecp871UKjwOr18I5hK45TujNS+8ktzZKUQzpSZFsvT+sVzUL5Y51w6p2v7jg+MAGNolgicuTa7abrFqej68hHX7m57gy6VC4+D6T8FqhvevlLtK26gmW+RKqTeBqUC21jrFnpNKi1x4mxW7s0mMaEePDqE1tldYrHy26Qh/Wri1att394+lV2xo7VO41+H18M6lRh37jV9CQOMrNgnP4+wW+dvApJacXAhvMa53hzpJHMDPx8SM1E7sfepiLujbAYCLXlzJxoMnXR1i4zoNh+lvwrHN8PFvwVLh7oiECzWZyLXWK4ETTR0nRGvm52Pi9RuHMX2ocXfplXNWU1JucXNUtfSZDFNfhPSl8OW9siRdGyJ95EI0w/PTB3BerxgAnlmyk+1HC8g/Xc68dQcpM3tAYh/6WzhvFmyeBz/83d3RCBexq2pFKZUEfNVYH7lS6jbgNoDOnTsPPXjQSZMTCeEBxj63nEMnas7ZcnFKHHOuG9ro69KzC1mz/wQzUhMJ8HXSzUhaGy3yX9+BKf+EYb9zzvsIh3J6+aE9ibw6GewUrd2B3GLG/2NFvftmpCYye1p/issthLfzY9HmI9y7oObEWYM6tefzu8Y4L0CLGT68DvZ8A1e9B30vcd57CYeQRC6EG2itWXfgBP9dns7o7tE8+82uZr3+nZuHV3XTOEX5aXj3Uji2FW5YBF1GOe+9xFlzaiJXSs0HxgHRQBbwmNb6jcZeI4lctEXFZWYWbT7KQ59tq3f/PRN6cue47igFk//9E6UVVr67fyzBAU6cu644D968yJiB8ebvoEMf572XOCtyZ6cQHqbgdAUH8ooJCfAlLjyQkFrJ+peME/zm1TX0iQtl1/FCAHY8OZGj+SV0jwkhp6gMs0WT4Ii5Xk4ehDcuBJOfcfdneMezP6dwOEnkQnihhz7bxgfrDtl17OJ7zqVfQljL3+zYVmNelvad4KYl0K59y88lnEISuRBeqLjMzJVzVhMfHsiJ4vJ651ivrZ2fD2arla2PTaSdfzOrXvavgPenQ6cRcN0n4BfYssCFU0giF6KVKK2wUFhqJsDPxLdpxzFbNRsPnmThxsw6x2Y8U3cBjSZtWwif3AL9LoPpb7V8xSLhcJLIhWjljheU8tIPe2t0xSz7w9h6pxVo0uqX4buHoetY6P8b6DUJQjo4MFrREpLIhWhDsk+VMnz293SLDuaHB8a17CSr/wPr5kLBIUAZc7X0nmz8i+nlyHCFnSSRC9HGVF8Y47qRnenfMZwrhyTi25z50rWGrDTYtRh2fw3Hthjbo3oYCb3PFEgcJt0vLiKJXIg2Jj27kAteWFln+9NX9GfmsE7GIGr7dkxOiWd8nxja+fk0vcpRQSbsXgK7voaMn4w5zoNjoNdE6D0Fuo8HPwcufSdqkEQuRBu0L6eICf/8kZAAX4rKzE0e//ZNwzi3Zwzr9ufRMaIdXaKCGz64tAD2LoXdi42vZafAtx10P9+YZbHXJAiOduCnEZLIhWjjKixW7pm/iSVpx6u2KdX4TLZv3TSM8b3tGOQ0l8PBVbYumCVwKtNYOLrTCGPAtNNw6JgqtelnSRK5EKJRj3+xnbdXZ9TZvvD3o0hNirT/RFobfem7FxsTch3fBtoKKGN1osRhRoLvNAKiuhu/TYRdJJELIZpksWpyi8qIDPZnx9FTXPbfnwHwNSl2PDkJf98WLE9QVghHfjWWmju8DjLXG90yAO0ibUndltwThoB/kAM/UesiiVwI0Wxfbz3GXR/8WvXc38fEq9cPYUyP6Kq50issVopKzUQE+9t3UqsVcvcYSb0yueftNfaZfCGuv5HUK1vu4YnSareRRC6EaLF312Tw10Xba2wLC/Tl/d+N4NKXjVb7OT2imXVxH3rGhjR/QYziPMj8xWitH14PmRvAXGLsC4kzumRiekN0L+NrTJ82OZAqiVwIcVZyi8q47OWfOZJf0uSxC24byTdpx1m2M4t//mYgI7pFNe/NLBVG/frh9XBkI+TsNlrxFdVWXGoXWSu594bo3q26BS+JXAjhMKUVFq57fR0bDp5k2uCOvDBjIE8v2cXclfvrPT46xJ81f5mAX3NuRqrNajWqYXL2QO7uM8k9ZzeUVFv73S8YontWS/J9jBZ9RFcwefcSxJLIhRAusTo9l2teXwfAnGuHcMc8o4995rBOzJ7WH5PJCa3l4lzI2VUzuefugVNHzhwTEAbxA41/CYONf16W3CWRCyFcRmtNmdlKoJ8PFRYr0+esZktmARP6dOCxS5LpGNEOH2ck9NrKCo2EnrUdjm6GY5vheBpYyoz9tZN7/CCI7OaxyV0SuRDCbUorLEx7ZTU7j52q2nbF4I6c1zuGC/rG1lnKrsxsocKiCfb3ocKiW1b22BBLBWTvNJJ6Q8k9bgAkDDISe8Jgj0nuksiFEG63bEcWv3u3+T/3lw9K4IbRScSEBNAp0gl15pYKo2umMrEf3WwMtppLjf3+oRAWD74B4Bto/PPxtz2u3FbreY39tm3KZEwwpnyqPTbZnqsm96mEQZLIhRCeIbuwlJ/Tc9mbVcQrK/Y167UT+nTgmhGdmdA3llOlFZiUItDXxKlSM1sO59M+yI+UjuFnN7AKtuS++0xiL84BS7mR3M1ltq+1nlvKzjx2AvXEKUnkQgjPU5lfCsvM5BSW0T0mpMb+wydO88WWo7y7JoOsU2XNPv+wpAj6xIXx10v6nX1yt5fWtqRfLbGby0BbwGoxpizQtq9W65nnTexT/S6RRC6E8H4fbTjMnxZurXdfTGgAOYU1k32Ar4kysxWAgYnhXDIwgd+kdiK8nR8AJ4rLiQjya3oKXw8gfeRCiFapwmLFbNENLjRtsWqe+3YX//uxbo27r0lhthr5rV98GDtsg7FTBsTz0OS+JIQHelSCl0QuhGjTdh8vZOmO4/SMDeXxL7ZzrKB5/djXjezMxOQ4zBZNp8ggAnxNbM0sIMjfhwO5xcSEBnBB39gGf6FUl5FbzL6cIgJ8fRjeNRJ/XxP5p8v59dBJkqKC6RYTQoXFio9SVXX3VqvGx8fU4kTu2/QhQgjh2XrHhdI7zliIemJyXJ39B3KLSTtSwMhuUfzvx3188msmJ09XVO1/f+0h3l97qM7rahvSuT2PTO3H0fwShnSOYG92Eef0iOa2dzfw/a5su2L1MSkstr8UukUHcyS/pKp7qKWkRS6EaNMqLFae+nonP+3NITkhnI0HT3Ikv4SLU+LwMSkmJsfx3pqDrM840fTJbIZ0bk9+SQX7c4qrtg3tEkF0iD+nSsys2Z9H3/gwKixW0rOLADj47FTpWhFCCGcyW6ws3JjJtiMFHCsopXtMMDmFZezLKWZ410hmXdyH02UWwoP8aryuMsdW74+3WnWN6Qy01phM0rUihBBO5etjYubwzsxs5JjwoLolkPUNqNaek+ZsB13df1+qEEKIsyKJXAghvJxdiVwpNUkptVspla6UmuXsoIQQQtivyUSulPIB/gtcDPQDrlZK9XN2YEIIIexjT4t8OJCutd6vtS4HFgCXOTcsIYQQ9rInkXcEDld7nmnbJoQQwgPYU35YX11MneJzpdRtwG22p2VKqbSzCcwFooFcdwfRBInRcbwhTonRMbw1xi4tPZk9iTwT6FTteSJwtPZBWuu5wFwApdSGlha2u4rE6BjeECN4R5wSo2O0xRjt6Vr5BeiplOqqlPIHZgJfOCoAIYQQZ6fJFrnW2qyUuhv4FvAB3tRab3d6ZEIIIexi1y36WuvFwOJmnHduy8JxKYnRMbwhRvCOOCVGx2hzMTpl0iwhhBCuI7foCyGEl3NoIvekW/mVUhlKqW1Kqc1KqQ22bZFKqaVKqb22rxG27Uop9ZIt7q1KqSFOjOtNpVR29fLMlsSllLrRdvxepdSNLojxcaXUEdv13KyUmlxt319sMe5WSk2stt1p3w9KqU5KqeVKqZ1Kqe1KqXtt2z3mWjYSo8dcS6VUoFJqvVJqiy3GJ2zbuyql1tmuyYe2QgeUUgG25+m2/UlNxe7EGN9WSh2odh0H2ba75efGdn4fpdQmpdRXtueuuY5aa4f8wxgI3Qd0A/yBLUA/R52/BfFkANG1tj0HzLI9ngU8a3s8GViCUTM/EljnxLjGAkOAtJbGBUQC+21fI2yPI5wc4+PAA/Uc28/2fx0AdLV9D/g4+/sBiAeG2B6HAntssXjMtWwkRo+5lrbrEWJ77Aess12fj4CZtu2vAnfYHt8JvGp7PBP4sLHYnRzj28D0eo53y8+N7T3+AHwAfGV77pLr6MgWuTfcyn8Z8I7t8TvA5dW2v6sNa4H2Sql4ZwSgtV4J1F5qpLlxTQSWaq1PaK1PAkuBSU6OsSGXAQu01mVa6wNAOsb3glO/H7TWx7TWv9oeFwI7Me449phr2UiMDXH5tbRdjyLbUz/bPw2cDyy0ba99HSuv70JgglJKNRK7M2NsiFt+bpRSicAU4HXbc4WLrqMjE7mn3cqvge+UUhuVcdcpQKzW+hgYP2RAB9t2d8fe3LjcFe/dtj9V36zssvCEGG1/lg7GaKl55LWsFSN40LW0dQdsBrIxkts+IF9rba7n/apise0vAKJcHaPWuvI6PmW7ji8qpQJqx1grFmf/X/8L+BNQuQBnFC66jo5M5Hbdyu9CY7TWQzBmbbxLKTW2kWM9LfZKDcXljnjnAN2BQcAx4J+27W6NUSkVAnwC3Ke1PtXYoQ3E4/Q464nRo66l1tqitR6Ecdf2cKBvI+/nETEqpVKAvwB9gGEY3SV/dleMSqmpQLbWemP1zY28n0NjdGQit+tWflfRWh+1fc0GPsP4Bs2q7DKxfa1c9trdsTc3LpfHq7XOsv0wWYHXOPPnnttiVEr5YSTIeVrrT22bPepa1hejJ15LW1z5wAqMfuX2SqnK+0yqv19VLLb94RjdcK6OcZKt60prrcuAt3DvdRwDXKqUysDo+jofo4XumuvowE5+X4zBg66cGZBJdtT5mxlLMBBa7fFqjL6w56k5EPac7fEUag6OrHdyfEnUHEhsVlwYrY8DGAM2EbbHkU6OMb7a4/sx+vEAkqk5OLMfY3DOqd8PtmvyLvCvWts95lo2EqPHXEsgBmhve9wO+AmYCnxMzUG6O22P76LmIN1HjcXu5Bjjq13nfwHPuPvnxvY+4zgz2OmS6+joDzAZY2R+H/Cwoy9QM+LoZrsYW4DtlbFg9EF9D+y1fY2s9o3wX1vc24BUJ8Y2H+PP6QqM3763tCQu4GaMgZB04CYXxPieLYatGHPtVE9GD9ti3A1c7IrvB+AcjD85twKbbf8me9K1bCRGj7mWwABgky2WNOCv1X6G1tuuycdAgG17oO15um1/t6Zid2KMP9iuYxrwPmcqW9zyc1PtPcZxJpG75DrKnZ1CCOHl5M5OIYTwcpLIhRDCy0kiF0IILyeJXAghvJwkciGE8HKSyIUQwstJIhdCCC8niVwIIbzc/wNByIRmaQ+kUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-1\n",
    "epochs = 20\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300x300_20epochs_normal-imagenet_zoomcrop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=300, 20 Epochs, normalize(imagenet_stats), zoom_crop\n",
    "\n",
    "acc = 0.893120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms(xtra_tfms=zoom_crop(scale=(0.75,2), do_rand=True))\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=300, normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0718, -0.0658, -0.0117,  ...,  0.0062,  0.0119,  0.0428],\n",
      "        [ 0.0639, -0.0524, -0.0286,  ..., -0.0625,  0.0323, -0.0058],\n",
      "        [ 0.0173,  0.0078, -0.0237,  ...,  0.0203, -0.0095,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0226,  0.0317,  ...,  0.0056,  0.0121, -0.0259],\n",
      "        [-0.0409,  0.0348,  0.0044,  ..., -0.0138, -0.0759, -0.0460],\n",
      "        [-0.0812,  0.0199,  0.0363,  ..., -0.0296, -0.0574,  0.0551]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = get_learner(train_val_data, eff_net, fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.162984</td>\n",
       "      <td>4.837645</td>\n",
       "      <td>0.092752</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.604719</td>\n",
       "      <td>2.849178</td>\n",
       "      <td>0.292998</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.599760</td>\n",
       "      <td>2.689834</td>\n",
       "      <td>0.338452</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.602536</td>\n",
       "      <td>3.171138</td>\n",
       "      <td>0.285012</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.445935</td>\n",
       "      <td>5.683571</td>\n",
       "      <td>0.203931</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.360094</td>\n",
       "      <td>3.398515</td>\n",
       "      <td>0.269656</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.098083</td>\n",
       "      <td>3.075146</td>\n",
       "      <td>0.277641</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.952321</td>\n",
       "      <td>2.017427</td>\n",
       "      <td>0.488329</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.693797</td>\n",
       "      <td>2.166955</td>\n",
       "      <td>0.441032</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.594281</td>\n",
       "      <td>1.539132</td>\n",
       "      <td>0.587224</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.338398</td>\n",
       "      <td>1.550183</td>\n",
       "      <td>0.609951</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.178400</td>\n",
       "      <td>1.262525</td>\n",
       "      <td>0.665848</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.952444</td>\n",
       "      <td>0.962089</td>\n",
       "      <td>0.727887</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.828649</td>\n",
       "      <td>0.802618</td>\n",
       "      <td>0.775184</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.672776</td>\n",
       "      <td>0.600871</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.589866</td>\n",
       "      <td>0.523294</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.438929</td>\n",
       "      <td>0.429421</td>\n",
       "      <td>0.871622</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.355974</td>\n",
       "      <td>0.398829</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.311487</td>\n",
       "      <td>0.387498</td>\n",
       "      <td>0.893120</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.307457</td>\n",
       "      <td>0.386120</td>\n",
       "      <td>0.893120</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-1\n",
    "epochs = 20\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_20epochs_normal-imagenet_zoomcrop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=300, 20 Epochs, normalize(imagenet_stats), zoom_crop(scale=(0.75, 1.5)), cutout, wd=1e-5\n",
    "\n",
    "acc = 0.896192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.5), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 50), p=1.)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=300, normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0718, -0.0658, -0.0117,  ...,  0.0062,  0.0119,  0.0428],\n",
      "        [ 0.0639, -0.0524, -0.0286,  ..., -0.0625,  0.0323, -0.0058],\n",
      "        [ 0.0173,  0.0078, -0.0237,  ...,  0.0203, -0.0095,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0226,  0.0317,  ...,  0.0056,  0.0121, -0.0259],\n",
      "        [-0.0409,  0.0348,  0.0044,  ..., -0.0138, -0.0759, -0.0460],\n",
      "        [-0.0812,  0.0199,  0.0363,  ..., -0.0296, -0.0574,  0.0551]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = get_learner(train_val_data, eff_net, fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.138037</td>\n",
       "      <td>4.810350</td>\n",
       "      <td>0.085995</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.428549</td>\n",
       "      <td>2.572322</td>\n",
       "      <td>0.369165</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.292538</td>\n",
       "      <td>2.466713</td>\n",
       "      <td>0.393120</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.148556</td>\n",
       "      <td>2.913030</td>\n",
       "      <td>0.370393</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.991544</td>\n",
       "      <td>2.971869</td>\n",
       "      <td>0.343980</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.879934</td>\n",
       "      <td>1.947132</td>\n",
       "      <td>0.504914</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.605572</td>\n",
       "      <td>2.170291</td>\n",
       "      <td>0.474201</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.352616</td>\n",
       "      <td>1.413570</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.168514</td>\n",
       "      <td>1.653884</td>\n",
       "      <td>0.608722</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.035978</td>\n",
       "      <td>1.145420</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.781689</td>\n",
       "      <td>0.987156</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.643086</td>\n",
       "      <td>0.779356</td>\n",
       "      <td>0.794840</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.473154</td>\n",
       "      <td>0.661946</td>\n",
       "      <td>0.834152</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.431513</td>\n",
       "      <td>0.726406</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.312205</td>\n",
       "      <td>0.568101</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.248527</td>\n",
       "      <td>0.499229</td>\n",
       "      <td>0.871622</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.186316</td>\n",
       "      <td>0.445250</td>\n",
       "      <td>0.879607</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.157612</td>\n",
       "      <td>0.418952</td>\n",
       "      <td>0.892506</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.149236</td>\n",
       "      <td>0.410351</td>\n",
       "      <td>0.897420</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.113366</td>\n",
       "      <td>0.409558</td>\n",
       "      <td>0.896192</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 20\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_20epochs_normal-imagenet_zoomcrop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=300, 60 Epochs, normalize(imagenet_stats), zoom_crop, cutout, wd=1e-5\n",
    "\n",
    "acc = 0.894349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,2.0), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 50), p=0.8)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=300, normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0718, -0.0658, -0.0117,  ...,  0.0062,  0.0119,  0.0428],\n",
      "        [ 0.0639, -0.0524, -0.0286,  ..., -0.0625,  0.0323, -0.0058],\n",
      "        [ 0.0173,  0.0078, -0.0237,  ...,  0.0203, -0.0095,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0226,  0.0317,  ...,  0.0056,  0.0121, -0.0259],\n",
      "        [-0.0409,  0.0348,  0.0044,  ..., -0.0138, -0.0759, -0.0460],\n",
      "        [-0.0812,  0.0199,  0.0363,  ..., -0.0296, -0.0574,  0.0551]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = get_learner(train_val_data, eff_net, fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.230538</td>\n",
       "      <td>5.041955</td>\n",
       "      <td>0.063268</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.673914</td>\n",
       "      <td>4.156498</td>\n",
       "      <td>0.158477</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.538826</td>\n",
       "      <td>2.655498</td>\n",
       "      <td>0.394349</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.363300</td>\n",
       "      <td>1.641846</td>\n",
       "      <td>0.581695</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.668860</td>\n",
       "      <td>1.246353</td>\n",
       "      <td>0.657248</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.486862</td>\n",
       "      <td>1.369021</td>\n",
       "      <td>0.619165</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.452839</td>\n",
       "      <td>1.622259</td>\n",
       "      <td>0.608722</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.428270</td>\n",
       "      <td>1.586644</td>\n",
       "      <td>0.606880</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.507509</td>\n",
       "      <td>1.902603</td>\n",
       "      <td>0.564496</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.538894</td>\n",
       "      <td>1.748868</td>\n",
       "      <td>0.573710</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.479373</td>\n",
       "      <td>1.676550</td>\n",
       "      <td>0.589066</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.496096</td>\n",
       "      <td>1.583589</td>\n",
       "      <td>0.597666</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.519880</td>\n",
       "      <td>1.678124</td>\n",
       "      <td>0.575553</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.546871</td>\n",
       "      <td>2.445877</td>\n",
       "      <td>0.496314</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.536974</td>\n",
       "      <td>2.040720</td>\n",
       "      <td>0.547297</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.498462</td>\n",
       "      <td>1.959456</td>\n",
       "      <td>0.549754</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.477821</td>\n",
       "      <td>1.924176</td>\n",
       "      <td>0.560811</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.402900</td>\n",
       "      <td>1.718645</td>\n",
       "      <td>0.602580</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.304366</td>\n",
       "      <td>1.807387</td>\n",
       "      <td>0.586609</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.210353</td>\n",
       "      <td>1.673049</td>\n",
       "      <td>0.605037</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.189477</td>\n",
       "      <td>1.541018</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.146438</td>\n",
       "      <td>1.178654</td>\n",
       "      <td>0.708845</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.071912</td>\n",
       "      <td>1.559668</td>\n",
       "      <td>0.633907</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.041054</td>\n",
       "      <td>1.186729</td>\n",
       "      <td>0.705774</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.964352</td>\n",
       "      <td>1.026204</td>\n",
       "      <td>0.733415</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.920367</td>\n",
       "      <td>0.917349</td>\n",
       "      <td>0.764742</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.854073</td>\n",
       "      <td>1.093846</td>\n",
       "      <td>0.740786</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.846986</td>\n",
       "      <td>0.992935</td>\n",
       "      <td>0.772113</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.768981</td>\n",
       "      <td>0.918962</td>\n",
       "      <td>0.781941</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>1.090073</td>\n",
       "      <td>0.756142</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.726132</td>\n",
       "      <td>0.905605</td>\n",
       "      <td>0.781941</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.660624</td>\n",
       "      <td>0.849207</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.605160</td>\n",
       "      <td>0.788578</td>\n",
       "      <td>0.808354</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.574427</td>\n",
       "      <td>0.787735</td>\n",
       "      <td>0.818796</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.556186</td>\n",
       "      <td>0.780725</td>\n",
       "      <td>0.804054</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.484441</td>\n",
       "      <td>0.720600</td>\n",
       "      <td>0.836609</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.503595</td>\n",
       "      <td>0.691928</td>\n",
       "      <td>0.833538</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.449183</td>\n",
       "      <td>0.620871</td>\n",
       "      <td>0.852580</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.444400</td>\n",
       "      <td>0.636338</td>\n",
       "      <td>0.858722</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.413656</td>\n",
       "      <td>0.690580</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.362836</td>\n",
       "      <td>0.608267</td>\n",
       "      <td>0.865479</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.334089</td>\n",
       "      <td>0.608525</td>\n",
       "      <td>0.867936</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.296135</td>\n",
       "      <td>0.617351</td>\n",
       "      <td>0.867936</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.313118</td>\n",
       "      <td>0.607307</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.250490</td>\n",
       "      <td>0.577736</td>\n",
       "      <td>0.867322</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.263472</td>\n",
       "      <td>0.559426</td>\n",
       "      <td>0.883292</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.239074</td>\n",
       "      <td>0.544564</td>\n",
       "      <td>0.880835</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.216326</td>\n",
       "      <td>0.533484</td>\n",
       "      <td>0.881450</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.189636</td>\n",
       "      <td>0.530066</td>\n",
       "      <td>0.891278</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.174645</td>\n",
       "      <td>0.542181</td>\n",
       "      <td>0.888821</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.160277</td>\n",
       "      <td>0.548202</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.167425</td>\n",
       "      <td>0.520838</td>\n",
       "      <td>0.896806</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.155250</td>\n",
       "      <td>0.509723</td>\n",
       "      <td>0.892506</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.157787</td>\n",
       "      <td>0.510292</td>\n",
       "      <td>0.894349</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.133291</td>\n",
       "      <td>0.508858</td>\n",
       "      <td>0.895577</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.133017</td>\n",
       "      <td>0.511153</td>\n",
       "      <td>0.895577</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.158488</td>\n",
       "      <td>0.512154</td>\n",
       "      <td>0.894349</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.139743</td>\n",
       "      <td>0.508872</td>\n",
       "      <td>0.894349</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.133323</td>\n",
       "      <td>0.508054</td>\n",
       "      <td>0.894349</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.124710</td>\n",
       "      <td>0.508635</td>\n",
       "      <td>0.894349</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop, cutout, wd=1e-5\n",
    "\n",
    "acc = 0.897420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,2.0), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 50), p=0.8)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[-0.0224, -0.0289, -0.0377,  ...,  0.0471,  0.0306,  0.0047],\n",
      "        [-0.0432,  0.0205,  0.0051,  ..., -0.0160, -0.0561, -0.0043],\n",
      "        [ 0.0130,  0.0037,  0.0018,  ...,  0.0440, -0.0344,  0.0071],\n",
      "        ...,\n",
      "        [ 0.0261, -0.0173,  0.0615,  ...,  0.0146, -0.0152, -0.0135],\n",
      "        [ 0.0338,  0.0055, -0.0338,  ...,  0.0223,  0.0438,  0.0332],\n",
      "        [ 0.0664,  0.0239, -0.0169,  ...,  0.0450, -0.0068, -0.0538]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = get_learner(train_val_data, eff_net, fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.226843</td>\n",
       "      <td>5.032156</td>\n",
       "      <td>0.062654</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.504771</td>\n",
       "      <td>4.039878</td>\n",
       "      <td>0.171376</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.203168</td>\n",
       "      <td>2.522625</td>\n",
       "      <td>0.442875</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.017522</td>\n",
       "      <td>1.554249</td>\n",
       "      <td>0.605651</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.309885</td>\n",
       "      <td>1.210480</td>\n",
       "      <td>0.681204</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.164529</td>\n",
       "      <td>1.363132</td>\n",
       "      <td>0.642506</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.190534</td>\n",
       "      <td>1.632756</td>\n",
       "      <td>0.589066</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.200058</td>\n",
       "      <td>1.814980</td>\n",
       "      <td>0.565725</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.255345</td>\n",
       "      <td>1.987779</td>\n",
       "      <td>0.552211</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.273188</td>\n",
       "      <td>2.313967</td>\n",
       "      <td>0.494472</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.294974</td>\n",
       "      <td>2.849214</td>\n",
       "      <td>0.400491</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.242515</td>\n",
       "      <td>1.937334</td>\n",
       "      <td>0.550983</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.335960</td>\n",
       "      <td>2.000188</td>\n",
       "      <td>0.534398</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.297346</td>\n",
       "      <td>2.740716</td>\n",
       "      <td>0.435504</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.250138</td>\n",
       "      <td>2.206177</td>\n",
       "      <td>0.520885</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.244090</td>\n",
       "      <td>1.839779</td>\n",
       "      <td>0.560197</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.196170</td>\n",
       "      <td>1.763117</td>\n",
       "      <td>0.572482</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.079156</td>\n",
       "      <td>1.509388</td>\n",
       "      <td>0.643735</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.106616</td>\n",
       "      <td>1.587476</td>\n",
       "      <td>0.612408</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.984774</td>\n",
       "      <td>1.395862</td>\n",
       "      <td>0.678747</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.964243</td>\n",
       "      <td>1.353948</td>\n",
       "      <td>0.689803</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.950050</td>\n",
       "      <td>1.450149</td>\n",
       "      <td>0.661548</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.862877</td>\n",
       "      <td>1.285575</td>\n",
       "      <td>0.675061</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.810621</td>\n",
       "      <td>1.343884</td>\n",
       "      <td>0.701474</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.749127</td>\n",
       "      <td>1.272374</td>\n",
       "      <td>0.713145</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.763454</td>\n",
       "      <td>1.073090</td>\n",
       "      <td>0.735258</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.660155</td>\n",
       "      <td>1.292968</td>\n",
       "      <td>0.707002</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.658839</td>\n",
       "      <td>1.215038</td>\n",
       "      <td>0.742629</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.656683</td>\n",
       "      <td>0.934142</td>\n",
       "      <td>0.766585</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.594021</td>\n",
       "      <td>0.965579</td>\n",
       "      <td>0.779484</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.562569</td>\n",
       "      <td>0.860070</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.510225</td>\n",
       "      <td>0.815714</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.443063</td>\n",
       "      <td>0.865874</td>\n",
       "      <td>0.801597</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.413374</td>\n",
       "      <td>0.806602</td>\n",
       "      <td>0.829238</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.376839</td>\n",
       "      <td>0.713120</td>\n",
       "      <td>0.834767</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.368762</td>\n",
       "      <td>0.743301</td>\n",
       "      <td>0.835995</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.368790</td>\n",
       "      <td>0.703960</td>\n",
       "      <td>0.840295</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.336286</td>\n",
       "      <td>0.764133</td>\n",
       "      <td>0.830467</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.329520</td>\n",
       "      <td>0.751054</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.270106</td>\n",
       "      <td>0.759733</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.260757</td>\n",
       "      <td>0.627577</td>\n",
       "      <td>0.867322</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.244824</td>\n",
       "      <td>0.658245</td>\n",
       "      <td>0.862408</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.219566</td>\n",
       "      <td>0.645216</td>\n",
       "      <td>0.861179</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.209397</td>\n",
       "      <td>0.598939</td>\n",
       "      <td>0.872850</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.183483</td>\n",
       "      <td>0.597560</td>\n",
       "      <td>0.883292</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.166482</td>\n",
       "      <td>0.607830</td>\n",
       "      <td>0.880835</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.147210</td>\n",
       "      <td>0.601896</td>\n",
       "      <td>0.880835</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.165678</td>\n",
       "      <td>0.614693</td>\n",
       "      <td>0.883907</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.142055</td>\n",
       "      <td>0.585072</td>\n",
       "      <td>0.890663</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.113424</td>\n",
       "      <td>0.556837</td>\n",
       "      <td>0.891278</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.119958</td>\n",
       "      <td>0.536782</td>\n",
       "      <td>0.892506</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.113066</td>\n",
       "      <td>0.548717</td>\n",
       "      <td>0.893735</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.115087</td>\n",
       "      <td>0.541275</td>\n",
       "      <td>0.893120</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.090741</td>\n",
       "      <td>0.536124</td>\n",
       "      <td>0.895577</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.099827</td>\n",
       "      <td>0.529403</td>\n",
       "      <td>0.896192</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.095487</td>\n",
       "      <td>0.522916</td>\n",
       "      <td>0.896806</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.100268</td>\n",
       "      <td>0.524297</td>\n",
       "      <td>0.895577</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.079283</td>\n",
       "      <td>0.523010</td>\n",
       "      <td>0.896806</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.095710</td>\n",
       "      <td>0.524758</td>\n",
       "      <td>0.896806</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.109673</td>\n",
       "      <td>0.523739</td>\n",
       "      <td>0.897420</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop, cutout, wd=1e-5, LabelSmoothing\n",
    "\n",
    "acc = 0.920147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,2.0), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 50), p=0.8)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0350,  0.0016, -0.0346,  ..., -0.0598, -0.0003, -0.0370],\n",
      "        [-0.0291, -0.0700, -0.0305,  ...,  0.0328,  0.0039,  0.0126],\n",
      "        [ 0.0060, -0.0149,  0.0303,  ...,  0.0613,  0.0282, -0.0374],\n",
      "        ...,\n",
      "        [-0.0226, -0.0298,  0.0018,  ..., -0.0036, -0.0619,  0.0595],\n",
      "        [-0.0309,  0.0332,  0.0542,  ..., -0.0068, -0.0067, -0.0230],\n",
      "        [ 0.0095, -0.0236,  0.0039,  ...,  0.0379,  0.0808,  0.0179]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Hyundai Sonata Hybrid Sedan 2012,Dodge Journey SUV 2012,Dodge Charger Sedan 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Land Rover LR2 SUV 2012,Geo Metro Convertible 1993,BMW 1 Series Coupe 2012,Toyota Sequoia SUV 2012,Lincoln Town Car Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fa0c9bbf158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.216022</td>\n",
       "      <td>5.032703</td>\n",
       "      <td>0.063268</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.567908</td>\n",
       "      <td>4.070794</td>\n",
       "      <td>0.213145</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.439360</td>\n",
       "      <td>2.772541</td>\n",
       "      <td>0.523342</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.500875</td>\n",
       "      <td>2.059142</td>\n",
       "      <td>0.649263</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.063339</td>\n",
       "      <td>1.902398</td>\n",
       "      <td>0.694717</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.953768</td>\n",
       "      <td>1.926308</td>\n",
       "      <td>0.691646</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.922984</td>\n",
       "      <td>2.111172</td>\n",
       "      <td>0.631450</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.968901</td>\n",
       "      <td>2.280344</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.003443</td>\n",
       "      <td>2.341126</td>\n",
       "      <td>0.591523</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.028057</td>\n",
       "      <td>2.383739</td>\n",
       "      <td>0.582310</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.075699</td>\n",
       "      <td>2.259957</td>\n",
       "      <td>0.604423</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.060998</td>\n",
       "      <td>2.279679</td>\n",
       "      <td>0.621007</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.032094</td>\n",
       "      <td>2.186791</td>\n",
       "      <td>0.635749</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.039738</td>\n",
       "      <td>2.470890</td>\n",
       "      <td>0.562654</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.032121</td>\n",
       "      <td>2.296913</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.976274</td>\n",
       "      <td>2.580434</td>\n",
       "      <td>0.577396</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.918823</td>\n",
       "      <td>2.138559</td>\n",
       "      <td>0.637592</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.900376</td>\n",
       "      <td>2.253967</td>\n",
       "      <td>0.623464</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.815584</td>\n",
       "      <td>2.043659</td>\n",
       "      <td>0.669533</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.791242</td>\n",
       "      <td>1.988131</td>\n",
       "      <td>0.692875</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.745227</td>\n",
       "      <td>1.768930</td>\n",
       "      <td>0.765971</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.670280</td>\n",
       "      <td>1.732695</td>\n",
       "      <td>0.762899</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.630475</td>\n",
       "      <td>1.803429</td>\n",
       "      <td>0.732801</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.620772</td>\n",
       "      <td>1.779127</td>\n",
       "      <td>0.751229</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.567784</td>\n",
       "      <td>1.687083</td>\n",
       "      <td>0.783170</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.561258</td>\n",
       "      <td>1.652454</td>\n",
       "      <td>0.778256</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.486473</td>\n",
       "      <td>1.615573</td>\n",
       "      <td>0.799140</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.450069</td>\n",
       "      <td>1.690093</td>\n",
       "      <td>0.777641</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.429518</td>\n",
       "      <td>1.702384</td>\n",
       "      <td>0.778256</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.417006</td>\n",
       "      <td>1.510582</td>\n",
       "      <td>0.823710</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.356196</td>\n",
       "      <td>1.561611</td>\n",
       "      <td>0.812039</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.361869</td>\n",
       "      <td>1.619273</td>\n",
       "      <td>0.792383</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.316557</td>\n",
       "      <td>1.541809</td>\n",
       "      <td>0.820025</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.284343</td>\n",
       "      <td>1.440077</td>\n",
       "      <td>0.857494</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.267275</td>\n",
       "      <td>1.502886</td>\n",
       "      <td>0.838452</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.241426</td>\n",
       "      <td>1.488699</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.205315</td>\n",
       "      <td>1.432261</td>\n",
       "      <td>0.845209</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.195313</td>\n",
       "      <td>1.424065</td>\n",
       "      <td>0.849509</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.160924</td>\n",
       "      <td>1.357488</td>\n",
       "      <td>0.867936</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.152028</td>\n",
       "      <td>1.368783</td>\n",
       "      <td>0.874693</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.144444</td>\n",
       "      <td>1.317248</td>\n",
       "      <td>0.873464</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.101675</td>\n",
       "      <td>1.297303</td>\n",
       "      <td>0.894349</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.127672</td>\n",
       "      <td>1.308452</td>\n",
       "      <td>0.883292</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.107765</td>\n",
       "      <td>1.255022</td>\n",
       "      <td>0.895577</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.075982</td>\n",
       "      <td>1.246142</td>\n",
       "      <td>0.902334</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.056403</td>\n",
       "      <td>1.229068</td>\n",
       "      <td>0.898034</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.037451</td>\n",
       "      <td>1.220360</td>\n",
       "      <td>0.906634</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.042600</td>\n",
       "      <td>1.211605</td>\n",
       "      <td>0.915233</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.022564</td>\n",
       "      <td>1.215350</td>\n",
       "      <td>0.907862</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.027645</td>\n",
       "      <td>1.198193</td>\n",
       "      <td>0.912776</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.007677</td>\n",
       "      <td>1.194135</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.000400</td>\n",
       "      <td>1.190185</td>\n",
       "      <td>0.914619</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.994150</td>\n",
       "      <td>1.188228</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.993161</td>\n",
       "      <td>1.189327</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.985398</td>\n",
       "      <td>1.186953</td>\n",
       "      <td>0.920147</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.996390</td>\n",
       "      <td>1.184504</td>\n",
       "      <td>0.920762</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.990149</td>\n",
       "      <td>1.185092</td>\n",
       "      <td>0.918305</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.981076</td>\n",
       "      <td>1.182614</td>\n",
       "      <td>0.920147</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.985873</td>\n",
       "      <td>1.183351</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.995531</td>\n",
       "      <td>1.183516</td>\n",
       "      <td>0.920147</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD8CAYAAACINTRsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8VFX+//HXSZ30DgQChKL0JkUQCyIiTVwVFbuurn517V93F/Wnrq7rou66rl9dXSy7q4tYsIvKKlIsCIICCU0IEAhJSEhIJW0y5/fHuWmQMkmmZfg8H495zMydW87NhffcOffcc5TWGiGEEP4hwNsFEEII4ToS6kII4Uck1IUQwo9IqAshhB+RUBdCCD8ioS6EEH5EQl0IIfyIhLoQQvgRCXUhhPAjQe5YaXh0nB568gB3rFoIIfzSxo0bD2utkzq7HreEem1EIs+9vZyJ/RPcsXohhPA7SqlMV6zHbdUv8xd9765VCyGEaIFb69SfX7nbnasXQghxDLeE+sCkSACeWr6TarvDHZsQQgjRDLfUqYeFBPLbucN4+KOtTHj8SzY9NN0dmxFC+ImamhqysrKorKz0dlHczmazkZKSQnBwsFvW75ZQB7h6Yl8e/mgrRUdr+Hb3YSYPTHTXpoQQXVxWVhZRUVGkpqailPJ2cdxGa01BQQFZWVn069fPLdtwW516QIBi26PnAfDPb/e6azNCCD9QWVlJQkKCXwc6gFKKhIQEt/4iceuF0vCQIG6fOpAVO/LILCh356aEEF2cvwd6HXfvp9vvKL1qYl8CleK1tS5pgimEEKIVbg/17tE2Zo1I5u0NB6iplZYwQgjfU1RUxN///vd2Lzdr1iyKiorcUKKO80jfL9OHdae00k76wWJPbE4IIdqlpVCvra1tdblPP/2U2NhYdxWrQzwS6hNS4wH4YV+hJzYnhBDtsmDBAjIyMhg9ejTjx4/n7LPP5oorrmDEiBEA/OIXv2Ds2LEMGzaMRYsW1S+XmprK4cOH2bdvH0OGDOFXv/oVw4YNY/r06VRUVHhlX9zWpLGxbtE2UhPCWb/3CDed6YktCiG6qkc+3sq27BKXrnNoz2gePn9Yi58vXLiQ9PR0Nm3axKpVq5g9ezbp6en1zQ5fffVV4uPjqaioYPz48Vx88cUkJDTt22rXrl0sWbKEl156iUsvvZR3332Xq666yqX74QyPdb07PjWeDZmFOBzaU5sUQogOmTBhQpN25M8++yyjRo1i4sSJHDhwgF27dh23TL9+/Rg9ejQAY8eOZd++fZ4qbhNOnakrpfYBpUAtYNdaj2vvhib0i+edjVnszi/j5O5R7V1cCHGCaO2M2lMiIiLqX69atYovv/yStWvXEh4ezpQpU5ptZx4aGlr/OjAwsEtUv5yttT7coa3s+5apR7cBPVm3t1BCXQjhU6KioigtLW32s+LiYuLi4ggPD2fHjh18/71v90DrmeqXre8R/+2jdIsM4Ye9crFUCOFbEhISmDx5MsOHD+c3v/lNk89mzJiB3W5n5MiRPPjgg0ycONFLpXSOs2fqGvivUkoD/9BaL2prgSbiB6CqSji7fyBr9hWitT5h7h4TQnQNb7zxRrPTQ0ND+eyzz5r9rK7ePDExkfT09Prp9957r8vL5yxnz9Qna61PAWYCv1ZKHdeGRSl1k1Jqg1JqQ35+ftMPEwYCMCWxhJziSrKOeKeuSQgh/J1Toa61zrae84D3gQnNzLNIaz1Oaz0uKemYYfYSzHilo8JNlby0VxdCCPdoM9SVUhFKqai618B0IL31pY4R2wdUIMn2bKJtQayXenUhhHALZ+rUuwPvW3XgQcAbWuvP27WVwGCI64sqzGBc6kw5UxdCCDdpM9S11nuAUZ3eUsJAKMhg9MmxrNyZR2llDVE294z8IYQQJyqP3VFK/AAo3MOIntFoDVtdfBuwEEIIT4Z6wgCoKWdkrLkTa4NUwQghurDIyEgAsrOzmTdvXrPzTJkyhQ0bNniyWB4OdSCh6gAAn6XnemzTQgjhLj179mTp0qXeLkY9j/TSCJjqF4CC3YxKGSht1YUQPuV3v/sdffv25dZbbwXg97//PUop1qxZw5EjR6ipqeGxxx7jggsuaLLcvn37mDNnDunp6VRUVHD99dezbds2hgwZ4pX+XzwX6jEpEBgCBRmcO3Qyf/7vz5RV2YkM9VwRhBBdwGcLIDfNtevsMQJmLmx1lvnz53PXXXfVh/rbb7/N559/zt133010dDSHDx9m4sSJzJ07t8U74l944QXCw8PZsmULW7Zs4ZRTTnHtfjjBc4kaEAjx/aFwD0NHRwOwPaeE8dYAGkII4U1jxowhLy+P7Oxs8vPziYuLIzk5mbvvvps1a9YQEBDAwYMHOXToED169Gh2HWvWrOGOO+4AYOTIkYwcOdKTuwB4MtTBVMEU7GZocgwAy7bkSKgLIZpq44zanebNm8fSpUvJzc1l/vz5LF68mPz8fDZu3EhwcDCpqanNdrvbmLf7tfLchVKAhP5QuJceUSEA5JdWeXTzQgjRmvnz5/Pmm2+ydOlS5s2bR3FxMd26dSM4OJiVK1eSmZnZ6vJnnnkmixcvBiA9PZ0tW7Z4othNeP5MvbYKSrI46+Qk9h4u9+jmhRCiNcOGDaO0tJRevXqRnJzMlVdeyfnnn8+4ceMYPXo0gwcPbnX5W265heuvv56RI0cyevRoJkw4rpsst/NsqFu9NVKQweDkHqzNKKCm1kFwoGd/MAghREvS0hou0iYmJrJ27dpm5ysrKwPM4NN13e6GhYXx5ptvur+QrfBw9UtDs8bBPaKornWwT87WhRDCZTwb6lHJEBwOhXsY3tNcLP1pf5FHiyCEEP7Ms6GulNUCJoMBSZGEBAaQkV/m0SIIIXyT1trbRfAId++n5yuzE/pDwW4CAhQ9YmxkF7fePEgI4f9sNhsFBQV+H+xaawoKCrDZbG7bhudv54wfADuWQa2d5BgbOUXSXYAQJ7qUlBSysrI4bihMP2Sz2UhJSXHb+j0f6gkDwGGHokx6xobJKEhCCIKDg+nXr5+3i+EXvFD9YjVrLNxDcoyN3JJKah3+/ZNLCCE8xfOh3qi3xp6xYdQ6tNxZKoQQLuL5UI9IhNBoKMggOcZcLMgplnp1IYRwBc+HulKmXr0wg8TIUAAOl1V7vBhCCOGPvHN/vtVbY2JUXahL9YsQQriCd0I9YQAUZ5FkMyfu0qxRCCFcw3tn6tpBSOl+EiJCyZMLpUII4RJeOlOv661xN92jQzlUIneVCiGEK3gp1Pub54IMukfb5ExdCCFcxDuhHhYHYfFQmEFYSCBbs0u8UgwhhPA33hudImEgFGRQbXcAUCAtYIQQotO8GOqmC96LT+kFwI7cUq8VRQgh/IX3Qj1+AJRmkxJpRt4uLJcbkIQQorO8e6YO9CEHQFrACCGEC3g91KPKM7EFB5Arg2UIIUSnOR3qSqlApdRPSqlPXLJlq7dGVbiHnjFh5EioCyFEp7XnTP1OYLvLthwaCbZYKDlIcqyNbOmpUQghOs2pUFdKpQCzgZdduvXoXlCSQ/coG3kl0qRRCCE6y9kz9WeA3wKOlmZQSt2klNqglNrg9DiD0clQcpDEqFDyy6r8ftBZIYRwtzZDXSk1B8jTWm9sbT6t9SKt9Tit9bikpCTnth7dE0qySYwModruoKzK7txyQgghmuXMmfpkYK5Sah/wJjBVKfUfl2w9uheU55MYZtqqy2AZQgjROW2Gutb6Pq11itY6FZgPfKW1vsolW49KBjQnhZcBsPlAkUtWK4QQJyrvtVMHc6YODIkwof7eTwe9WRohhOjygtozs9Z6FbDKZVuP7mkKUZYLhFJZU+uyVQshxInIy2fqyea5JJupg7uRJ10FCCFEp7TrTN3lbLEQHA6lOazNKKBCztSFEKJTvHumrpS5WFpykEvHpQBQUlnj1SIJIURX5t1Qh/q26mNT4wHIKZIqGCGE6CgfCHXTVUDPGBuA9AEjhBCd4AOhngyl2fSMCQXkTF0IITrDB0K9FzjsdAsoIUBBjpypCyFEh/lAqFtt1ctz6R5t42CRhLoQQnSU90M9qqGtep/4cPYdLvdueYQQogvzfqhbXQVQks3gHlH8fKgMh0O64BVCiI7wfqhHJEFAEJRkM6xnDGVVdvYcLvN2qYQQokvyfqgHBFg3IGUzJDkagN15UgUjhBAd4f1QB3OxtDSb3vFhAGQdOerlAgkhRNfkG6FunanHhAUTZQtif6GEuhBCdIRvhHp0LyjJRgF9E8LZVyChLoQQHeEjod4Tao5CZTH9EiOlWaMQQnSQj4R6Q1v1+PBg9hcelWaNQgjRAT4S6lZb9dJscq2BMrbnlnixQEII0TX5Rqg3uqv0svG9AaiscXixQEII0TX5XKjHhYeYlxUyWIYQQrSXb4R6UAhEdIOSbGKtUC+qqPZyoYQQouvxjVAHc7G0JJvYsGAAio7KmboQQrSXD4W6aaseHRaMUnCkXM7UhRCivXwo1E1XAYEBioSIEPLLqrxdIiGE6HJ8J9SjkqHiCNRU0C3KRl6JhLoQQrSX74R6o37Vu0WHcqhUxioVQoj28qFQb2jWmBIXRmbBUbSWu0qFEKI9fCjUG87U+8ZHUFppp6zK7t0yCSFEF+M7oV53A1JpNklRoQDkl0q9uhBCtIfvhHpoJITGQElDqOdJqAshRLv4TqiDadZYkk2PGBuADJYhhBDt1GaoK6VsSqn1SqnNSqmtSqlH3FYaK9R7x4UToOCAhLoQQrSLM2fqVcBUrfUoYDQwQyk10S2lsboKCAkKoJfVAkYIIYTzgtqaQZt2hWXW22Dr4Z62htG9oOwQ1NbQNz6CzAIZAUkIIdrDqTp1pVSgUmoTkAd8obVe18w8NymlNiilNuTn53esNFHJgIayQ/RJCCdTql+EEKJdnAp1rXWt1no0kAJMUEoNb2aeRVrrcVrrcUlJSR0rTaO26qkJ4RQdraFYemsUQgintav1i9a6CFgFzHBLaaJ7mueSbPrERwCQWShVMEII4SxnWr8kKaVirddhwDRgh1tK0yjUUxPDAeRiqRBCtEObF0qBZODfSqlAzJfA21rrT9xSmrA4CLJBaTZ94utCXc7UhRDCWc60ftkCjPFAWUCp+rbq4SFBJEWFypm6EEK0g2/dUQoQZUIdIFVawAghRLv4XqhHN4R6H2mrLoQQ7eKDoZ4MpTngcNA3IZxDJVVUVNd6u1RCCNEl+F6ox/SG2moozaFvgrlYKh17CSGEc3wv1HuMNM+5W+ibYLVVlyoYIYRwig+G+nBQAZC9iVTrTH13flkbCwkhhABfDPWQCEg8GXI2ExseAsCTn+/0cqGEEKJr8L1QB0geBTmbAQgPCSQwQHm5QEII0TX4bqiXZkNZHjee0Z9ah5ZBqIUQwgm+G+oAOZvpHRcGwNs/HPBigYQQomvwzVCvawGTs4nZI5MBeGP9fi8WyMd89Rjs/MzbpRBC+CDfDHVbNMQPgJzNhIeY7ml255VRWil9q7N/Hax5ClYt9HZJhBA+yDdDHZpcLK3z7sYsLxXGh6x+wjznbIIiqZISQjTl26FetB+OFrL+gXMAeOnrvV4ulJdlbYCMFTDmavN+xzLvlkcI4XN8N9R7jjbPOZvpFmUjPiKECf3ivVsmd8raCFVt3GS1+gkIi4cZCyFpCOxwT7f2Qoiuy3dDvf5iqamC6ZcYQW5xpRcL5EYHN8LLU2HJfKhtoenmwY2w678w6dcQGglD5kDmt1B+2LNlFUL4NN8N9fB4iO1TH+o9om0cKvHTUF/9lBnxad/X8MWDLc9ji4UJN5n3g+eAdkgrGCFEE74b6mBdLN0EQPdoG7kllWitvVwoF8vZDD9/BmfeCxNvhe//DpuWNJ0ne5OZZ9KvTcsgMH+bmD5SBSOEaMKZMUq9J3k0bP8YKotJjArhaHUtJRV2YsKDPVuO8gLYtdycFZcchFlPQa+xrln36ifBFmPOwIMj4FA6fHwnJA2CXqeYedY8BaExcOrNDcspBYNnw4ZXoaoUQqNcUx4hRJfm42fq1sXS3DQiQ833z8b9hZ7ZduEe+PZv8OoM+PNA+OAWyPoBSnLgX3Pg5+Wd30ZumjnTnnirCfbAIJj3L4jsDm9dBWV5jea5xczT2JA5UFsFu7/sfFmEEH7Bx8/UG7oLmNTfvM4ucmO9usMBGV/BuhcagrLHCDjzNzBopvmSKcuDNy6BJZfDnKdh7HUd396apyA0uukZeEQCzF8Mr0yHt6+BsDgzz8T/OX75PpMgPAG2fwLDLux4OYQQfsO3Qz0yCaJ7QfYm+ow3oVZYXu367VSVweYlsH4RHP7ZnClPuR9GXwGxvZvOG9UdrvsU3rnWVJMUH4Sz7zfVIe1xaBts+9B8YYTFNf0seSRc8By8e4N539w8AAGBMGgWbP0A7FUQFNq+Mggh/I5vhzrU31kaGhRIfESI61vApC2FT+6BqmLoOQYuXGTOeoNCWl4mNBIufxM+uQvWPGnq2c/9AxTvN9U2hXugcK9pbnjqzTDwnOPXseYpCIk0VS/NGTHPfMFsWtLyPABDzoefXoe9a+Ckc9u370IIv9M1Qn3nZ1BdTrXdwYrtefzRVTUN+7+H9//HhPn0x6D3BOfPuAODYe5zZkzVVX+CTYubfh5lOiLjPxfBKdeY9dfViefvhK3vw+l3m6abLTn7fjhrAQS0cumj31nmy2H7x8eHuqMWvvmr9eXRTPWNEMLvdI1QR0NuOmVVdtf1q160H9680rSFv/Lt5qs32qIUTFlg6trzd0B8f+vRz4zgVFNhAv+7/4PdK+D8Z+GkabDmzxAcDpNua3sbrQU6QLDNhPnOT8HxV1MlA1BZAu/eaFrtgBkmMPX09u+jEKJL8e3WL9DQAiZnExeO6QVAraOTbdWrysyFztoaU43SkUBvbNAMOP0uGDrXhGeIGTCb4DA491G44Qtztrz4YnjnOkhfCuNvMBdFXWHwHCjPhwPrzfvCPfDKueZi73mPQ1w/+PDXUC0DeAvh73w/1KN6QEQ3yNlMr1gzYMbGzCMdX5/DAe/fDHnb4JJXIelkFxW0FSnj4OY1cPo95uJoYCicdrvr1n/SdAgMMU0f966Bl6ZC2SG4+n1zw9IFz8ORffDlI67bphDCJ/l+qCtVf7H0qol9Abh18Y8dX9/KP5rwO+9xGDjNRYV0QrANpj1swv2aDyCym+vWbYs2des/vg6vX2ha7/zqK+h/lvk8dTJMuBnW/wP2feO67QohfI7vhzqYUM/bTo9w8/ZwWRXpB4vbv54t78DXfzYXLk/10oXDHiOgz0TXr3foBaYFz8Bppronvn/Tz6c9LNUwQpwAukao9xwNuhYObeWRucMAmPN/3zD1L6uorKl1bh05W+Cj26DPaTDrL+1vV96CjPwyUhcsY3/BUZesr8NGXwnXLYP5bzT0D9NYSERDNcyKRz1ePCGEZ7QZ6kqp3kqplUqp7UqprUqpOz1RsCbq7yzdxDWT+tZP3pNfzuAHP2+7k6/KYnOzUFgcXPpa623Q2+mcv6wGYMbf1tRPW5tRQOqCZdz7zmZ25JbUT5+88CtSFyzj+ZW7Xbb9egEBpnVLXeuX5tRVw6x7EfZ96/oyCCG8zpkzdTvwv1rrIcBE4NdKqaHuLdYxYnqbwSF2forSmg9/PbnJx6t/zm95Wa3ho9vhSCbM+6e5S9VFDpdV1b+eMqhhvZe/9D0ASzdmcfHfv6uf92BRBQBPLd/ZZD35pVXc8K8fqKl1uKxsLaqvhrkVylr5uwkhuqQ2Q11rnaO1/tF6XQpsB3q5u2BNKGVu1Nn9JXzxIKN6x7Jv4Wy+vOdMAPYXtlL1sX6RaXEy7WHoO6lDmy+uqCF1wbL6R12Vz2X/WFs/z8+HzKhFmQVN66vLq2t5+es9jHusodOtUSlNO+Ya/8cvWbEjjzuW/NRk+qUvriV1wTLsrgz7umqYogPw9BB453rYs8q0ChJCdHntqlNXSqUCY4B17ihMq0673XRPu/Y5WPs8AAOSIokKDWLXoRaGgcvaCMsfgJNnwiTnmhBqrevD+4d9pkfIUY/8t8k8r3yzF3utg4x8E+DXT04lI7+Msip7sy1zHlu2vf71yJQYNmcVk11UQXmVndQFDeOMZh2pqH/tcGjWW9vfldfGMHftlToZbvkOxt9oOjB77QL4v1Pg66dNh2VCiC7L6VBXSkUC7wJ3aa1Lmvn8JqXUBqXUhvx8N/ysV8qMzTlkLiy/H9KWopRiSHI0W5ppCaOPFpobfaKS4Rd/b/HOzB25JU2qbz7eklP/+pIX1/Ly13uOW+a7jMP1Z+YAZ52chNYw/OHlbM02f5q9f5rF1kfOa7Lc6zdM4FdnmFYpCz/bwbCHm3bfm3awmBnPrGFtRgH/78P0+um3/GcjeSWVXPvqevJKKkldsIxnvvy5pb+Uc7oNhpkL4X93wkUvmY7TVjwCL5wmQ+QJ0YUpZ0YSUkoFA58Ay7XWT7c1/7hx4/SGDRtcULxm1FSatthZP8BV77JwZ3deXJ3BpofOJTY8hNLKGkb+/nM+Tnie4RUb4JfLIaX5AS0y8svqL3Tu+MMMQoMC6Hffp83O++dLRjFvbAoznlnDjtzS+unL7zqTblGhjPnDF03m37dwNgBbs4uZ/ew3TOwfz5s3meqfxmfndW47eyDPtfMC6te/PZve8eHtWqZVWRtM//HDL4KLFrluvUKINimlNmqtx3V2Pc60flHAK8B2ZwLd7YJtcPkbkDAQ3rqKkxx7Ac20R5eSsX4Zf/nDPTwf/CzDy9fCeX+sD/RpT68mdcEycopNFUdNraM+0AEe+Xgbn6bl1r9/++am9e/zxqYANAl0gIHdIomLCOG601KxBQdw5al9WH7XmfWfD+sZw76Fs+sDHWBCakMnXrdPHci+hbO5c9pJze5uUEDLTS/PeHIlT/93J794/lvW7TEtblbtbKg+WbUzj9QFy9iWfdwPq+aljDPXLra8JQNvCNFFtXmmrpQ6HfgaSAPqrqbdr7Vu/pQWN5+p1ynOgpfPRVeXUVipSVANYXtER/JB7WTmP/gGYaFB1NQ6OOmBhgGa034/nXV7CrnxtebL+NFtkxmZEsuHmw5y55ubWPG/ZzEgKRIwdd2DH/qcaruDZXeczrCeMc2uozVaa97ZmMVvl25h+6MzCAsJrJ9e90thUv8EXrx6LJkF5cx9zvnmh4N7RPH5XWey93A5Z/95Vf30ul8ObaqphBdPNyMq3fp9Qz82Qgi3ctWZulPVL+3lkVAHyNsOXz1GTWgcf9oAO3UKPzt6UxmaQGmVaaHywwPTePCDdD7fmtvsKhbfeCpXvtz0uq/TAeghddU1GY/PIrekktiwYC5+4bvjfjXUeemacfzqmC+sdu1T5nfwz5mmF8nz/tjhcgshnCehfowDhUeZ/tc1nNQ9kqcvHc20p1cfN8/sEcksS8tpMm3fwtkcKa+urxO/d/rJ3Da1+aoQX6K1Zu2eAvJLq5g9IpkPN2Xz4eZs1hzTZr9XbBgHiyp47oox9IoN40Kr3fyfLhrB5RP6tLyBj++CH/8NN37pukG2hRAtklBvw9s/HOC3726pf3/daak8OGcoA+431Rv/c9YArp+cSvdom7eK6HJlVXaGN2pRs/mh6fxh2TaWbsxqdv4fHphGUpQZAu+Ndfu5//20houvlcXw3ASISIKbVppBQYQQbiOh7qTP03NIiQtneC9T9/1dxmEKyqo5f1RPL5fMPX75rx/4aoe5WFpX5dJcaxswZ/HfLpjK0Wo7Qx9q+DKor6rZ/jG8dRWc8zCccU/bGz+0Fb79mxmgo9sQ6DbUPCee7NKuGYTwR64Kdd8f+aiTZgxPbvL+tAGJXiqJZ7xy7Tjufz+Nh88fVj8tNjyYoqM1AIQFB7LxwWkMfWg5B4sqSD9YzEON2sSDqdpRSpnxT4ecD6ufMINhp57R/ODWedth1ULY9gGEREFMCuz+AhzWKFUBQZA02AzPN9i3rlcI4W/8/kxdGDnFFezMLWXKINOP+/X/XM/Knc3Xv//z+vGcbc1HSQ7Vz59GSFUhBIWZboP7nWmNjRpuBtBOf8+0kjn1ZnNxNTwe7NVQsNsMRpK3zYwzm7cNhs+DmU+6btQnIfyEVL+ITqmormXIQ583mfbXy0Zx91ub699/ducZ5BRXcMe/1nB+zB7+NPqIGVkpb2vDQsERcOpNphuG1oLaXg3fPgOrnzQDcM96CoZd6LIukIXo6iTURafd8p+N5JdW8fbNkyivthMWHMjARu35j7Xt0fMY+tByEilmYsA2zuhRw2U3/AYi2lGldWirGagj+ydTtTPzSYjuxPWNvO3mF0D5YTNOa1meeR1sg5lPyS8C0WVIqAu3qLLXMuGPKyiuqDnus5O7Rzbp8wZMHzeqvWfbtXbTMdvKx81NTt2GQt/JpqOxvqc71z1y/k746g/mYm4dFQDhiabFTsEuGHAOXL5Efg2ILkFCXbjV/oKjnPnUSgDunzWYxz/d0eTzlLgwso5U8Lf5o7nzzU2EhwSy8t4prNyRxyXjehPYSvcG9QoyYOv7kPkt7F8HNVa3xYmDTL19/ylm4I+w2IZlirNg1Z9g0xum6ue0280Zf2Q3MwhK3SAh378Any8wvwROvbnzfxAh3ExCXXhU42aRe/80i58OFHGRdSNTcxp3NlZWZeedDQe48tS+hAS10N1QbQ1kb4LMb8zg2JlrTcirAOg5xlyYtVfBDy8DGsb/yjSzbKnqR2tYMt90LXzjCtN6x1lamzJUl8NJ01vs4VMIV5JQFx5VU+vgQOFR4iNCiA03bc5bav/emvduPY2UuDCibcHYglsZes9eDQc3wJ7VZhCPgxtAO2DU5TBlAcS2cjdsnfICeHGyaZlz02oIjWx9/ooi2PwmbHgFDltdGyePhumPQb8znN5HITpCQl143ZasIj5Ny+V3MwZR69D88t8b+H+zhzD9r2vaXhiY2D+e7/cUsufxWQRY1TWVNbU899Vu7j735KZVOFWl5sw5qkf7Crl3Dfx7Loy+wvSr35zsTSbI05ZCzVHoNQ7G32B+JXz1GBQfMAOtnPsIJA1q3/aFcJKEuvBZ3+0+zBOf72BzVsPgJe/delrV8CxiAAAQGUlEQVSL1TV9E8L59/UTCAxQnPGkqce/dlJfHrlguGsK9NVjpj39RS/DyEvMtJJsSHsHNr9lmmgGhZnPxt0APUc3LFtTYQbq/vpp86VyyjUw9UFpVSNcTkJd+DytNVV2R301S/HRGkY9+t82lmrgskFAau3wr9mmOeW0h2HHMlOlg4aU8TDyMhhxSdMLsscqLzB31m54xbSwuWgR9D+r82UTwiKhLrq0rCNHSYkLb7NeftqQboQGBbI9t4Q9+eV8ec9ZDOzWRt14c4r2m37iK4shti+Mmm/CPGFA+9aTswWW/tLcLXvGPTDlvuM7O9MaMlbA+pfN9qJ6mGEV655je5svk4BWrimIE46EuvAbjYP90zvOYGjP6CYdkx1r5b1T6JcYgdaaZWk5nDu0O6FBTgRk3nbT2VjvCZ1ru15dDp/9Dn563YTzxS9DXKppnZP2jhkYPW8bRHY3I3SV5kJpjqmvrxPT21TljLkaopNb3JQ4cUioC79T35EYUOvQ/P6jrbz+fWaz875+wwSufmU9AFG2ILY8PL1+2ZziCuLCQwgNCmj/jVHtkf6e6XcebS7Epr8H5XnQbRhM+jWMmNfQAZrW5mJvaS4cSoMfXzNVQCoQBs2EcddD/6nSfPIEJqEuThgOhyYgQOFwaPrf3+IoiscZ3iuaT24/o0ld/vu3nsaYPnGuK9yRTHj3Rshab+5gPe026H+2c78ECjLMQCQ//QeOFpjeLG0xEBoNtmjzHBZn+sgZeoFU1/g5CXVxQsorqWTC4yvq3z9z2WjuemtTu9aR/sh5RIa6sNdpR62pOw+Pb3ve5tirYMcnkJtmqoeqShqeiw5ASRbED4DT74KR86Vvej8loS5OWFprtmaX1A98Ul5lZ9jDyxncI4rfnDeIUb1j+cfqDF76em+r6/ndjME88fmO+nr8xtIPFqMUHRpY3KUctaZ/m2+ehpzNEN3LdI0w4hJTnXO0EI4eNp2YVRyBHiNMv/dSjdPlSKgL0Yb/90EaX23P4+zB3Zg8MJEZw3q0Wn0zolcMaQeLW/z858dmttzNgbvVtaj5+mnTV05rolNg1GXmrD7pZM+UT3SahLoQHfDKN3v5wyfbOrRsYICi1qFZdsfp3j2D37/O1OGHxZu+b8ITzCM0GvasNF0dZKww3Sr0GgvDLoLuQ00VTkxKy3XzDgfYK83gJ8LjJNSF6KTMgnJS4sJZlpbDHUt+qp/++g0T6BZlIyUujGGNBvJuyVPzRtI/KZKxfV14AbazSnNNtwebl8ChRsMVBoaY5pfxAyAwyKq+KbCqbwrNF0Hf02HMVTB0ruk3R3iEhLoQHvTGuv3c/35ah5bNeHyWc10Ru0tJtmlpU5gBhXvMo2CPCfDwBHOBt+6MX2vY+p6ZJyQKhl9o2tKnjJd+6d1MQl0IL6isqWVfQTlzn/uWarujXcveNe0kTuoWxZqf83n8ohHeDfrWaA3715qmlls/MF0g22JN+NtiGj1izahVMb3NXbIxvU31zrF32AqnSKgL4UMOFB7ljjd/otruYGt2CQCrfzOFs55a5dTyn9x+en1rHnutg6DAABwO838zwJvhX1Vqgj37R9PMsrIYKovMc8URM4RgE8oMWGKLPeYL4JhHmPV5SKTpS7+2ynS3XPccEm66V47p3XqfPH5EQl2ILmD1z/lc++r6Tq2jLvBn/e1rtuWUeLcVzrHsVWY0quIDpk190X7TJUJV3ReA9agoMtMc9vZvIzTaCvgUU8cfGGra6gfZzDWCoFDzCKx7tqYFBJuLwgGB5sYuZb3WjuMfKsDMU79MkHkE1r0PbnivlPk1ozVQ90wzywWZ9dbNUz9/o194jfJXRfeQUBeiK6nrBmFHbgkznvm6U+u6f9ZgzjgpiX6JEeSXVuHQmojQINIPFjNlUDcAM86shphwH6kO0dr0f9M47KvKzAXbuqCuC+a6G6+KrS+KupuwairMmby90jqrrzKv/YB6pERCXQh/UVlTyx+XbSc1MYJrJ/Ul7WAxtuBAFq/L5D/f7+/0+r9bMJWesWFUVNfy1Y48Zo/0o07EtG6mCqfK/Cpw1JpnXfeszZm2Cmh4oABrHXXzO2rMe+2wplvTHLXmoQKsC8eq4QJy42UddtPls65t2EbdduGYi87mtZpwo4S6ECcCh0Pzn3WZTDm5Gz1jbVz1yjq+31PYqXWOTInh+StOadJf/aMfb+PVb/fy9s2TmNAvHq01D3+0ldfWZvL0paO46JSUzu6KaIXUqQtxgqv7v9u4J8qM/DLO+ctqZgzrwdQh3bh0XG+ufmUdX+863OntPXPZaM4d2h27Q/OP1RmM7RvHOUO6d3q9wvBYqCulXgXmAHlaa6fGF5NQF8J3aK2pqKklODCAoABFWZWdm17byNo9BcfNe+m4FN7ekNWu9a+7/xy6R9v4cf8R8koqOeOkJKrtDuwOTVJUaJvL22vNvK0ORH4C8GSonwmUAa9JqAvhX0oqazh4pIIhyQ0dmlXW1FJSWcO27BJOH5hIUGAAS9bv5773OnbzVZ3Y8GCKjta0Os+MYT148eqxzX6WV1qJQjn1RdEVebT6RSmVCnwioS7Eia3xQCbVdgdXvPQ9GzKPuGVbI1NisNdqtuWUHPfZzOE9uG3qQEoq7Lz67V6+2HYIMF02nDUoiaTIUKrsDl5fm0lcRAhj+8bRL7FzXR5orTlaXUtEaBBaazILjpLqxDob/81aI6EuhPAZtQ593B2yWmu0hkp7LVuzSyirtDO+XzyfpeVw8TEXXQ+XVfHMil2kZRW32lOmK0XZgiitbLndfL/ECPYeLm9zPaNSYjhcVs3Booom0yf1TziuiuupeSOJsgXz8EfpHCqpAiAiJJDy6loyn5jjW6GulLoJuAmgT58+YzMzmx+GTAghWuNwaP753T5+3H+EnKIK7j73ZE4fmFj/BXG0upaFn+1g6UZT9//I3GFM6BfP3sPl3Lr4xybrGp8axw/73PNLwtV8LtQbkzN1IYSvqaypRSkIVIq0g8UMSY4mv7SKpKhQtAZbcABam24ZyqvsbMw8QkxYMKN6N+2m4Gi1nbDgQJRSZOSXUVJRQ9+ECLZmFxNtC2ZIcrTpojkth8TIEKYM6sbuvDJiw4O5/700/rvtEDOH9+Cy8b0JCQogMjSIZ1fs4pXrJkioCyGEv3BVnXqbHUgopZYAa4FBSqkspdQNnd2oEEII92hz9F2t9eWeKIgQQojO85Gu3oQQQriChLoQQvgRCXUhhPAjEupCCOFHJNSFEMKPSKgLIYQfkVAXQgg/IqEuhBB+REJdCCH8iIS6EEL4EQl1IYTwIxLqQgjhRyTUhRDCj0ioCyGEH5FQF0IIPyKhLoQQfkRCXQgh/IiEuhBC+BEJdSGE8CMS6kII4Uck1IUQwo9IqAshhB+RUBdCCD8ioS6EEH5EQl0IIfyIhLoQQvgRCXUhhPAjEupCCOFHJNSFEMKPSKgLIYQfkVAXQgg/4lSoK6VmKKV2KqV2K6UWuLtQQgghOqbNUFdKBQLPAzOBocDlSqmh7i6YEEKI9nPmTH0CsFtrvUdrXQ28CVzg3mIJIYToCGdCvRdwoNH7LGuaEEIIHxPkxDyqmWn6uJmUugm4yXpbpZRK70zBfFgicNjbhXAT2beux1/3C068fevrihU7E+pZQO9G71OA7GNn0lovAhYBKKU2aK3HuaKAvkb2rWvy133z1/0C2beOcqb65QfgJKVUP6VUCDAf+MgdhRFCCNE5bZ6pa63tSqnbgOVAIPCq1nqr20smhBCi3ZypfkFr/SnwaTvWu6hjxekSZN+6Jn/dN3/dL5B96xCl9XHXPIUQQnRR0k2AEEL4EZeGelfsTkAp1VsptVIptV0ptVUpdac1PV4p9YVSapf1HGdNV0qpZ6193KKUOqXRuq615t+llLrWW/vUmFIqUCn1k1LqE+t9P6XUOquMb1kXv1FKhVrvd1ufpzZax33W9J1KqfO8syfHU0rFKqWWKqV2WMdvkh8dt7utf4/pSqklSilbVz12SqlXlVJ5jZs5u/I4KaXGKqXSrGWeVUo11wzbk/v2lPVvcotS6n2lVGyjz5o9Hi1lZ0vHvFVaa5c8MBdRM4D+QAiwGRjqqvW76wEkA6dYr6OAnzHdITwJLLCmLwCesF7PAj7DtN+fCKyzpscDe6znOOt1nA/s3z3AG8An1vu3gfnW6xeBW6zXtwIvWq/nA29Zr4daxzIU6Gcd40Bv75dVtn8DN1qvQ4BYfzhumJv79gJhjY7ZdV312AFnAqcA6Y2muew4AeuBSdYynwEzvbxv04Eg6/UTjfat2eNBK9nZ0jFvtUwu3LlJwPJG7+8D7vPGf4pO7seHwLnATiDZmpYM7LRe/wO4vNH8O63PLwf+0Wh6k/m8tC8pwApgKvCJ9Y/+cKN/cPXHDNO6aZL1OsiaTx17HBvP5+V9i8YEnzpmuj8ct7q7uOOtY/EJcF5XPnZA6jHB55LjZH22o9H0JvN5Y9+O+exCYLH1utnjQQvZ2dr/19Yerqx+6fLdCVg/W8cA64DuWuscAOu5mzVbS/vpi/v/DPBbwGG9TwCKtNZ2633jMtaX3/q82JrfF/cLzFlNPvBPq3rpZaVUBH5w3LTWB4E/A/uBHMyx2Ij/HDtw3XHqZb0+drqv+CXm1wO0f99a+//aIleGulPdCfgqpVQk8C5wl9a6pLVZm5mmW5nuFUqpOUCe1npj48nNzKrb+Myn9quRIMzP3he01mOAcszP+JZ0mf2z6pcvwPxE7wlEYHpJPVZXPXatae+++Ow+KqUeAOzA4rpJzczm8n1zZag71Z2AL1JKBWMCfbHW+j1r8iGlVLL1eTKQZ01vaT99bf8nA3OVUvswPWtOxZy5xyql6u5PaFzG+vJbn8cAhfjeftXJArK01uus90sxId/VjxvANGCv1jpfa10DvAechv8cO3DdccqyXh873ausC7lzgCu1VXdC+/ftMC0f8xa5MtS7ZHcC1pXyV4DtWuunG330EVB3hf1aTF173fRrrKv0E4Fi6+fjcmC6UirOOtOabk3zCq31fVrrFK11KuZYfKW1vhJYCcyzZjt2v+r2d541v7amz7daWPQDTsJcmPIqrXUucEApNciadA6wjS5+3Cz7gYlKqXDr32fdvvnFsbO45DhZn5UqpSZaf6trGq3LK5RSM4DfAXO11kcbfdTS8Wg2O61j2NIxb5mLLxjMwrQeyQAe8OTFik6U+XTMT5otwCbrMQtTn7UC2GU9x1vzK8ygIRlAGjCu0bp+Cey2Htd7e98alWsKDa1f+lv/kHYD7wCh1nSb9X639Xn/Rss/YO3vTjzYssCJ/RoNbLCO3QeYVhF+cdyAR4AdQDrwOqbFRJc8dsASzLWBGsxZ6Q2uPE7AOOvvlAE8xzEXz72wb7sxdeR1efJiW8eDFrKzpWPe2kPuKBVCCD8id5QKIYQfkVAXQgg/IqEuhBB+REJdCCH8iIS6EEL4EQl1IYTwIxLqQgjhRyTUhRDCj/x/Lw4keCLujgcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_003\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop, cutout, wd=1e-5, LabelSmoothing, mixup\n",
    "\n",
    "acc = 0.923219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,2.0), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 50), p=0.8)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0718, -0.0658, -0.0117,  ...,  0.0062,  0.0119,  0.0428],\n",
      "        [ 0.0639, -0.0524, -0.0286,  ..., -0.0625,  0.0323, -0.0058],\n",
      "        [ 0.0173,  0.0078, -0.0237,  ...,  0.0203, -0.0095,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0226,  0.0317,  ...,  0.0056,  0.0121, -0.0259],\n",
      "        [-0.0409,  0.0348,  0.0044,  ..., -0.0138, -0.0759, -0.0460],\n",
      "        [-0.0812,  0.0199,  0.0363,  ..., -0.0296, -0.0574,  0.0551]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fe045255158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.261452</td>\n",
       "      <td>5.082067</td>\n",
       "      <td>0.052211</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.779532</td>\n",
       "      <td>4.280972</td>\n",
       "      <td>0.179361</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.994647</td>\n",
       "      <td>3.061420</td>\n",
       "      <td>0.399263</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.234458</td>\n",
       "      <td>2.261507</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.799880</td>\n",
       "      <td>2.046139</td>\n",
       "      <td>0.641892</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.634579</td>\n",
       "      <td>2.096601</td>\n",
       "      <td>0.628378</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.617093</td>\n",
       "      <td>2.025749</td>\n",
       "      <td>0.657862</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.637721</td>\n",
       "      <td>2.234322</td>\n",
       "      <td>0.604423</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.669004</td>\n",
       "      <td>2.420606</td>\n",
       "      <td>0.573710</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.699150</td>\n",
       "      <td>2.375306</td>\n",
       "      <td>0.552211</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.691556</td>\n",
       "      <td>2.543086</td>\n",
       "      <td>0.544840</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.688857</td>\n",
       "      <td>2.387052</td>\n",
       "      <td>0.586609</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.715963</td>\n",
       "      <td>2.285239</td>\n",
       "      <td>0.597052</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.724162</td>\n",
       "      <td>2.552166</td>\n",
       "      <td>0.526413</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.682731</td>\n",
       "      <td>2.290393</td>\n",
       "      <td>0.615479</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.621208</td>\n",
       "      <td>2.519454</td>\n",
       "      <td>0.570639</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.646888</td>\n",
       "      <td>2.209949</td>\n",
       "      <td>0.625307</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.576465</td>\n",
       "      <td>2.203470</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.452883</td>\n",
       "      <td>1.941743</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.460989</td>\n",
       "      <td>1.972753</td>\n",
       "      <td>0.692260</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.347527</td>\n",
       "      <td>1.906943</td>\n",
       "      <td>0.706388</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.429674</td>\n",
       "      <td>1.690325</td>\n",
       "      <td>0.769656</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.300777</td>\n",
       "      <td>1.791814</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.279803</td>\n",
       "      <td>1.705389</td>\n",
       "      <td>0.762899</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.225774</td>\n",
       "      <td>1.714626</td>\n",
       "      <td>0.764742</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.161813</td>\n",
       "      <td>1.642444</td>\n",
       "      <td>0.786855</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.158433</td>\n",
       "      <td>1.704830</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.135433</td>\n",
       "      <td>1.598937</td>\n",
       "      <td>0.810197</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.106179</td>\n",
       "      <td>1.558067</td>\n",
       "      <td>0.802826</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.043700</td>\n",
       "      <td>1.531253</td>\n",
       "      <td>0.820639</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.063030</td>\n",
       "      <td>1.497350</td>\n",
       "      <td>0.821867</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.987052</td>\n",
       "      <td>1.474756</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.986746</td>\n",
       "      <td>1.464332</td>\n",
       "      <td>0.838452</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.961408</td>\n",
       "      <td>1.419796</td>\n",
       "      <td>0.839681</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.925314</td>\n",
       "      <td>1.389155</td>\n",
       "      <td>0.862408</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.887117</td>\n",
       "      <td>1.399611</td>\n",
       "      <td>0.845209</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.869692</td>\n",
       "      <td>1.332508</td>\n",
       "      <td>0.871007</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.870531</td>\n",
       "      <td>1.322422</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.821248</td>\n",
       "      <td>1.282808</td>\n",
       "      <td>0.886978</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.830050</td>\n",
       "      <td>1.288061</td>\n",
       "      <td>0.882678</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.751463</td>\n",
       "      <td>1.265053</td>\n",
       "      <td>0.895577</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.759053</td>\n",
       "      <td>1.234030</td>\n",
       "      <td>0.902334</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.752386</td>\n",
       "      <td>1.236051</td>\n",
       "      <td>0.896806</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.752096</td>\n",
       "      <td>1.225283</td>\n",
       "      <td>0.898649</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.663390</td>\n",
       "      <td>1.205248</td>\n",
       "      <td>0.904177</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.725611</td>\n",
       "      <td>1.206364</td>\n",
       "      <td>0.909705</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.684809</td>\n",
       "      <td>1.208321</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.675866</td>\n",
       "      <td>1.184342</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.646065</td>\n",
       "      <td>1.170048</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.641240</td>\n",
       "      <td>1.165270</td>\n",
       "      <td>0.920762</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.632530</td>\n",
       "      <td>1.157407</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.595297</td>\n",
       "      <td>1.152337</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.635591</td>\n",
       "      <td>1.159844</td>\n",
       "      <td>0.922604</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.612905</td>\n",
       "      <td>1.154740</td>\n",
       "      <td>0.923219</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.602613</td>\n",
       "      <td>1.151168</td>\n",
       "      <td>0.922604</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.614604</td>\n",
       "      <td>1.145572</td>\n",
       "      <td>0.924447</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.618912</td>\n",
       "      <td>1.144600</td>\n",
       "      <td>0.923833</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.643656</td>\n",
       "      <td>1.142195</td>\n",
       "      <td>0.923219</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.618216</td>\n",
       "      <td>1.143461</td>\n",
       "      <td>0.925061</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.613428</td>\n",
       "      <td>1.142831</td>\n",
       "      <td>0.923219</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fe045255158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"b3_sz300_60epochs_004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.export(\"exported_models/exported.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 20 Epochs, normalize(imagenet_stats), zoom_crop, wd=1e-5, LabelSmoothing, mixup\n",
    "\n",
    "acc = 0.914005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,2.0), do_rand=True)\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[-0.0382, -0.0037,  0.0276,  ..., -0.0339,  0.0026,  0.0116],\n",
      "        [-0.0232, -0.0192, -0.0612,  ..., -0.0241, -0.0650,  0.0326],\n",
      "        [ 0.0131,  0.0091, -0.0193,  ..., -0.0121,  0.0004, -0.0130],\n",
      "        ...,\n",
      "        [ 0.0639,  0.0190, -0.0217,  ..., -0.0451, -0.0064, -0.0432],\n",
      "        [-0.0395, -0.0129, -0.0275,  ...,  0.0139, -0.0460, -0.0325],\n",
      "        [-0.0229, -0.0088,  0.0008,  ...,  0.0323, -0.0127,  0.0362]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Dodge Dakota Club Cab 2007,Dodge Journey SUV 2012,Dodge Charger Sedan 2012,Chevrolet Traverse SUV 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Hyundai Genesis Sedan 2012,Acura Integra Type R 2001,Chevrolet Avalanche Crew Cab 2012,Chevrolet Silverado 1500 Hybrid Crew Cab 2012,Chevrolet Silverado 1500 Extended Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fe045255158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.200615</td>\n",
       "      <td>4.903356</td>\n",
       "      <td>0.072482</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.081461</td>\n",
       "      <td>3.185856</td>\n",
       "      <td>0.332310</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.450619</td>\n",
       "      <td>3.222067</td>\n",
       "      <td>0.345823</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.342707</td>\n",
       "      <td>3.400915</td>\n",
       "      <td>0.303440</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.251600</td>\n",
       "      <td>3.191902</td>\n",
       "      <td>0.406634</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.091748</td>\n",
       "      <td>3.228866</td>\n",
       "      <td>0.360565</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.992910</td>\n",
       "      <td>2.797984</td>\n",
       "      <td>0.491400</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.816722</td>\n",
       "      <td>2.367791</td>\n",
       "      <td>0.573096</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.637952</td>\n",
       "      <td>2.063539</td>\n",
       "      <td>0.673833</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.500136</td>\n",
       "      <td>1.965641</td>\n",
       "      <td>0.697789</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.401012</td>\n",
       "      <td>1.880255</td>\n",
       "      <td>0.719287</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.319669</td>\n",
       "      <td>1.673581</td>\n",
       "      <td>0.786241</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.187654</td>\n",
       "      <td>1.490783</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.060361</td>\n",
       "      <td>1.402707</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.979284</td>\n",
       "      <td>1.359660</td>\n",
       "      <td>0.869165</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.929275</td>\n",
       "      <td>1.275733</td>\n",
       "      <td>0.902948</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.852237</td>\n",
       "      <td>1.244440</td>\n",
       "      <td>0.907862</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.812446</td>\n",
       "      <td>1.220630</td>\n",
       "      <td>0.916462</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.804198</td>\n",
       "      <td>1.209376</td>\n",
       "      <td>0.915848</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.799108</td>\n",
       "      <td>1.209180</td>\n",
       "      <td>0.914005</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 20\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_005\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 20 Epochs, normalize(imagenet_stats), zoom_crop, cutout, wd=1e-5, LabelSmoothing, mixup\n",
    "\n",
    "acc = 0.904791"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,2.0), do_rand=True) + [cutout(n_holes=(1,2), length=(40, 60), p=0.8)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[-0.0387,  0.0400,  0.0271,  ..., -0.0138, -0.0536, -0.0622],\n",
      "        [-0.0409, -0.0061, -0.0144,  ..., -0.0416, -0.0232,  0.0589],\n",
      "        [ 0.0011, -0.0408, -0.0385,  ...,  0.0130,  0.0175, -0.0129],\n",
      "        ...,\n",
      "        [ 0.0522,  0.0302,  0.0393,  ..., -0.0065,  0.0585, -0.0228],\n",
      "        [-0.0426, -0.0382,  0.0172,  ...,  0.0033,  0.0515, -0.0134],\n",
      "        [-0.0477,  0.0115,  0.0008,  ..., -0.0113, -0.0274, -0.0571]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Ford Edge SUV 2012,Acura Integra Type R 2001,Hyundai Genesis Sedan 2012,McLaren MP4-12C Coupe 2012,BMW 1 Series Coupe 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7fe045255158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.211422</td>\n",
       "      <td>4.909228</td>\n",
       "      <td>0.070025</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.212939</td>\n",
       "      <td>3.313144</td>\n",
       "      <td>0.307125</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.477954</td>\n",
       "      <td>3.283005</td>\n",
       "      <td>0.329853</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.368873</td>\n",
       "      <td>3.489353</td>\n",
       "      <td>0.308968</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.377006</td>\n",
       "      <td>3.634404</td>\n",
       "      <td>0.352580</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.191431</td>\n",
       "      <td>2.992228</td>\n",
       "      <td>0.396806</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.042139</td>\n",
       "      <td>2.536987</td>\n",
       "      <td>0.517199</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.864335</td>\n",
       "      <td>2.448488</td>\n",
       "      <td>0.564496</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.777891</td>\n",
       "      <td>2.624644</td>\n",
       "      <td>0.595823</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.624716</td>\n",
       "      <td>1.951740</td>\n",
       "      <td>0.702088</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.442254</td>\n",
       "      <td>1.819464</td>\n",
       "      <td>0.732801</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.361331</td>\n",
       "      <td>1.657984</td>\n",
       "      <td>0.784398</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.269347</td>\n",
       "      <td>1.497758</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.137397</td>\n",
       "      <td>1.431023</td>\n",
       "      <td>0.843366</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.023125</td>\n",
       "      <td>1.359814</td>\n",
       "      <td>0.874079</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.964837</td>\n",
       "      <td>1.305700</td>\n",
       "      <td>0.890663</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.866743</td>\n",
       "      <td>1.266735</td>\n",
       "      <td>0.897420</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.877306</td>\n",
       "      <td>1.246056</td>\n",
       "      <td>0.900491</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.834849</td>\n",
       "      <td>1.238468</td>\n",
       "      <td>0.904177</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.804649</td>\n",
       "      <td>1.237388</td>\n",
       "      <td>0.904791</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 20\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_20epochs_006\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=300, 20 Epochs, normalize(imagenet_stats), rand_resize_crop\n",
    "\n",
    "acc = 0.869779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms(xtra_tfms=rand_resize_crop(300, max_scale=2.0, ratios=(0.75, 1.33)))\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=300, normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[-0.0536, -0.0216,  0.0016,  ...,  0.0020,  0.0500,  0.0447],\n",
      "        [-0.0192,  0.0428, -0.0357,  ...,  0.0522,  0.0246, -0.0467],\n",
      "        [-0.0081,  0.0245, -0.0039,  ..., -0.0337, -0.0430, -0.0109],\n",
      "        ...,\n",
      "        [-0.0181,  0.0115,  0.0129,  ..., -0.0099,  0.0221, -0.0353],\n",
      "        [-0.1010,  0.0380, -0.0561,  ...,  0.0691, -0.0047, -0.0425],\n",
      "        [ 0.0142,  0.0740, -0.0543,  ...,  0.0185,  0.0211,  0.0200]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = get_learner(train_val_data, eff_net, fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.078391</td>\n",
       "      <td>4.733749</td>\n",
       "      <td>0.097052</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.128467</td>\n",
       "      <td>2.471825</td>\n",
       "      <td>0.355651</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.065155</td>\n",
       "      <td>2.358328</td>\n",
       "      <td>0.408477</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.978597</td>\n",
       "      <td>3.256512</td>\n",
       "      <td>0.335995</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.908676</td>\n",
       "      <td>3.244434</td>\n",
       "      <td>0.273956</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.779976</td>\n",
       "      <td>2.793937</td>\n",
       "      <td>0.340295</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.498640</td>\n",
       "      <td>2.475498</td>\n",
       "      <td>0.382678</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.409567</td>\n",
       "      <td>2.404403</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.220254</td>\n",
       "      <td>2.033123</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.017412</td>\n",
       "      <td>1.934685</td>\n",
       "      <td>0.509828</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.859317</td>\n",
       "      <td>1.681110</td>\n",
       "      <td>0.559582</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.680821</td>\n",
       "      <td>1.359327</td>\n",
       "      <td>0.643735</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.519366</td>\n",
       "      <td>1.101416</td>\n",
       "      <td>0.700860</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.404377</td>\n",
       "      <td>0.905859</td>\n",
       "      <td>0.762899</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.297568</td>\n",
       "      <td>0.804833</td>\n",
       "      <td>0.785627</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.236393</td>\n",
       "      <td>0.633060</td>\n",
       "      <td>0.825553</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.153220</td>\n",
       "      <td>0.560296</td>\n",
       "      <td>0.842752</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.115711</td>\n",
       "      <td>0.531779</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.075788</td>\n",
       "      <td>0.493613</td>\n",
       "      <td>0.867936</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.078283</td>\n",
       "      <td>0.492835</td>\n",
       "      <td>0.869779</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-1\n",
    "epochs = 20\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_20epochs_normal-imagenet_rand_resize_crop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, sz=300, 20 Epochs, zoom_crop\n",
    "\n",
    "acc = 0.900491"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tfms = get_transforms(xtra_tfms=zoom_crop(scale=(0.75,2), do_rand=True))\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=300, padding_mode=\"zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[-0.0072,  0.0721,  0.0491,  ..., -0.0071, -0.0148, -0.0271],\n",
      "        [ 0.0085, -0.0438, -0.0097,  ..., -0.0791,  0.0018, -0.0702],\n",
      "        [-0.0053, -0.0196, -0.0301,  ..., -0.0590,  0.0147, -0.1202],\n",
      "        ...,\n",
      "        [-0.0343,  0.0291,  0.0106,  ...,  0.0156,  0.0454,  0.0590],\n",
      "        [-0.0174,  0.0005, -0.0278,  ...,  0.0194,  0.0529,  0.0159],\n",
      "        [ 0.0051, -0.0319, -0.0159,  ..., -0.0302,  0.0350,  0.0167]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n_class = 196\n",
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Lamborghini Aventador Coupe 2012,Suzuki Aerio Sedan 2007,Suzuki Kizashi Sedan 2012,Dodge Caliber Wagon 2012,BMW 3 Series Sedan 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=CrossEntropyLoss(), metrics=[<function accuracy at 0x7faec7a32158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = Learner(train_val_data, eff_net, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], path='.', callback_fns=ShowGraph)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.165739</td>\n",
       "      <td>4.860180</td>\n",
       "      <td>0.076167</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.711944</td>\n",
       "      <td>2.759920</td>\n",
       "      <td>0.316339</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.729475</td>\n",
       "      <td>2.587435</td>\n",
       "      <td>0.358108</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.593584</td>\n",
       "      <td>3.182458</td>\n",
       "      <td>0.264742</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.458220</td>\n",
       "      <td>2.724496</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.349305</td>\n",
       "      <td>2.797056</td>\n",
       "      <td>0.315725</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.177639</td>\n",
       "      <td>3.441000</td>\n",
       "      <td>0.233415</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.949889</td>\n",
       "      <td>2.396260</td>\n",
       "      <td>0.385135</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.753502</td>\n",
       "      <td>2.141473</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.546982</td>\n",
       "      <td>1.884265</td>\n",
       "      <td>0.498157</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.351091</td>\n",
       "      <td>1.927906</td>\n",
       "      <td>0.506142</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.166203</td>\n",
       "      <td>1.327223</td>\n",
       "      <td>0.644349</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.000638</td>\n",
       "      <td>0.957002</td>\n",
       "      <td>0.734644</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.820162</td>\n",
       "      <td>0.784821</td>\n",
       "      <td>0.771499</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.694057</td>\n",
       "      <td>0.625948</td>\n",
       "      <td>0.821867</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.509795</td>\n",
       "      <td>0.508233</td>\n",
       "      <td>0.851966</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.460111</td>\n",
       "      <td>0.422589</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.382998</td>\n",
       "      <td>0.351933</td>\n",
       "      <td>0.896806</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.333039</td>\n",
       "      <td>0.342879</td>\n",
       "      <td>0.901106</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.331064</td>\n",
       "      <td>0.339229</td>\n",
       "      <td>0.900491</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4lFXawOHfmUklBFKBhAAJSA8BQigCIiAiTcUGqLgqrt1d+4pbFNbGuquLFT5UdFUUEewCFgQBqYlACDWUQCCBFEiD9DnfH+8QElIIIdMyz31duTLz1icvycOZU5XWGiGEEK7L5OgAhBBCXBxJ5EII4eIkkQshhIuTRC6EEC5OErkQQrg4SeRCCOHiJJELIYSLk0QuhBAuThK5EEK4OA9bXNQ/IEh3vaSjLS4thBBNUkJCQpbWOrQh59okkSv/UOLj421xaSGEaJKUUocaeq5NqlaKyyzIHC5CCGEfNqsjj3p6KaknTtvq8kIIIaxs2tg57rU1try8EEIIbFRH7mFSAOQXlxE5/XtmT+7DxL5tbXErIUQTUFpaypEjRygqKnJ0KDbn4+NDREQEnp6ejXZNZYu67Li4OL12/UZ6PvsD5Rbj+p/fdyn9I4Ma/V5CCNd38OBB/P39CQ4ORinl6HBsRmtNdnY2+fn5REVFVdmnlErQWsc15Lo2q1rx8TSz/8VxbHt2NJHBzbhp7nr++9NeEg6dsNUthRAuqqioqMkncQClFMHBwY3+ycPmA4Ja+nry1q2xALy2Ipkb5qznPz/ssfVthRAupqkn8TNs8XPaZWRnz/CWJM4YzfMTowF4c+U+psxbz7r9Wfa4vRBCNGl2G6LfwseTqYM6cODFcTw6qguHs09zyzsbue7t39h4INteYQghRDU5OTm8/fbbF3zeuHHjyMnJsUFEF8buc62YTIqHR3VmxePDeXpsN7IKipk8bwM3z9vAyVMl9g5HCCFqTeTl5eV1nrd06VICAgJsFVa9OWzSLF8vM/de3ollDw/jvss7sf5ANn2f+4msgmJHhSSEcFPTp09n//799OnTh/79+zNixAhuueUWevXqBcDEiRPp168fPXv2ZN68eRXnRUZGkpWVRUpKCt27d+fuu++mZ8+ejB49msLCQrvFb5N+5BeiubcH08d2I9Tfm+e+28lNc9fzzUND8PdpvD6WQgjXMfPbHexMy2vUa/YIb8GzV/esdf+sWbNISkpi69atrFq1ivHjx5OUlFTRRXD+/PkEBQVRWFhI//79ueGGGwgODq5yjeTkZD799FPeeecdJk2axJIlS5g6dWqj/hy1cZppbO8aGsX7d/QnJfsULy7d7ehwhBBubMCAAVX6eb/++uv07t2bQYMGkZqaSnJycrVzoqKi6NOnDwD9+vUjJSXFXuE6vkRe2YhurZg6sAMLNx/midFdCG7u7eiQhBB2VlfJ2V78/PwqXq9atYqff/6Z9evX06xZM4YPH15jP3Bv77P5ymw227VqxWlK5GdMHdSB0nLNV1vTHB2KEMJN+Pv7k5+fX+O+3NxcAgMDadasGbt372bDhg12ju78nKpEDtC1jT+9I1ryeXwq04ZEus0gASGE4wQHBzNkyBCio6Px9fWldevWFfvGjBnD3LlziYmJoWvXrgwaNMiBkdasXnOtKKVSgHygHCg733wAcXFx+mIWlvh4wyH+/lUS3zw0hJgIx3ftEULY1q5du+jevbujw7Cbmn5ee821MkJr3aehN7oQV/cOx9vDxKL4VFvfSgghXJ7T1ZGDMT/L2Og2fL01jaLSujvkCyGEu6tvItfAj0qpBKXUPbYM6IxJce3ILyrjhx3H7HE7IYRwWfVN5EO01rHAWOBBpdSwcw9QSt2jlIpXSsVnZmZedGCDOgYTGdyMt1buw2KR9T+FEKI29UrkWus06/cM4EtgQA3HzNNax2mt40JDQy8+MJPigRGXsPd4ATvTG3eUlxBCNCXnTeRKKT+llP+Z18BoIMnWgQEM72L8h7Byd4Y9bieEEC6pPiXy1sBapdQ2YBPwvdZ6uW3DMrRq4UP/yEC+3paGLZakE0KIhmrevDkAaWlp3HjjjTUeM3z4cC6mK3Z9nTeRa60PaK17W796aq1fsGlEhzfA8qfBmrgn9m3LvgypXhFCOKfw8HAWL17s0Bicr/thxi7Y8DacPAjAyG6tAGOQkBBC2MpTTz1VZU7yGTNmMHPmTK644gpiY2Pp1asXX3/9dbXzUlJSiI42Vj8rLCxkypQpxMTEMHnyZLvNt+J0Q/QJ72t8T9sCQR0Ja+kLwL6MAgcGJYSwm2XT4dj2xr1mm14wdladh0yZMoVHHnmEBx54AIBFixaxfPlyHn30UVq0aEFWVhaDBg3immuuqXXqkDlz5tCsWTMSExNJTEwkNja2cX+OWjhfibxVDzB7GYncatqQKBIOnSSvqNSBgQkhmrK+ffuSkZFBWloa27ZtIzAwkLCwMP76178SExPDqFGjOHr0KMePH6/1GqtXr66YgzwmJoaYmBi7xO58JXIPL+N/z7StFZtGdmvF/N8O8t22dG4Z2N6BwQkhbO48JWdbuvHGG1m8eDHHjh1jypQpLFiwgMzMTBISEvD09CQyMrLGKWwrc8REf85XIgejeiVtK1gsAPSPCiS8pQ/v/3bQwYEJIZqyKVOmsHDhQhYvXsyNN95Ibm4urVq1wtPTk5UrV3LoUN1tdcOGDWPBggUAJCUlkZiYaI+wnTiRl+TDif0AeHuYuXVQB5IzCsiWNT2FEDbSs2dP8vPzadu2LWFhYdx6663Ex8cTFxfHggUL6NatW53n33///RQUFBATE8PLL7/MgAHVxk7ahPNVrUDVBs+QzgBc1jmEf/+wh592HmfKAKleEULYxvbtZxtaQ0JCWL9+fY3HFRQYHTAiIyNJSjLGSPr6+rJw4ULbB3kO5yyRh3QFD98qDZ692rakXZAvLyzdJXOvCCFEJc6ZyM0eEBZTJZErpZjUz5gRcUtqjgODE0II5+KciRyM6pX0bWA5Ox/5Hy6NxNOsWJ6U7sDAhBC24C7TcNji53TuRF56GrL2Vmxq2cyTyzqH8n1iutv8owvhDnx8fMjOzm7yf9daa7Kzs/Hx8WnU6zpnYydUbfBsdXZtuwkxYfyyO4PfD+fQr0Ogg4ITQjSmiIgIjhw5QmOsZeDsfHx8iIiIaNRrOm8iD74EvJobibzPLRWbR/VojZfZxLfb0iSRC9FEeHp6EhUV5egwXJbzVq2YzBDWu0qDJ0ALH0+GdQlhxe7ah8kKIYQ7cd5EDkb1yrHtUF51jpW+7QNJPVFIbqHMvSKEEM6fyMuKIHN3lc09wloA8F1imiOiEkIIp+L8iRyqVa/0jwoCYHd6vr0jEkIIp+PciTwwCrxbVkvkzb09GBAVxPajuQ4KTAghnIdzJ3KTCcJ7w9Hfq+2KbR/IjrRcikrLazhRCCHch3MncjCqV47vgLKqsx7Gtg+gtFyTJKVyIYSbc41Ebik1knklcZFBKAW/7ct2UGBCCOEcXCORQ7V68iA/L3pHBPDLngwHBCWEEM7D+RN5QAfwDayWyMFYAm5bag6Z+bLYhBDCfTl/Ilfq7NJv5xjZrRUAq6RULoRwY86fyMFI5Bk7obSwyuae4S0I9fdm7b4sBwUmhBCO5zqJXJfDsaQqm5VS9I5oyc60PAcFJoQQjuc6iRxqrCfv2safA1mnpD+5EMJtuUYib9EW/EJrTOTR4S0pt2j2HJPh+kII9+QaiVwpCI+tOZG3bQlAogwMEkK4KddI5GBUr2TtgeKCKpsjAn0Jae7F+v3S4CmEcE/1TuRKKbNSaotS6jtbBlSr8L6gLcb85FXjYljnUNbvz6a4TOrJhRDu50JK5A8Du2wVyHmF9zG+11C9Mq5XGCdPl7L54Ek7ByWEEI5Xr0SulIoAxgPv2jacOvi3Af/wGhP5wI7G/ORvrky2d1RCCOFw9S2Rzwb+AlhsGMv5hfetMZH7+3ji7WFia2oOWmsHBCaEEI5z3kSulJoAZGitE85z3D1KqXilVHxmZmajBVhFeF/IToai6gOA/nltT4pKLcz5db9t7i2EEE6qPiXyIcA1SqkUYCEwUin18bkHaa3naa3jtNZxoaGhjRym1ZmBQenbqu2aEBMOwNpk6b0ihHAv503kWuuntdYRWutIYArwi9Z6qs0jq0kdDZ5+3h5c0a2VzIQohHA7rtOPHMAvBFq2rzGRgzGJ1v7MAhmuL4RwKxeUyLXWq7TWE2wVTL2E96k1kfcIb4FFI8P1hRBuxbVK5GDUk588CIXV+4z3CDOG6+9Ml9kQhRDuwzUTOdS40EREoC/+3h4yra0Qwq24YCKvvcHTZFJ0D2shJXIhhFtxvUTuGwiBUXXWk+9Kz6Os3LFjl4QQwl5cL5FDrWt4AlzWOYTTJeUsTjhi56CEEMIxXDeR5x6GU9UH/1zRvTX+Ph7skHpyIYSbcN1EDrWWyjsEN+PwidN2DEgIIRzHNRN5WG/jey315O2DmpEqiVwI4SZcM5H7tIDgzpD2e4272wU148jJQsotMhOiEKLpc81EDrVOaQtGibyk3MLxvCI7ByWEEPbn2ok8Px3y0qvtah/UDEDqyYUQbsG1EzlAevUGT0nkQgh34rqJvE0vUKYaq1fCA3wxKaTBUwjhFlw3kXs3h5CuNSZyT7OJ8ABfKZELIdyC6yZygLaxRiKvYZ3OdoHSBVEI4R5cO5GH94VTmZB3tNqu9kHNOHyi0AFBCSGEfbl+Iocaq1faBfmSVVBMYYmsFnRRSk7BhxNh59eOjkQIUQvXTuSte4LJo5ZEbvRcST0p1SsXZcU/4cBKWPWvGquwhBCO59qJ3NMXWnWvMZF3CPYDICXrlL2jajoOrYON/wdBnSBjB6RudHREQogauHYih7MjPM8pLUaFGIl8V7qs39kgJafh6wchoD1MWw7eLSB+vqOjEkLUoGkk8sKTkHOoyuaWvp50a+PP74err+0p6uGX5+HEAbjmDWjeCnpPgR1fwqlsR0cmhDhH00jkUGP1Ss/wljIveUMc3ggb3oa4u6Dj5ca2uGlQXgJbFzg2NiFENa6fyFv1ALNXLYm8BVkFxWTky+RZ9VZaCF8/AC3bwZUzz25v1R3aDzaqVyyyjJ4QzsT1E7mHt9F7pYZE3iO8BQA7pVRefytfgOx9cM3r4O1fdV//u+DkQaMXixDCabh+Igdrg+e2aiXF7mFGIl8Un+qIqFxP6mZY/xb0uwM6jai+v/vV0CxEGj2FcDJNJ5EX5xqlxUpa+nrSr0MgS7cfo6RMqgPqVFpkVKn4h8OVz9V8jIc39J0Ke5ZBXpp94xNC1KrpJHKosXrl9sGRAPbvvZKXDl89AJl77Hvfhlr1EmTtNapUfFrUfly/O0Bb4PcP7RaaEKJuTSORh3YDD58aE3lM25YATJm3wX7xWCzw5b1GD48PJ8LJQ+c/x5GOJMC616HvbXDJFXUfGxRlHJPwPygvs098Qog6NY1EbvY05ievIZFHhvgR7OcFQG5hqX3iWf8GHPwVhjwCpafgo4mQf9w+975QZcXWKpUwuOqF+p0Tdxfkp8HeZbaNTQhRL00jkYNRvZK+DSzVJ8l65/Y4AF5ausv2cRz93ZifpMe1MGoG3LoY8o/Bx9cbA5ecza//gszdcPVr4NOyfud0Hg0t2kqjpxBOomkl8pICo+vcOfpEBACwcHOqbedeKS6AJX+E5q2NxKgUtBsAUxYY9c8LJhmzCTqLtC2wdjb0mQqdr6z/eWYPo658/y+Qvd9m4Qkh6ue8iVwp5aOU2qSU2qaU2qGUmnm+cxyijgZPk0nxxs3G/o822LC+evl0Y1j79fPAN/Ds9k4j4Yb34Gg8fDbVqM5wtLISozG2eav6V6lU1vc2UGZI+KDRQxNCXJj6lMiLgZFa695AH2CMUmqQbcNqgJAu4NmsxkQOcHXvcK7v25b31h5k7q/7OV3SyA11O76ELR/BZY9D5NDq+3tcA1e/bpRiv7inxiogu1r9b8jYaXxy8A248PNbhEG38bDlY6ProhDCYc6byLWhwPrW0/rlfBNTm8wQ1rvWRA5wz+UdAZi1bDev/Li38e6dkwrfPgxt42D49NqPi70NRr8AO78yjnfU/N7p22DNK9D7ZuhyVcOv0/8uKDwhi04I4WD1qiNXSpmVUluBDOAnrXW1iamVUvcopeKVUvGZmZmNHWf9hPeF9MRau8V1a9OC5t4eAGxOOdE497SUG10NLeVwwztGD5q6DH4Ihj1plN5/+of9k3lZCXz1IPiFwFUvXty1IocZc5VLo6cQDlWvRK61Ltda9wEigAFKqegajpmntY7TWseFhoY2dpz1E94Xygohq/ZBOEkzr+KOwZEkHsltnMWZ174Kh36D8a9AUMf6nTPib9D/blj3hnG+Pa19FY5vhwmzoVnQxV3LZDJmRUzdAMd3NE58QogLdkG9VrTWOcAqYIxNorlYdTR4VnZ173AAft17kZ8cUjfDypcg+kaImVz/85SCsS9Dr0lGV8XN715cHPV1bLtRN95rEnQb1zjX7HMLmL2lVC6EA9Wn10qoUirA+toXGAXstnVgDRLUCbz8z5vIY9sHENDMkx1puQ2/V1EefPFHaNkWJrxqJOcLYTLBxLehyxj4/gnYvrjhsdRHeanRS8U3CMb+q/Gu2ywIoq+HbZ8Z3S+FEHZXnxJ5GLBSKZUIbMaoI//OtmE1kMkE4X2MQTl1UErhYTLx6aZUyi0NrKNe+iTkHIbr363/QJpzmT3hpg+gwxCjnn3vDw27Tn2snQ3HEo3/dC62SuVccXdBST5sX9S41xVC1Et9eq0kaq37aq1jtNbRWut/2iOwBgvvC8eTjEa9OgzsaCSz11YkX/g9Ej+HxIVw+VPQfmBDojzL0xdu/hRaR8OiP0DKbxd3vZoc32GM4Iy+wZiKtrFFxEHrXrB5vuN64gjhxprOyM4zwvsaS5Jl7KzzsFdu6g3A6yuS+ee3dR9bxckU+P4xaDcILnviIgKtxKcFTF1iLHT86RRI29o41wWjB89XDxifGsb+u/GuW5lS0H+a0Yh6JN429xBC1KppJnI4bz25j6eZB0d0AmD+bwc5crIePVjKy2DJ3YCydjX0uMhgK/ELgdu+NBLuxzdAVgM+KZxRnG8k1N8/giV3QfpWo0rFL7jx4j1Xr5vAqznEv2e7ewghatSImchJBEaCT4A1kd9Z56FPXtWNjLxiPk84wkvLdjOyayuuj22Lqq3hcvXLcGSTMdw+oH2jh07LCPjD1zD/KmP622nLIaBd7ceXFhrznWfuNj6BZOyGjF2Qe/jsMR4+MOBeYxIvW/L2N3rubPnY6J/e2PXwQohaKW2DOs24uDgdH+/Aj9gLJhlD4XtcC3F3Go2JtSRnrTVRTy+teP/CddFsPZzD5wlHSJk1/uyBh9bDB+MgZgpcN8e28acnwgcToHko3LncKKVnJxtJOmPX2cR94iAVg2xNnsY0Ba26Q6tuxqLUod2M/9hMZtvGe8axJJg7xBi9Ovgh+9xTiCZCKZWgtY5r0LlNMpHnpcFvr8G2T6Eo10hw/e6E3lNqLCnO/nkvs3+uXpUxKS6Cl2/sDYU5MHcomDzgvjXVFyW2hcMbjFK5h5cxY6LFOlpVmSG4k5GwQysl7aCO5x9Vag/vjYZTWfCnhAvvkimEG5NEXpuS08ZkVvHzjZkHPXyg53XGaMSI/tUSzdxf9zNrWdUu8ikvjYPF02DXNzDtR4joZ7/4D642VuIJ7HC2hB3S2Vg701lt+wy+vMeoIuo43NHRCOEyJJHXx7HtEP8+JC4y+jy36mlUu8RMqtIPvLTcQtLRXD7bnMrCzansuD4bv6V/giueMWY2FHUrLYJXuxszQE7+yNHRCOEyLiaRN71eK7Vp08voufG4dTUcswcsfQJe6QZfP1QxiMjTbKJv+0CGd21FB3UMvn+CsnaDjWXbxPl5+kDfW2H398YC1EIIm3OfRH6Gd3NjdZt7V8PdK41BMklL4J0R8H/DjFJ7cQFXdg3iXb+5lOLBtWl/sF+DYVPQ707Q5cYMj0IIm3O/RF5Z21i49k2jlD7uP0Y/8e8egVe6Yf5wAp3L9jK99G52nGpB578t5astR7n7w3i2puac99JrkjMZ9eqvnDhV9wjTJim4E3QcYaweVMuUwkKIxuPeifwMn5Yw4G64/zejQbP7BGPxhbhpPPawMXqztFzzyGdb+WnncSa+9Rsrdh2v9XIbDmRz23ub2JdRwDdbj9rrp3Au/e+CvKOQ/KOjIxGiyZNEXplSxtwp182F6Ydh/Kt0ae3PO3+o3v7w4Ce/U1ND8drkLKbM23D2/b5sm4bstLqMBf8wGekphB1IIq+Nh3dF98Qre7Rmzq2xvHBdNCmzxnN9bFuKSi1c/u9VAKTnFrI2OYuDWaeY+t7ZxZPCW/rw867jnHTH6hWzB8TeDvtWWAcuCSFsxX26HzaiE6dKiH3up1r3X9Y5hI/uGsiShCM8/vk2IgJ9+fHRYazYlUHO6RKmDupQ+zQAViVlFrw8XPz/2bw0+G80DP4TXDnT0dEI4dSkH7kDfLrpME9/sb3GfXufH4uXh6na8P8zIoOb8f2fL8PPu+pUN2k5hVi0ZuJbv5FVUMKzV/fghx3H2HDgBLufG4OPpwv2nFl4qzFK9bGdzj2QSQgHk37kDnBTvwg8TIqOoX6sf3okKbPG88yEHnx+36UVJWmlVMUMi5WlZJ9m4IsrKCmzAMZ8L33/+SODZ/3C0H+tJKvAqIqZ+e1ONhwwFonu9o/lHDl5msEvrSCroBiAwpJye/yoFyduGpzOgl3fOjoSIZosKZHbmNaavccLuGr2agDGRrdhWdKxiv2t/L3JyC+udl5LX09yC0trvObtl3bg0k4h3PdxAk9e1ZUHR1xim+Abg8UCb8QaDZ/Tljk6GiGcllStuACtdUW9+K97M7l9/qZqx/x1XDfuGByFRWt8PM0Ul5WTV1hGmcXCpS/9Uuu1bxnYnjsGR3Lbext5+cbeFJaU0addIK38vTGZnGDiqt9eg5+eMWZFHHhf487jLkQTIYncBRWWlHPZyyvJKijGz8vMwnsupVdE3Wt/Jh/PZ/exfP70ad2LZpzrt+kjaRvgezHhXpzifPj8Ttj3kzH517j/QOQQx8UjhBOSRO5m1u3PYk1yFk+N6cZnmw/z1JKaG10rqzK3uiNobcy/svxpY+GLXjfBlc9BizDHxiWEk5DGTjczuFMIT43pBsCkuHaENPcC4NO7B5Eyazzbnh3N9X3bVimF7z2eX+v1LBY7LJislDFi9sGNxqLVO7+BN+Ng3RtQXnNbgBCifqRE3sTty8hn1KtGQ+uBF8dhMikSDp1gzqoDjIluwxOfbwOgZ3gLvv/zZfYL7MQBo3S+dzmEdIVx/4aOl9vv/kI4mYspkUurUxPXKbR5xeunliSyfMcx8ouMiax+rjRfzI60PNbtz2JwpxD7BBbUEW75DPYsh+VPwYfXGIt+jH4BWra1TwxCNBFStdLEKaVIfmEsAJ8nHKlI4pX1ams0st7yzkYKiu08W2HXMfDARhj+V9izzKhuWfMqlLnhtAZCNJAkcjfgaTYxOa5dxfvr+rZlxeOXV9SpL7h7YMW+6Gd/YFd6HlsOnyQtp9BOAfrA8KeM+vNOI2HFTJhzqTFPixDivKSOXADG3C5d/l59wE7SzKuY/H/rmTu1H+2CmtknmOSfYdmTRj1696vhqhchoL197i2Eg0j3Q9Fobp63gfUHap56165dGMuKjR4tq/9jvL/scWPyLU8f+8UghB1J90PRaD69x6huWf3kiGr7dh/Ls18gHt4w7Al4aDN0GQ0rn4e3B0Fy7bNOCuGupEQuamWxaApLy8kpLGXIrF8Y3jWUD+4c4Jhg9v8CS/8C2cnQbQKMeUmqW0STIiVyYRMmk8LP26NiYNGqPZkVMzbaXaeRcP86GDXDSOpvDjCqXcqqTzgmhLs5byJXSrVTSq1USu1SSu1QSj1sj8CEc3nIOsPipoMnHBeEhxcMfRQe3ASdr4RfnoO3pXeLEPUpkZcBj2utuwODgAeVUj1sG5ZwNvde3hGAqe9tZOq7G89ztI0FtIPJH8GtSwANH18Pn90GuUccG5cQDnLeRK61Ttda/259nQ/sAmTonZvx9/HkjsGRAKzdl8Xo//7K0ZxCft2bWes5p4rLWLUnw3YLYHQeBQ9sgJF/NxpB3+wPa/8rg4mE27mgxk6lVCSwGojWWueds+8e4B6A9u3b9zt06FDjRSmcxq70PMa+tgYAkwKLht7tAlh49yB8PE0kHc1j9s97Sck+xf7MUxXnbZ8xGn8fT9sFdvIQ/PBX2P0dhHSxzt0y3Hb3E6KR2aUfuVKqOfAr8ILW+ou6jpVeK01bTVPntmnhw7Shkby4dHet5+17YSweZhu3r+/9AZb9BU6mQM/r4aoXoEW4be8pRCOwea8VpZQnsARYcL4kLpq+yf3bc3mXUAAevqIzAMfyiqol8TE927D3+bEV77ek5tg+uC5XVZq7ZalR3fLb6w2bKresGHIOQ+om2PEVbJgLq2YZ24RwIuctkStjfbL/ASe01o/U56JSIm/6tNYczyumTUsfUrJOMfw/qwC4bVAHnpsYXeXYjLwiBry4gnZBvqz5y0j7BXniICyfbkyVG9rNWJko6jKwlMOpTMhPh7x043v+sXO+p8Ppmke40joa/rhCRpmKRmXTqhWl1FBgDbAdONOJ+K9a66W1nSOJ3P1k5hfz7DdJvHlzbI3rhMY9/xNZBSXsfX4sXh52Hr6wZ5lR3ZJzGJq3NpK4Pqc/vDKBXytjxSL/MPBvU+l7+Nn3R+Phk0kw6EEY86J9fw7RpMlcK8Lp/W9dCs9+s4MFfxzIwKgg29eVn6u0EDa8DdkHKiXrSgnbL7T+i0IvfRI2zYOpX8AlV9g2buE2JJELp3e6pIwez/xQ8X7XP8fg62UGoKi0HE+zCXMNJXmnVFoI84ZD4Um4fz34BTs6ItEEyBB94fSaeXkQ7OdV8f7Zb5LILyrldEkZ3f6xnOH/WVmx76P1Kazfn82KXccpLrNRH/SL4ekLN7xrJPJv/mQsLC2EA0mJXNjNqeIyCkvLiXv+5xr3d224f3wNAAATF0lEQVTtz546Fon+6dFhdG7tb6vwLtz6t4y+6xNmQ9ydjo5GuDgpkQuX4OftQUhzb/51Q68a99eVxAEeW7TNFmE13MD7oeMIYxHpzL2Ojka4MUnkwu4m92/PXUOjGNQxiMQZo9n1zzEsvu/Siv3PTOjBd38ayoI/GkvQPTWmGwDbj+aybl+WQ2KukckEE+cYVS1f/FGmBhAOI1UrwiV8svEwf/1yO33aBfDVg0McHU5Vu76Dz26FIY/AlTMdHY1wUVK1Ipq8Kf2NxaO3pubw5RYnm+Ww+wSIvR1+ew0OrnZ0NMINSSIXLsFkUvx9fHcAHv1sGzV9kiwuK69xu12MeQmCO8EX98JpB87ZLtySJHLhMv54WceK11FPL+VAZgFFpeX87cvtRE7/nq5/X07U00s5capqXXXCoRMUldq4G6OXH1z/DpzKgO8ekS6Jwq6kjly4lP2ZBVzxyq91HqMUHHxpPMnH87nyv0ZVx9joNsyZ2s/2Aa55FVbMhGvfhr632v5+osmQOnLhNjqFNq+YcfFcn90zCDAKw71n/liRxAGWJR3jf+tSbB/gkIehw1Bjbpfs/ba/nxBIiVy4KK01WQUlLIpP5Y7Bkfh5G/Ok3PH+Jlbtqbpq0XMTo/nHV0kAzJ3ajzHRbWwbXO4RmDMYgjvDtOVgtuGCGqLJkBK5cDtKKUL9vXlwxCUVSRxg/u39eePmvgQ28+T62LbsfX4stw3qwPheYQDc93EC+zMLbBtcywhjtOfRePj1ZdveSwikRC7cyMcbDvF3a8k84e+jCG7ubdsbfnk/JC6EO5dB+0G2vZdweVIiF6Iepg7qQFyHQAD6Pf8zBcVltr3h2H9BQHv44m4oyrXtvYRbk0Qu3MrnlaYCuO+jBN5ZfYBNB23U79unhdElMfeoMYe5EDYiiVy4FaUUKbPGM6JrKGv3ZfHC0l1M+r/1LEmw0WjRdgPg8qcg8TNI/Nw29xBuTxK5cEsv39i7yvt/Ld9NWfnZ5d/ScwsZM3s12QXF5J4u5a9fbufIydMNu9llj0O7gfD9Y3Dy0MWELUSNpLFTuC2LRVOuNb/szuDejxK4Y3AkM67pyZu/JPOfH2uelnb62G7cd3mnC7/ZyRSYMxTaRMMd34PJfHHBiyZHGjuFaACTSeFpNjGqe2sAPliXwg1z1tWaxAFmLdvNqj0ZF36zwEgY/wocXg9rX21gxELUTBK5cHtmk2LOrbEAJBw6CcC4Xm3Y98JY3rollnZBvvw2fSSvTekDwB3vb2bFruMXPkFXzCSIvhFWvgRJXzTqzyDcm1StCGE145sdfGAdxr//xXE1Lgb96Gdb+XLL0Yr3B18ah1IXsGh0US58MtkomY+aYcxhfiHniybrYqpWJJELcYG+T0znwU9+r7Jt6zNXEtDMq5YzzlFaBF8/AElLoN+dMO4/YPY4/3miSZM6ciHsaHxMGNtnjK6yrc8/f2L13sxazjiHpw9c/y4MfQwS3odPJ0Nx3euVClEXSeRCNIC/jyfbZ4xm6Z8vw9vD+DP6w/xN9R8tajLBqGfh6tdg/0qYPxby0mwYsWjKpGpFiIu0Iy2X8a+vrXg/rEso04ZE8uLSXXQI9uOOwZEUFJcxqnvrGuvd2fczLLoDvP3h1kXQppf9ghdOQ+rIhXCw0yVl3PLORram5pz32Oi2LfjygSF4mit9ID62HRZMguI8mPQ/uGSUDaMVzkjqyIVwsGZeHiy691IGRgVV2X55l9BqxyYdzaPz35ZVXUS6TS+4ewUERhkJPeEDG0csmhIpkQthA0Wl5Xh7mFBKkZ5bSHpuEVn5xXywLoV1+7Mrjtv2zGhaNqu08ERxPnx+h1HdMvQxGPkPoz5dNHlStSKEC9FaM/PbnRV91ruHtcCk4OO7BhLo5wXlZbD0CaNHS/QNxvqfnj6ODVrYnE2rVpRS85VSGUqppIbcQAhRlVKKGdf0JNBaEt+VnseOtDz6PveTMVrU7AET/gujZhp9zT+aCKdP0PHp74mc/v2FjygVTV59PrN9AIyxcRxCuJ21T42sVqdesd6oUjD0EbjxfTj6O9mvDaMdxwCIenophSXl9g5XOLF6Va0opSKB77TW0fW5qFStCHFh8otK6TXjx2rbZ0/uw0eLPuMdr1fQKO4ueZzfdRdi2wfwxQNDHBCpsBXptSKEi/P38eSZCT2qbX/ks60k6K5cXzIT5dOSL5q9xATzJn4/nEPSUVk+ThgaLZErpe5RSsUrpeIzM+s5VFkIUWHa0Ci+fWgoXh4mZlzdg7lTYyv2zXtkMkF/Xg3hfXjTczYPm5cw5Y0f2Zxio2XqhEuRqhUhXEmlCbdOa2++Lh9MqxH3MWTYlfh4ymIVrkyqVoRwF54+cMN7WO76hQ1+w7nWvI4r1kwm+blYTq6ZB8UFjo5QOMB5S+RKqU+B4UAIcBx4Vmv9Xl3nSIlcCPs4kJrG/Lkvc6v5Z7qbUsnXvnxdPhj/oXfz8CpjDdK/jOnK9X0jaNNS+qI7MxkQJIQby8grYsCLPxOrkrnF4xcmmNbjo0rZYrmET8pH8m35pRThDcDcqf0YE93GwRGLmkgiF0JwqriM+WsPknYsHZ+di7jXbzVtSg6Rp5vxRflQPim/gr26HQA3D2jH8xN71Twbo3AISeRCiOq0hkPrIOF99M6vUeUlbLZ04ZOyK1hqGUgxXhx4cRwmSeZOQRK5EKJup7Jh2yfo+PdRJ/aTo/34snwo20LGMeuBqfh4yVJzjiaJXAhRP1rDwdXo+Pcp3fktXpSx29KONsOmETDwVvBv7egI3ZZ0PxRC1I9S0PFy1KQPKPzTTv5eeieFeBOwdiaWV7pjWXAT25a/T0nR6SqnFZWWs+ngCZmwy0lJiVwIN1ZUWk7MjB9pZ0nlBvMarjOvJUydIA8/fGMnUdBtEgP+d5LSSnN0PXlVVz7ZeJj+kYHMntLXccE3MVK1IoS4KOv3Z3PzOxswYWGwaQc3mFczxrQZX1XCfksYS8qH8UX5UI4RXOW8x67swp+v6OygqJsWSeRCiIv2fWI6H21I4YHhlxB/6CTzV2xjnHkj0/zW060kCY3iROvBLCwdyhtp3Sr6pr9/Z39GdG3l4OhdnyRyIUSjOzO7Yo+wFphyUmDbQtj2CeQcBi9/irtezf0J4Wyw9CAsNJgP7xpI2wBfxwbtwiSRCyHsw2KBw+tg66ew8ysoKaBEm0mwdGW1JYaQPmO464ZrwWSioLiMOav2MbFPWzq39nd05E5PErkQwv7Kiik/tJ6DG74h5PhaAvL2AJCpW7DO0otfy3uxxhJDJgG0C/LlhYm9GNYl1MFBOy9J5EIIh8vPOsIXiz/G/+gaLjMlEqryANhlac+vlhjWWHqh2l/Ke38cireHTLl7LknkQgin8u7qfbTM28NNAXsp3fsz5tQNmHQZhdqLjZburFe9MXW+gnuuG0tgc29Hh+sUJJELIZxbcQGlB9bw1eIPiS3dQidTOgDpOoj9nl045N2Fa8eNh/C+nPZoya70fIZ1DkEpYx6YotLyJr9whiRyIYTLSDqaS8bhvaRs/p6QzA1Eq4N0NB2r2H9Eh7DdEsV2SxRHfLuyuiCCHPzpHtaCgVFBfLAuBTAGJk2Ka0dyRj6XdgymzKLxMKmK5O9qJJELIVxSabmF99YeJHHfIU7uj6eXOkAv00Gi1UGiTMcrjjuiQ0i0dCTJEkWi7sh2SxS5NK/1umN6tmHO1FiXSuqSyIUQLq/coqvMj75ux342rv2FUQFpXFK+j+y9m4jgbMk9zyecjUXt2VLanmQdQbJuy2HdGkstU0h996ehzFq2m7X7svD1NLPlGeda51QSuRDCPRSehPRtkLYV0rZA+lY4mVKxW5u9KQ+6hFUngtha1KYiwR/SrSmn5qS9+L5L2Zqag7enmclx7fDycMxcgpLIhRDuqygPspIhcxdk7obMPZCxG3IPVxxiMXmSamoLod0oaNGJRYeaszY3hEO6NWVUn4s91N+bGVf35N21BxjZtRXDu7aiZ3gLmy7CIYlcCCHOVVwAWXutyf1Mgt8FOYcqDrGYPDlEGOmlzfH19SW70EIpHpRhphQPSrXxuqTyNswV20dFRxAb1Yrjp8rx9vLE18uT02XQzNsTH08PlMlsTB2szKBMoEyUaigug+a+3tZ9xnbVaUSDE7ksCyKEaJq8m0PbWOOrspJT1hL8HkyZu4jK3ENU4UkoL4HycrAUk51XQGFREa2amSgoLMRsKcODMjwox1uVnb3WHuMrrNLlzzfbjKf1qzFJIhdCuBcvPwjvY3zVovJkvUGVXmutOV1SxqYDmVwS5MUd763jRN4pPCjHjAUTFpTSmNCYsGDGgsJ4H9TMTN7pEkxYrPuNYxQaMxbgyQb/SFK1IoQQjaCguAw/LzNKKbTW3PH+Zn7dm8mEmDBmTzb+07BoOF1Shtmk2HDgBOEBPqxNzuLuyzpiNpukjlwIIVyZrNkphBBuTBK5EEK4OEnkQgjh4iSRCyGEi5NELoQQLk4SuRBCuLh6JXKl1Bil1B6l1D6l1HRbByWEEKL+zpvIlVJm4C1gLNADuFkp1cPWgQkhhKif+pTIBwD7tNYHtNYlwELgWtuGJYQQor7qk8jbAqmV3h+xbhNCCOEE6jNpVk0T8FYb16+Uuge4x/q2WCmVdDGB2UEIkOXoIM5DYmw8rhCnxNg4XDXGDg29WH0S+RGgXaX3EUDauQdprecB8wCUUvENnTPAXiTGxuEKMYJrxCkxNg53jLE+VSubgc5KqSillBcwBfimsQIQQghxcc5bItdalymlHgJ+AMzAfK31DptHJoQQol7qtbCE1nopsPQCrjuvYeHYlcTYOFwhRnCNOCXGxuF2MdpkPnIhhBD2I0P0hRDCxTVqInemofxKqRSl1Hal1FalVLx1W5BS6ielVLL1e6B1u1JKvW6NO1EpFVv31S8qrvlKqYzK3TMbEpdS6nbr8clKqdvtEOMMpdRR6/PcqpQaV2nf09YY9yilrqq03Wa/D0qpdkqplUqpXUqpHUqph63bneZZ1hGj0zxLpZSPUmqTUmqbNcaZ1u1RSqmN1mfymbWjA0opb+v7fdb9keeL3YYxfqCUOljpOfaxbnfI3431+mal1Bal1HfW9/Z5jlrrRvnCaAjdD3QEvIBtQI/Gun4D4kkBQs7Z9jIw3fp6OvAv6+txwDKMPvODgI02jGsYEAskNTQujPVgD1i/B1pfB9o4xhnAEzUc28P6b+0NRFl/B8y2/n3AWLg81vraH9hrjcVpnmUdMTrNs7Q+j+bW157ARuvzWQRMsW6fC9xvff0AMNf6egrwWV2x2zjGD4AbazjeIX831ns8BnwCfGd9b5fn2JglclcYyn8t8D/r6/8BEytt/1AbNgABSqkwWwSgtV4NnLjIuK4CftJan9BanwR+AsbYOMbaXAss1FoXa60PAvswfhds+vugtU7XWv9ufZ0P7MIYcew0z7KOGGtj92dpfR4F1ree1i8NjAQWW7ef+xzPPN/FwBVKKVVH7LaMsTYO+btRSkUA44F3re8VdnqOjZnInW0ovwZ+VEolKGPUKUBrrXU6GH9kQCvrdkfHfqFxOSreh6wfVeefqbJwhhitH0v7YpTUnPJZnhMjONGztFYHbAUyMJLbfiBHa11Ww/0qYrHuzwWC7R2j1vrMc3zB+hz/q5TyPjfGc2Kx9b/1bOAvgMX6Phg7PcfGTOT1GspvR0O01rEYszY+qJQaVsexzhb7GbXF5Yh45wCdgD5AOvCKdbtDY1RKNQeWAI9orfPqOrSWeGweZw0xOtWz1FqXa637YIzaHgB0r+N+ThGjUioaeBroBvTHqC55ylExKqUmABla64TKm+u4X6PG2JiJvF5D+e1Fa51m/Z4BfInxC3r8TJWJ9XuG9XBHx36hcdk9Xq31cesfkwV4h7Mf9xwWo1LKEyNBLtBaf2Hd7FTPsqYYnfFZWuPKAVZh1CsHKKXOjDOpfL+KWKz7W2JUw9k7xjHWqiuttS4G3sexz3EIcI1SKgWj6mskRgndPs+xESv5PTAaD6I42yDTs7Guf4Gx+AH+lV6vw6gL+zdVG8Jetr4eT9XGkU02ji+Sqg2JFxQXRunjIEaDTaD1dZCNYwyr9PpRjHo8gJ5UbZw5gNE4Z9PfB+sz+RCYfc52p3mWdcToNM8SCAUCrK99gTXABOBzqjbSPWB9/SBVG+kW1RW7jWMMq/ScZwOzHP13Y73PcM42dtrlOTb2DzAOo2V+P/C3xn5AFxBHR+vD2AbsOBMLRh3UCiDZ+j2o0i/CW9a4twNxNoztU4yP06UY//ve1ZC4gGkYDSH7gDvtEONH1hgSMebaqZyM/maNcQ8w1h6/D8BQjI+cicBW69c4Z3qWdcToNM8SiAG2WGNJAp6p9De0yfpMPge8rdt9rO/3Wfd3PF/sNozxF+tzTAI+5mzPFof83VS6x3DOJnK7PEcZ2SmEEC5ORnYKIYSLk0QuhBAuThK5EEK4OEnkQgjh4iSRCyGEi5NELoQQLk4SuRBCuDhJ5EII4eL+HygjUJ7boRsXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-1\n",
    "epochs = 20\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_20epochs_zoomcrop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop, wd=1e-5, LabelSmoothing, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,2.0), do_rand=True)\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0718, -0.0658, -0.0117,  ...,  0.0062,  0.0119,  0.0428],\n",
      "        [ 0.0639, -0.0524, -0.0286,  ..., -0.0625,  0.0323, -0.0058],\n",
      "        [ 0.0173,  0.0078, -0.0237,  ...,  0.0203, -0.0095,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0226,  0.0317,  ...,  0.0056,  0.0121, -0.0259],\n",
      "        [-0.0409,  0.0348,  0.0044,  ..., -0.0138, -0.0759, -0.0460],\n",
      "        [-0.0812,  0.0199,  0.0363,  ..., -0.0296, -0.0574,  0.0551]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f7a9423e158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.245312</td>\n",
       "      <td>5.047501</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.783428</td>\n",
       "      <td>4.216805</td>\n",
       "      <td>0.175061</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.898960</td>\n",
       "      <td>2.922734</td>\n",
       "      <td>0.450246</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.130514</td>\n",
       "      <td>2.259289</td>\n",
       "      <td>0.600123</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.783135</td>\n",
       "      <td>2.181058</td>\n",
       "      <td>0.624079</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.629166</td>\n",
       "      <td>1.959982</td>\n",
       "      <td>0.665233</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.606921</td>\n",
       "      <td>2.161095</td>\n",
       "      <td>0.625307</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.589913</td>\n",
       "      <td>2.249611</td>\n",
       "      <td>0.600737</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.561589</td>\n",
       "      <td>2.191021</td>\n",
       "      <td>0.617322</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.689677</td>\n",
       "      <td>2.371197</td>\n",
       "      <td>0.565725</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.691874</td>\n",
       "      <td>2.550238</td>\n",
       "      <td>0.546683</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.707616</td>\n",
       "      <td>2.473767</td>\n",
       "      <td>0.563268</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.638625</td>\n",
       "      <td>2.472267</td>\n",
       "      <td>0.558354</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.595789</td>\n",
       "      <td>2.386350</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.598348</td>\n",
       "      <td>2.319826</td>\n",
       "      <td>0.580467</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.551180</td>\n",
       "      <td>2.396466</td>\n",
       "      <td>0.584152</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.524808</td>\n",
       "      <td>2.377810</td>\n",
       "      <td>0.579238</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.531762</td>\n",
       "      <td>2.187493</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.417459</td>\n",
       "      <td>2.004126</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.367288</td>\n",
       "      <td>1.968129</td>\n",
       "      <td>0.688575</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.363258</td>\n",
       "      <td>1.834837</td>\n",
       "      <td>0.732187</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.337855</td>\n",
       "      <td>1.827623</td>\n",
       "      <td>0.733415</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.303985</td>\n",
       "      <td>1.902574</td>\n",
       "      <td>0.711302</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.205563</td>\n",
       "      <td>1.804980</td>\n",
       "      <td>0.748157</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.211960</td>\n",
       "      <td>1.635796</td>\n",
       "      <td>0.786855</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.178686</td>\n",
       "      <td>1.792257</td>\n",
       "      <td>0.749386</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.132657</td>\n",
       "      <td>1.704104</td>\n",
       "      <td>0.773342</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.091930</td>\n",
       "      <td>1.543230</td>\n",
       "      <td>0.814496</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.072374</td>\n",
       "      <td>1.628726</td>\n",
       "      <td>0.788698</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.029392</td>\n",
       "      <td>1.497517</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.966174</td>\n",
       "      <td>1.490916</td>\n",
       "      <td>0.820025</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.976289</td>\n",
       "      <td>1.531963</td>\n",
       "      <td>0.816953</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.946278</td>\n",
       "      <td>1.447605</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.907445</td>\n",
       "      <td>1.373739</td>\n",
       "      <td>0.853194</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.883449</td>\n",
       "      <td>1.417004</td>\n",
       "      <td>0.855037</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.905062</td>\n",
       "      <td>1.464468</td>\n",
       "      <td>0.850123</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.843421</td>\n",
       "      <td>1.409097</td>\n",
       "      <td>0.845823</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.798576</td>\n",
       "      <td>1.375229</td>\n",
       "      <td>0.867322</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.799662</td>\n",
       "      <td>1.341294</td>\n",
       "      <td>0.862408</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.755400</td>\n",
       "      <td>1.338293</td>\n",
       "      <td>0.875307</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.759357</td>\n",
       "      <td>1.311938</td>\n",
       "      <td>0.873464</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.743559</td>\n",
       "      <td>1.278190</td>\n",
       "      <td>0.892506</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.720686</td>\n",
       "      <td>1.284979</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.727071</td>\n",
       "      <td>1.258685</td>\n",
       "      <td>0.892506</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.704340</td>\n",
       "      <td>1.240115</td>\n",
       "      <td>0.896806</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.679295</td>\n",
       "      <td>1.236793</td>\n",
       "      <td>0.897420</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.658101</td>\n",
       "      <td>1.236409</td>\n",
       "      <td>0.899877</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.631638</td>\n",
       "      <td>1.221398</td>\n",
       "      <td>0.904177</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.639033</td>\n",
       "      <td>1.224495</td>\n",
       "      <td>0.903563</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.658124</td>\n",
       "      <td>1.212213</td>\n",
       "      <td>0.910934</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.635755</td>\n",
       "      <td>1.204781</td>\n",
       "      <td>0.908477</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.605027</td>\n",
       "      <td>1.204672</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.603657</td>\n",
       "      <td>1.197262</td>\n",
       "      <td>0.911548</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.582472</td>\n",
       "      <td>1.196715</td>\n",
       "      <td>0.911548</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.580027</td>\n",
       "      <td>1.195767</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.617725</td>\n",
       "      <td>1.195449</td>\n",
       "      <td>0.907862</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.607512</td>\n",
       "      <td>1.196046</td>\n",
       "      <td>0.909705</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.588380</td>\n",
       "      <td>1.195697</td>\n",
       "      <td>0.907862</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.589751</td>\n",
       "      <td>1.195661</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.563402</td>\n",
       "      <td>1.195074</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_010\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop 1.2, cutout p0.5, wd=1e-5, LabelSmoothing, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.2), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.5)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0718, -0.0658, -0.0117,  ...,  0.0062,  0.0119,  0.0428],\n",
      "        [ 0.0639, -0.0524, -0.0286,  ..., -0.0625,  0.0323, -0.0058],\n",
      "        [ 0.0173,  0.0078, -0.0237,  ...,  0.0203, -0.0095,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0250, -0.0226,  0.0317,  ...,  0.0056,  0.0121, -0.0259],\n",
      "        [-0.0409,  0.0348,  0.0044,  ..., -0.0138, -0.0759, -0.0460],\n",
      "        [-0.0812,  0.0199,  0.0363,  ..., -0.0296, -0.0574,  0.0551]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f01dd2bf1e0>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.255710</td>\n",
       "      <td>5.044384</td>\n",
       "      <td>0.065111</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.651124</td>\n",
       "      <td>4.038998</td>\n",
       "      <td>0.225430</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.637526</td>\n",
       "      <td>2.740393</td>\n",
       "      <td>0.483415</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.849819</td>\n",
       "      <td>2.094747</td>\n",
       "      <td>0.657862</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.478132</td>\n",
       "      <td>1.893231</td>\n",
       "      <td>0.713145</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.332865</td>\n",
       "      <td>1.888494</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.317989</td>\n",
       "      <td>2.151523</td>\n",
       "      <td>0.636978</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.342926</td>\n",
       "      <td>2.263163</td>\n",
       "      <td>0.609337</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.347319</td>\n",
       "      <td>2.330727</td>\n",
       "      <td>0.589066</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.327741</td>\n",
       "      <td>2.168817</td>\n",
       "      <td>0.646192</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.375283</td>\n",
       "      <td>2.213864</td>\n",
       "      <td>0.622236</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.335027</td>\n",
       "      <td>2.462775</td>\n",
       "      <td>0.561425</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.335876</td>\n",
       "      <td>2.095467</td>\n",
       "      <td>0.668919</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.358171</td>\n",
       "      <td>2.143033</td>\n",
       "      <td>0.660319</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.305856</td>\n",
       "      <td>2.168572</td>\n",
       "      <td>0.649263</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.256836</td>\n",
       "      <td>2.216714</td>\n",
       "      <td>0.630221</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.242120</td>\n",
       "      <td>2.502421</td>\n",
       "      <td>0.552211</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.180745</td>\n",
       "      <td>1.844150</td>\n",
       "      <td>0.738329</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.167159</td>\n",
       "      <td>2.028055</td>\n",
       "      <td>0.679975</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.110309</td>\n",
       "      <td>1.871023</td>\n",
       "      <td>0.717445</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.047775</td>\n",
       "      <td>1.768977</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.036410</td>\n",
       "      <td>1.798943</td>\n",
       "      <td>0.746929</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.986280</td>\n",
       "      <td>1.728399</td>\n",
       "      <td>0.773342</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.941596</td>\n",
       "      <td>1.711936</td>\n",
       "      <td>0.761671</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.936481</td>\n",
       "      <td>1.774460</td>\n",
       "      <td>0.748157</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.905643</td>\n",
       "      <td>1.605318</td>\n",
       "      <td>0.796069</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.825927</td>\n",
       "      <td>1.572447</td>\n",
       "      <td>0.817568</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.867477</td>\n",
       "      <td>1.526310</td>\n",
       "      <td>0.834767</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.815656</td>\n",
       "      <td>1.469016</td>\n",
       "      <td>0.831695</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.771769</td>\n",
       "      <td>1.525679</td>\n",
       "      <td>0.819410</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.789269</td>\n",
       "      <td>1.468478</td>\n",
       "      <td>0.840295</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.734169</td>\n",
       "      <td>1.426123</td>\n",
       "      <td>0.850123</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.762069</td>\n",
       "      <td>1.397382</td>\n",
       "      <td>0.854423</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.702991</td>\n",
       "      <td>1.416238</td>\n",
       "      <td>0.851966</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.708272</td>\n",
       "      <td>1.319916</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.669191</td>\n",
       "      <td>1.331500</td>\n",
       "      <td>0.869165</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.681828</td>\n",
       "      <td>1.302895</td>\n",
       "      <td>0.880835</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.678602</td>\n",
       "      <td>1.305604</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.639526</td>\n",
       "      <td>1.265814</td>\n",
       "      <td>0.890663</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.642207</td>\n",
       "      <td>1.280915</td>\n",
       "      <td>0.887592</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.633361</td>\n",
       "      <td>1.264806</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.592956</td>\n",
       "      <td>1.241008</td>\n",
       "      <td>0.888206</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.568672</td>\n",
       "      <td>1.246070</td>\n",
       "      <td>0.893120</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.571923</td>\n",
       "      <td>1.201715</td>\n",
       "      <td>0.898649</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.568891</td>\n",
       "      <td>1.193812</td>\n",
       "      <td>0.907248</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.565264</td>\n",
       "      <td>1.194439</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.521291</td>\n",
       "      <td>1.201434</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.525037</td>\n",
       "      <td>1.186907</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.493758</td>\n",
       "      <td>1.175667</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.504886</td>\n",
       "      <td>1.168077</td>\n",
       "      <td>0.914619</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.519324</td>\n",
       "      <td>1.161227</td>\n",
       "      <td>0.908477</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.495282</td>\n",
       "      <td>1.156567</td>\n",
       "      <td>0.915233</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.512906</td>\n",
       "      <td>1.152666</td>\n",
       "      <td>0.912162</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.478377</td>\n",
       "      <td>1.148958</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.463853</td>\n",
       "      <td>1.139767</td>\n",
       "      <td>0.920762</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.477734</td>\n",
       "      <td>1.144465</td>\n",
       "      <td>0.917076</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.478915</td>\n",
       "      <td>1.144237</td>\n",
       "      <td>0.918305</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.494680</td>\n",
       "      <td>1.142831</td>\n",
       "      <td>0.918305</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.475075</td>\n",
       "      <td>1.141064</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.495837</td>\n",
       "      <td>1.141878</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_011\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 100 Epochs, normalize(imagenet_stats), zoom_crop 1.2, cutout p0.5, wd=1e-5, LabelSmoothing, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.2), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.5)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[-0.0419, -0.0259,  0.0045,  ...,  0.0454,  0.0042,  0.0342],\n",
      "        [-0.0261, -0.0003, -0.0019,  ...,  0.0437, -0.0226,  0.0193],\n",
      "        [-0.0138,  0.0676,  0.0795,  ..., -0.0042, -0.0007, -0.0760],\n",
      "        ...,\n",
      "        [-0.0257, -0.0303, -0.0092,  ...,  0.0228, -0.0438, -0.0980],\n",
      "        [ 0.0268, -0.0485,  0.0114,  ..., -0.0292,  0.0364,  0.0196],\n",
      "        [ 0.0127, -0.0127, -0.0065,  ..., -0.0281,  0.0167,  0.0331]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012,Geo Metro Convertible 1993\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "BMW M6 Convertible 2010,Suzuki SX4 Hatchback 2012,Ford E-Series Wagon Van 2012,Chevrolet Silverado 2500HD Regular Cab 2012,Volkswagen Golf Hatchback 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f7a9423e158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.245329</td>\n",
       "      <td>5.027651</td>\n",
       "      <td>0.060197</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.737675</td>\n",
       "      <td>4.197422</td>\n",
       "      <td>0.189803</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.900161</td>\n",
       "      <td>3.066196</td>\n",
       "      <td>0.423833</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.129447</td>\n",
       "      <td>2.268496</td>\n",
       "      <td>0.624079</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.581212</td>\n",
       "      <td>1.855884</td>\n",
       "      <td>0.734029</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.316579</td>\n",
       "      <td>1.730959</td>\n",
       "      <td>0.761056</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.170968</td>\n",
       "      <td>1.603254</td>\n",
       "      <td>0.796683</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.099219</td>\n",
       "      <td>1.735066</td>\n",
       "      <td>0.752457</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.071137</td>\n",
       "      <td>1.772412</td>\n",
       "      <td>0.746315</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.101140</td>\n",
       "      <td>1.717238</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.093247</td>\n",
       "      <td>1.828371</td>\n",
       "      <td>0.739558</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.158352</td>\n",
       "      <td>1.977779</td>\n",
       "      <td>0.695332</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.136267</td>\n",
       "      <td>1.978593</td>\n",
       "      <td>0.692875</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.094626</td>\n",
       "      <td>1.876330</td>\n",
       "      <td>0.724202</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.208433</td>\n",
       "      <td>2.020789</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.161482</td>\n",
       "      <td>2.018706</td>\n",
       "      <td>0.687346</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.181397</td>\n",
       "      <td>1.873548</td>\n",
       "      <td>0.718673</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.137074</td>\n",
       "      <td>2.095579</td>\n",
       "      <td>0.675061</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.143650</td>\n",
       "      <td>2.180148</td>\n",
       "      <td>0.626536</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.142911</td>\n",
       "      <td>1.906608</td>\n",
       "      <td>0.717445</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.143657</td>\n",
       "      <td>1.923453</td>\n",
       "      <td>0.722359</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.128740</td>\n",
       "      <td>1.940141</td>\n",
       "      <td>0.717445</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.119622</td>\n",
       "      <td>2.326537</td>\n",
       "      <td>0.621007</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.150770</td>\n",
       "      <td>1.999337</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.123939</td>\n",
       "      <td>1.993871</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.100337</td>\n",
       "      <td>2.076236</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.038419</td>\n",
       "      <td>1.803626</td>\n",
       "      <td>0.757371</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.036264</td>\n",
       "      <td>1.933172</td>\n",
       "      <td>0.711916</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.020794</td>\n",
       "      <td>1.643212</td>\n",
       "      <td>0.800369</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.011358</td>\n",
       "      <td>1.652080</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.987797</td>\n",
       "      <td>1.956899</td>\n",
       "      <td>0.728501</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.945994</td>\n",
       "      <td>1.611321</td>\n",
       "      <td>0.803440</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.948512</td>\n",
       "      <td>1.700500</td>\n",
       "      <td>0.780098</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.939171</td>\n",
       "      <td>1.802014</td>\n",
       "      <td>0.749386</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.884875</td>\n",
       "      <td>1.747695</td>\n",
       "      <td>0.762285</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.880688</td>\n",
       "      <td>1.690612</td>\n",
       "      <td>0.774570</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.869263</td>\n",
       "      <td>1.644113</td>\n",
       "      <td>0.798526</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.846122</td>\n",
       "      <td>1.644267</td>\n",
       "      <td>0.791155</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.787969</td>\n",
       "      <td>1.549026</td>\n",
       "      <td>0.823096</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.802385</td>\n",
       "      <td>1.536405</td>\n",
       "      <td>0.815111</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.787975</td>\n",
       "      <td>1.626846</td>\n",
       "      <td>0.792998</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.817555</td>\n",
       "      <td>1.515031</td>\n",
       "      <td>0.823710</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.794842</td>\n",
       "      <td>1.510672</td>\n",
       "      <td>0.834152</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.785120</td>\n",
       "      <td>1.513073</td>\n",
       "      <td>0.826781</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.729930</td>\n",
       "      <td>1.418453</td>\n",
       "      <td>0.857494</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.728178</td>\n",
       "      <td>1.439388</td>\n",
       "      <td>0.855651</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.719276</td>\n",
       "      <td>1.475259</td>\n",
       "      <td>0.839066</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.718960</td>\n",
       "      <td>1.440320</td>\n",
       "      <td>0.845209</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>1.500032</td>\n",
       "      <td>0.834767</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.686944</td>\n",
       "      <td>1.453774</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.703282</td>\n",
       "      <td>1.413435</td>\n",
       "      <td>0.853808</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.654822</td>\n",
       "      <td>1.393640</td>\n",
       "      <td>0.857494</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.647590</td>\n",
       "      <td>1.404444</td>\n",
       "      <td>0.858722</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.671115</td>\n",
       "      <td>1.452952</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.659686</td>\n",
       "      <td>1.312426</td>\n",
       "      <td>0.871622</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.616265</td>\n",
       "      <td>1.329781</td>\n",
       "      <td>0.872850</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.615386</td>\n",
       "      <td>1.301505</td>\n",
       "      <td>0.877764</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.618308</td>\n",
       "      <td>1.309645</td>\n",
       "      <td>0.877764</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.598396</td>\n",
       "      <td>1.312082</td>\n",
       "      <td>0.880835</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.599380</td>\n",
       "      <td>1.327691</td>\n",
       "      <td>0.870393</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.577285</td>\n",
       "      <td>1.264803</td>\n",
       "      <td>0.896192</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.599765</td>\n",
       "      <td>1.295423</td>\n",
       "      <td>0.879607</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.594903</td>\n",
       "      <td>1.280975</td>\n",
       "      <td>0.895577</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.559583</td>\n",
       "      <td>1.262913</td>\n",
       "      <td>0.894963</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.558355</td>\n",
       "      <td>1.254966</td>\n",
       "      <td>0.889435</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.561584</td>\n",
       "      <td>1.250609</td>\n",
       "      <td>0.898649</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.525769</td>\n",
       "      <td>1.230245</td>\n",
       "      <td>0.902948</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.551494</td>\n",
       "      <td>1.237820</td>\n",
       "      <td>0.903563</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.525330</td>\n",
       "      <td>1.198331</td>\n",
       "      <td>0.903563</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.531575</td>\n",
       "      <td>1.231296</td>\n",
       "      <td>0.902948</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.511811</td>\n",
       "      <td>1.194185</td>\n",
       "      <td>0.908477</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.495540</td>\n",
       "      <td>1.203204</td>\n",
       "      <td>0.909705</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.526126</td>\n",
       "      <td>1.189428</td>\n",
       "      <td>0.911548</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.497111</td>\n",
       "      <td>1.211228</td>\n",
       "      <td>0.906020</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.500274</td>\n",
       "      <td>1.193461</td>\n",
       "      <td>0.907862</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.519339</td>\n",
       "      <td>1.176026</td>\n",
       "      <td>0.917076</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.485540</td>\n",
       "      <td>1.174063</td>\n",
       "      <td>0.915233</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.490467</td>\n",
       "      <td>1.180826</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.474453</td>\n",
       "      <td>1.178204</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.460784</td>\n",
       "      <td>1.183161</td>\n",
       "      <td>0.912776</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.460732</td>\n",
       "      <td>1.176905</td>\n",
       "      <td>0.912776</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.487681</td>\n",
       "      <td>1.170626</td>\n",
       "      <td>0.918305</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.470396</td>\n",
       "      <td>1.167339</td>\n",
       "      <td>0.920147</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.459924</td>\n",
       "      <td>1.158147</td>\n",
       "      <td>0.923219</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.468554</td>\n",
       "      <td>1.157023</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.434265</td>\n",
       "      <td>1.160161</td>\n",
       "      <td>0.920147</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.456398</td>\n",
       "      <td>1.167035</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1.451993</td>\n",
       "      <td>1.160684</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.433339</td>\n",
       "      <td>1.159397</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.444387</td>\n",
       "      <td>1.156600</td>\n",
       "      <td>0.924447</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.434183</td>\n",
       "      <td>1.160864</td>\n",
       "      <td>0.921376</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.441448</td>\n",
       "      <td>1.156925</td>\n",
       "      <td>0.921376</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.426840</td>\n",
       "      <td>1.158448</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.440098</td>\n",
       "      <td>1.160026</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.423092</td>\n",
       "      <td>1.159373</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.465822</td>\n",
       "      <td>1.159625</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.463953</td>\n",
       "      <td>1.158556</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.443709</td>\n",
       "      <td>1.157534</td>\n",
       "      <td>0.918305</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.454909</td>\n",
       "      <td>1.157439</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.439265</td>\n",
       "      <td>1.157974</td>\n",
       "      <td>0.918305</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-5\n",
    "epochs = 100\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_100epochs_001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B0, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop 1.5, cutout p0.8, wd=1e-3, LabelSmoothing, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.5), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.8)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b0\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Parameter containing:\n",
      "tensor([[ 0.0578,  0.0263, -0.0778,  ..., -0.0094, -0.0485, -0.0246],\n",
      "        [-0.0734, -0.0396, -0.0109,  ...,  0.0324,  0.0119, -0.0037],\n",
      "        [ 0.0089, -0.0328,  0.0024,  ..., -0.0174,  0.0379, -0.0387],\n",
      "        ...,\n",
      "        [-0.0383,  0.0002, -0.0413,  ..., -0.0609, -0.0292,  0.0201],\n",
      "        [ 0.0377, -0.0567, -0.0270,  ..., -0.0283, -0.0108,  0.0571],\n",
      "        [-0.0219, -0.0084, -0.0193,  ..., -0.0436, -0.0485, -0.0315]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1280, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f7bb06ec158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "  (3): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "  (11): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (12): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (13): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (14): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "  (19): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (20): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (21): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (22): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "  (27): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (28): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (29): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (30): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "  (35): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (36): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (37): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (38): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "  (43): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (44): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (45): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (46): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (51): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (52): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (53): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (54): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (57): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (59): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (60): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (61): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (62): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "  (67): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (68): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (69): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (70): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (73): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (75): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (76): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (77): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (78): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (81): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (83): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (84): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (85): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (86): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (89): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "  (91): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (92): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (93): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (94): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (97): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (99): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (100): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (101): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (102): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (105): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (107): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (108): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (109): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (110): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (113): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (115): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (116): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (117): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (118): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (121): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "  (123): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (124): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (125): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (126): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (129): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Dropout(p=0.5)\n",
       "  (131): Linear(in_features=1280, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b0\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.255009</td>\n",
       "      <td>5.042468</td>\n",
       "      <td>0.063268</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.828648</td>\n",
       "      <td>4.323233</td>\n",
       "      <td>0.156634</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.046984</td>\n",
       "      <td>3.217035</td>\n",
       "      <td>0.380835</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.290459</td>\n",
       "      <td>2.419346</td>\n",
       "      <td>0.550983</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.820600</td>\n",
       "      <td>2.037461</td>\n",
       "      <td>0.657248</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.586259</td>\n",
       "      <td>1.978913</td>\n",
       "      <td>0.676290</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.457248</td>\n",
       "      <td>2.007910</td>\n",
       "      <td>0.673833</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.463569</td>\n",
       "      <td>2.042022</td>\n",
       "      <td>0.669533</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.446822</td>\n",
       "      <td>2.094139</td>\n",
       "      <td>0.656634</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.501967</td>\n",
       "      <td>2.276641</td>\n",
       "      <td>0.621007</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.513488</td>\n",
       "      <td>2.457724</td>\n",
       "      <td>0.578624</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.483247</td>\n",
       "      <td>3.242832</td>\n",
       "      <td>0.426290</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.498870</td>\n",
       "      <td>2.435102</td>\n",
       "      <td>0.575553</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.506521</td>\n",
       "      <td>2.403330</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.469939</td>\n",
       "      <td>2.707340</td>\n",
       "      <td>0.537469</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.464089</td>\n",
       "      <td>2.416486</td>\n",
       "      <td>0.603194</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.431264</td>\n",
       "      <td>2.102835</td>\n",
       "      <td>0.657248</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.332982</td>\n",
       "      <td>2.173817</td>\n",
       "      <td>0.657248</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.283895</td>\n",
       "      <td>1.982807</td>\n",
       "      <td>0.700246</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.247370</td>\n",
       "      <td>2.215065</td>\n",
       "      <td>0.630835</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.220325</td>\n",
       "      <td>2.098045</td>\n",
       "      <td>0.676904</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.152981</td>\n",
       "      <td>1.830357</td>\n",
       "      <td>0.751229</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.167068</td>\n",
       "      <td>1.780735</td>\n",
       "      <td>0.772113</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.129863</td>\n",
       "      <td>1.673826</td>\n",
       "      <td>0.791155</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.067343</td>\n",
       "      <td>1.652871</td>\n",
       "      <td>0.800369</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.041884</td>\n",
       "      <td>1.688207</td>\n",
       "      <td>0.774570</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.000277</td>\n",
       "      <td>1.626585</td>\n",
       "      <td>0.807740</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.990069</td>\n",
       "      <td>1.601176</td>\n",
       "      <td>0.814496</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.959799</td>\n",
       "      <td>1.580061</td>\n",
       "      <td>0.814496</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.965175</td>\n",
       "      <td>1.557211</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.870312</td>\n",
       "      <td>1.555536</td>\n",
       "      <td>0.835995</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.851866</td>\n",
       "      <td>1.530450</td>\n",
       "      <td>0.843366</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.862183</td>\n",
       "      <td>1.505398</td>\n",
       "      <td>0.840295</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.839629</td>\n",
       "      <td>1.473455</td>\n",
       "      <td>0.841523</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.775634</td>\n",
       "      <td>1.436483</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.785598</td>\n",
       "      <td>1.395860</td>\n",
       "      <td>0.877764</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.758895</td>\n",
       "      <td>1.402317</td>\n",
       "      <td>0.872236</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.735983</td>\n",
       "      <td>1.363095</td>\n",
       "      <td>0.885749</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.732241</td>\n",
       "      <td>1.378924</td>\n",
       "      <td>0.875307</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.727955</td>\n",
       "      <td>1.372713</td>\n",
       "      <td>0.874693</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.704614</td>\n",
       "      <td>1.311170</td>\n",
       "      <td>0.893120</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.659095</td>\n",
       "      <td>1.293752</td>\n",
       "      <td>0.899877</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.678696</td>\n",
       "      <td>1.327683</td>\n",
       "      <td>0.889435</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.682653</td>\n",
       "      <td>1.293765</td>\n",
       "      <td>0.894963</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.628285</td>\n",
       "      <td>1.280521</td>\n",
       "      <td>0.904791</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.626707</td>\n",
       "      <td>1.275926</td>\n",
       "      <td>0.902948</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.600186</td>\n",
       "      <td>1.267394</td>\n",
       "      <td>0.901106</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.592549</td>\n",
       "      <td>1.255444</td>\n",
       "      <td>0.904791</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.597146</td>\n",
       "      <td>1.252422</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.589263</td>\n",
       "      <td>1.239802</td>\n",
       "      <td>0.910934</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.563516</td>\n",
       "      <td>1.220498</td>\n",
       "      <td>0.918305</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.551795</td>\n",
       "      <td>1.223600</td>\n",
       "      <td>0.915848</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.547392</td>\n",
       "      <td>1.221772</td>\n",
       "      <td>0.915848</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.544591</td>\n",
       "      <td>1.215976</td>\n",
       "      <td>0.915233</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.583985</td>\n",
       "      <td>1.213228</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.539379</td>\n",
       "      <td>1.213489</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.536679</td>\n",
       "      <td>1.210282</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.566839</td>\n",
       "      <td>1.212118</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.549427</td>\n",
       "      <td>1.212744</td>\n",
       "      <td>0.918305</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.542147</td>\n",
       "      <td>1.212116</td>\n",
       "      <td>0.919533</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD8CAYAAACINTRsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XeYlNXZ+PHvme2V7cvCArsgHZa2IooFQWmamChRrDEafWP0RzRvolheo8YYNVWNvcRosAVrxK4gqID0XpaysAtshV122T5zfn+cZ2d7n7bD/bmuuWbmaXMeHvaeM+ec5z5Ka40QQgj/YPN2AYQQQriOBHUhhPAjEtSFEMKPSFAXQgg/IkFdCCH8iAR1IYTwIxLUhRDCj0hQF0IIPyJBXQgh/EigOw4aEN5HTxg11B2HFkIIv7Ru3boirXViT4/jlqAe2CeJBU8s5prT09xxeCGE8DtKqQOuOI7bml/ufX8bFTV17jq8EEKIVri1Tf3ud7e68/BCCCGacUtQT0+IAODdDYd4d0OuOz5CCCFEK9zSph4REsjyu2Yw+aEvue3NTUwYEEuaFeiFEKK52tpacnNzqaqq8nZR3C40NJTU1FSCgoLccny3BHUFJEWH8toNp3HF86t57fuD3DV3pDs+SgjhB3Jzc4mKiiItLQ2llLeL4zZaa4qLi8nNzSU9Pd0tn+HWNvUzhiRw3sgknlu+jxdW7HPnRwkherGqqiri4+P9OqADKKWIj4936y8St9989PsfjQHgwSU7kFmWhBBt8feAXs/d5+n2oJ7SJ4zbZw8HYMeRMnd/nBBCnNQ8kiZg3qRUAL7Yke+JjxNCiC4pKSnhqaee6vJ+c+fOpaSkxA0l6j6PBPWkqFAyB8WyZPMRT3ycEEJ0SVtB3W63t7vfRx99RExMjLuK1S0eS+h1YUYKu/LLyMqXJhghhG9ZuHAhe/fuZfz48Zx66qmce+65XHHFFYwdOxaAH/3oR0yaNInRo0fz3HPPOfdLS0ujqKiI7OxsRo4cyQ033MDo0aOZOXMmlZWVXjkXtwxpbM3csSnc/+F2Ptx8hNvOj/LUxwohepn7/7uN7YePu/SYo/pF87sfjG5z/cMPP8zWrVvZuHEjy5Yt44ILLmDr1q3OYYcvvfQScXFxVFZWcuqpp3LJJZcQHx/f5BhZWVm8/vrrPP/881x66aW8/fbbXHXVVS49j87wWE09KTqU09LjWLT6oKc+UgghumXy5MlNxpE//vjjjBs3jilTppCTk0NWVlaLfdLT0xk/fjwAkyZNIjs721PFbaJTNXWlVDZQBtiBOq11Znc+bFhyFKv2HWX74eOM6hfdnUMIIfxcezVqT4mIaLgDftmyZXzxxResXLmS8PBwpk2b1uo485CQEOfrgIAArzW/dKWmfq7Weny3Avq3j8PrV3DVlEEAPC83IgkhfEhUVBRlZa3395WWlhIbG0t4eDg7d+5k1apVHi5d13imTb36OOz+hGHzAjk1LZZluwqoqrUTGhTgkY8XQoj2xMfHM3XqVMaMGUNYWBjJycnOdbNnz+aZZ54hIyOD4cOHM2XKFC+WtGOdDeoa+EwppYFntdbPdbRDEynjQNshfzu3njeMK19YzZLNR7jEGr8uhBDe9tprr7W6PCQkhI8//rjVdfXt5gkJCWzd2pBq/De/+Y3Ly9dZnW1+maq1ngjMAW5WSp3dfAOl1I1KqbVKqbWFhYVNV6aMM89HNnLGkHj69Qnlq50FPSq4EEKIljoV1LXWh63nAuBdYHIr2zyntc7UWmcmJjabZq/PAAiLhSObUEoxZXA83+wpoqq2/YH9QgghuqbDoK6UilBKRdW/BmYCXZvSSClTW8/bDMCMkcmUVtaSlV/e9RILIYRoU2dq6snAN0qpTcD3wBKt9Sdd/qSUcZC/Dey1DO9rbj7aLXeXCiGES3XYUaq13geM6/En9c0Aew0U7iQt0YxDXbJFOkuFEMKVPHZHKSnmTiuObCIwwIZS8NXOAvKP+//0VUII4SmeC+pxgyE4Eo5sAuCpKyYCSOZGIUSvFBkZCcDhw4eZN29eq9tMmzaNtWvXerJYHgzqNptpgrGC+pyxKcSEB7GnUDpLhRC9V79+/Vi8eLG3i+HkuaAO1giYLeAwQxkHxYWTc7TCo0UQQojW3HHHHU1yqt93333cf//9zJgxg4kTJzJ27Fjef//9FvtlZ2czZoyZtrOyspL58+eTkZHBZZdd5pX8Lx5LvQuYoF5bAcV7IHE4qXHhbDtU6tEiCCF83McLTeXPlfqOhTkPt7vJ/PnzufXWW/nlL38JwFtvvcUnn3zCbbfdRnR0NEVFRUyZMoUf/vCHbc4z+vTTTxMeHs7mzZvZvHkzEydOdO15dIKHg3qGeT6yCRKHExJoI7u4ghPVdUSEeLYoQgjR2IQJEygoKODw4cMUFhYSGxtLSkoKt912G8uXL8dms3Ho0CHy8/Pp27dvq8dYvnw5CxYsACAjI4OMjAxPngLg6aCeMBwCQ01Qz7iUUSnRvMMhNuWUcMYpCR4tihDCR3VQo3anefPmsXjxYvLy8pg/fz6LFi2isLCQdevWERQURFpaWqtpdxtrqxbvKZ5tUw8IhOTRzs7S80aaTGi5Jd7JOyyEEI3Nnz+fN954g8WLFzNv3jxKS0tJSkoiKCiIpUuXcuDAgXb3P/vss1m0aBEAW7duZfPmzZ4odhOeDepg2tWPbAatSY0NIzTIxq48ubNUCOF9o0ePpqysjP79+5OSksKVV17J2rVryczMZNGiRYwYMaLd/W+66SbKy8vJyMjg0UcfZfLkFmmy3M7zDdkp42DtS3Asm8C4dIYlR0lQF0L4jC1bGjppExISWLlyZavblZeb4dhpaWnOtLthYWG88cYb7i9kO7xTUwdnE8yolGi2HCpFa+3xogghhL/xfFBPGgW2QGdQH9O/D6WVteQek3Z1IYToKc8H9cAQSBzpDOojU8wE1DuOHPd4UYQQvuNk+bXu7vP0fFAHq7N0E2jNCCsN70vf7vdKUYQQ3hcaGkpxcbHfB3atNcXFxYSGhrrtM7xzx0/KONj4bzh+mIg+/QFYte+oV4oihPC+1NRUcnNzaTEVph8KDQ0lNdV9Kce9F9TBzITUpz/zTx3Ap9vy0Fp7feC+EMLzgoKCSE9P93Yx/IJ3ml/6jgFUwwiYftEcq5DOUiGE6CnvBPXgCEgY2mQEDMC2w5LcSwghesI7QR0aOkuBoUkm2fz+IknDK4QQPeHdoH78EJQXEhUaREJkMAeKT3itOEII4Q+8G9QB8kxtPS0+gv1FEtSFEKInvBfU+1p5hq1k+IMTI9hbKEFdCCF6wntBPSwGwuPhqLnpaGhSFEXl1Rw7UeO1IgkhRG/nvaAOEDMISg4CMDA+HIBV+4q9WSIhhOjVvBzUB0KJSTo/OCECgOVZRd4skRBC9GreDeqxg6AkBxwOhiZHkRAZQq3d4dUiCSFEb+b9mrqjFsrzABjRVybMEEKInvByUE8zz8dME8yIvlHszi/D7vDvTG1CCOEu3q+pg7OzdHjfKKrrHGTLTUhCCNEtXg7qA8yz1VlaP2GGNMEIIUT3eDeoB4VBZLIzqJ+SFIlNwU6ZBUkIIbql00FdKRWglNqglPrQpSWIGehsUw8NCiAtIYKPtua59COEEOJk0ZWa+q+AHS4vQaMbkADsDs2egnLKqmpd/lFCCOHvOhXUlVKpwAXACy4vQcxAk63RXgfA/5s+FIADxZKGVwghuqqzNfW/A7cDrr8zKHYQOOqg7DAAI1PMRNQHj0pQF0KIruowqCulLgQKtNbrOtjuRqXUWqXU2i5NHttsWGP/mDAAjpRWdf4YQgghgM7V1KcCP1RKZQNvANOVUv9uvpHW+jmtdabWOjMxMbHzJYgZZJ6tztI+YUEEBSgKy6o7fwwhhBBAJ4K61vpOrXWq1joNmA98pbW+ymUl6JMKKGdNXSlFYmSIBHUhhOgG745TBwgMgeh+zrHqAIlRIRSWS1AXQoiuCuzKxlrrZcAyl5ciZmCTYY0RIYF8k9WFdnkhhBCAL9TUocVY9Vq7A4cGrSWxlxBCdIWPBPX6sermhqO5Y1MApF1dCCG6yHeCunZAaS4AQxIjAdhXJNkahRCiK3wjqMdawxrrp7ZLNFPb7SuUoC6EEF3hG0G92Q1I/fqEERxoY39RuRcLJYQQvY9vBPXoVFABzhuQbDZFenwE+6X5RQghusQ3gnpAIET3bzICZnBihDS/CCFEF/lGUAfTrt4oqKcnRHDwaAW1dtfnEBNCCH/lO0E9ZmCTu0oHxoVT59DkH5fEXkII0Vk+FNQHQdkRqDNj0/vHmmyNm3JKvVkqIYToVXwoqNePgMkBYHS/PgDsLZQRMEII0Vk+GNRNE0xcRDDDkiNZf/CYFwslhBC9i+8E9WY3IAFMHBjLxpwSyQEjhBCd5DtBPSoFbEFNRsBkpMZQUlFL7rFKLxZMCCF6D98J6rYAM2HGsYaaekaqaVd/d8Mhb5VKCCF6Fd8J6tAir/qolGgA3lyT460SCSFEr+JbQb3ZDUg2m+LSzFQOlVRSXWf3YsGEEKJ38K2gHjMQThRATYVzUXF5DQC/eHWdt0olhBC9ho8F9TTzXNrQ3PLQxWMBWLpLprcTQoiO+FhQt8aqN+osTY4Odb6WPDBCCNE+3wzqjcaqA/z10nEAHCiWrI1CCNEe3wrqkckQENIiqA/vGwXAp9vyvVEqIYToNXwrqNtsEDOgyQgYaJiz9E+f7vJGqYQQotcI9HYBWogZ1CKohwYFEB4cwKRBsV4qVDc57OamKiGE8BDfqqmDaVc/dqDF4kmDYimvrvNCgbqpeC/8IQUOb/B2SYQQJxHfC+qxg6DyKFQdb7I4LiLYOWa9Vzi4EuzVcOA7b5dECHES8b2gnjDcPBfubLI4PiKEwrLq3pOxMX+beS7Y7t1yCCFOKr4X1JNHmef6oGjpFxNKZa2d45W9pAmmvvz5EtSFEJ7je0G9z0AIjoSCHU0W94sx09sdKukFaXi1hvyt5nXhTnDITVNCCM/wvaBus0HSyBbNFmnxEQAsXpfrjVJ1TXkBVBRD0miorWgx7l4IIdzF94I6mKCev83UeC0D48MBeOnb/d4qVecVWE0vGT+x3ksTjBDCMzoM6kqpUKXU90qpTUqpbUqp+91eqqTRZgRMecMdpJEhgSRGhRAV6ntD61uob08ffbF5lqAuhPCQztTUq4HpWutxwHhgtlJqiltL1UZn6WWZAyirqqOsqtatH99j+dvM9Hyxg8y4e+ksFUJ4SIdBXRvl1tsg6+HecYVJo81zsxru+AExAOzKK3Prx/dY/lZIts4haXSLTl8hhHCXTrWpK6UClFIbgQLgc6316la2uVEptVYptbawsIe5zyPiTXKvZjXcjAFmztL1B4/17PjuZK+Dwl2QZP3aSBoJxVlQ14tunBJC9FqdCupaa7vWejyQCkxWSo1pZZvntNaZWuvMxMTEnpcsaVRDh2P9oqhQ0uLD+X6/Dwf14j1gr4Fk658oeTQ46kxgF0IIN+vS6BetdQmwDJjtltI0ljza1HgdTecmHTcghi92+HAK3vrx6c7ml5HmWZpghBAe0JnRL4lKqRjrdRhwHrCz/b1cIGkU1FXB0X1NFh86Zm4+2p3vo+3qBdvBFggJw8z7+KHmfbNOXyGEcIfO1NRTgKVKqc3AGkyb+ofuLRZtjoC5+dxTAJj5t+VuL0K35G8zAT0w2LwPDDaBXWrqQggP6Mzol81a6wla6wyt9Rit9QOeKBiJI0DZWoyAOWdYQ3v93z7f7ZGidEn+toaml3pJI1v0DwghhDv45h2lAEFhEDe4RU3dZlMkRJpa8GNfZrF8dw9H2rhSVSmU5rQM6smjzMQf1T7aZCSE8Bu+G9TBGgHT8sadbxdOd76+5qXvWbm32JOlalv9EMyk5jV1qympwP1dEUKIk5tvB/Xk0XB0P9ScaLI4JDCArD/Mcb5/dVW2hwvWhuYjX+o5R8DInaVCCPfy7aCeNArQLSbMAAgKsLHsN9MACA/2kXwwBdshNAai+zVdHpMGQeHSWSqEcDvfDur1Nd42cqekJUSQFBXiO+l46ztJlWq63GYzHb/SWSqEcDPfDuqxaRAY1m6zRf1k1HV2L09EobX58mne9FIveVTXa+oHvoP3fmlSDwghRCf4dlC3BUDSiHaD+u2zzJymXp8RqeQg1JS1HdSTRsGJQijv5GgdreHTu2HjItj2ruvKKYTwa74d1MGMJGknde3YVJO5cXd+eZvbeET90MvmI1/qOUfAdLKzNPsbOLweAoJhxZ9lSjwhRKf4flBPHgUnCuBEUaurR6ZEAXDDK2s9WaqWnEF9ZOvruxrUv30MIhLhwr+ZjuJdS3peRiGE3/P9oJ7UerqAeo1Hvoy971PufX8rpRVemESjYBvEpkNIZOvrI5MgLK5zQT1vK+z5HE77BYy73NyEtfxPTab3E0KI1vh+UE9ufcKMxu6cMwKAsqo6Xll5gHEPfMbkP3zhidI1aC09QGNKmfWd6Sz97gkIioBTrzf9CmfeBkc2wZ4vXVdeIYRf8v2gHpkE4QntZjn8+VmDWywrKKtGe6pmW1tp8qi3F9TBygGzo0X7eHWdnYLjVeZNSQ5sXQyTroWwWLMsYz5Ep0ptXQjRId8P6mANB2y7ph5gU2Q/fAH7HprLdVPTncsLy6rdXjStNdc++ipoRyeC+iioKae6+ECTxcPv+YTJD32J3aFh1dNm4ZSbGjYIDIapv4KcVXDgWxefgRDCn/SOoJ402uRN6WAEiM2muPcHo3j1+skArNzn2pwwO44cJ23hEqrrGibueP37HBIq9pg3yQ0TQv3ls10cO9F0CrtPCuMA+OXfXnUuu+7lNc7XL3y2Hta9DGPmQcyAph8+8WqISILlf3bR2Qgh/FEvCeojofYElGR3avMx/cxcpv9Zm0t1nZ0jpZWdboqptTvYmXe81XVzHlsBmJp1vbKqWkaog1TqYKoiB6C1ZsZflvHEV3uY8PvPWZFlxqWvzT7Kb782QX64ykVrzeGSSr7aWeA8VumKZ8x5Tl0AwIebD/Pjp741NfigMDjjFti3lLfee9f3J98WQniFjyRN6UDjdAFxLdvPm4uNMKl5v9lT1CQAAyz6+WlMPSXB+X7Y3R9TY3ew68HZLN1ZyC/+vQ6Axy+fwNQh8cRHhgBw4RMrmhznrne38OBFY/jjxzt4O3gPu3Qqiz/exb9XHWyy3YLXN7Dh3pnMe2YlEE6uTmCYLYf0Oz9qsl0INfws8BP2xZzB9L9lA9nOdZ9vz2P2mBTIvA694q/ErnuCWauCyX74gg7/LYQQJ5feUVNPNKNbupLlcNyAmFaXX/nCasC0hactXEKNlV5g+D2fOAM6mGA86cGGETRbDzWtvb+2+iCD7/qI6wI+YZIti/ftU1sEdIBjFbVkNZp6L3nIeGbYNvCXoKe4MuALhquDfPPbs/l18noS1XHuKpje4hivrrLa4EOi2DHoSs4PWMcIdZADxQ3ZK3fmmaahvNKqjv5phBB+rHcE9ZBIiD8FDq7q9C7v3zy1zXUHik+w9sCxTh1nV14ZB4srALh88kC2PzDLuS5T7eTOwNcoHzyXf9ob5uK+aspA9j00l77RoQCcb029d/6oZIKm/ZZd4RM527aZPwS9xKchC0l9bhQ/r3yZjY7BrHK0vHnp2z3FPLnUtNvP3zSOMh3GLwI/4Js9DTdk3bF4MwAPLpH0vkKczJQ7hv1lZmbqtWtdfIfnlw/AN3+HX++AqORO7fL17kI+2nyER+Zl4HBo3lqbw8J3tjTZ5rUbTuOK51c73z9yyVj2FZ7g2eX7mh+OW88byq3nDaOkoobzHljMkpA7qQsIp//tq5j2xHqyiyvI+sMcggLMd2VljZ2R9zY0/+x9aC4BNpPB8fy/LKOqaB/v/SCQ+KMbIW8z9mn3sJoxnD4kHgClFG+uOcgdb5syTxgYw4aDJdwd+G9+FvAJZ1U/xhHi+dd1k/nHV1msyT7G+AExvHPTGdQ5NMGBveM7WwgBSql1WuvMHh+n1wT1wt3w5Kkw6yE4/eZuHcLh0Ay+q2lbdvbDF7Am+yg/eWYl0aGBbPrdTJRSaK1btHvve2guNpsCex361Ytw5KzFdsOXqL5jqLM7OFFtp094UJN93lmfy6/f2sS/rpvcZH7Vrkhb2DRFwFMXJDLzi1m8YJ/Lw3VXdLj/2zedwaRBsd36bCGEZ7gqqPeeqlziMOg3ETa93u1D2GyKSyamOt8/ekkGAKemxZH98AVsvm8WysqFrpTimasmObedNjzRBHSArx5AZX9DwA8fR/U1wxgDA2wtAjrAxRNTyX74gm4HdIC/Xjquyfu5Z02mcuiFXBHwFRF0nJ3ykqe/89yNWEIIr+o9QR1MHpS8LSY3Sjf95dJx7P/jXHY/OIdLTx3Q7razx/RlQFwYkSGBvHCN9QW6478m2Vbm9TDusm6XoysunpjKTyaZL6NPbj0LgKhptxKtKlg157Bzux0PzG51f8D5q6N+rP0Hmw5LoBfCD/We5heAE8Xwl2HmbsuZD7r++B0p3gvPTTOdttd9AoEhni9DYy/OgrLD2G/ZgLIFYLMpDpVU8o+vsrjvh6MJCQxgT0EZ5/11eau7Tx+RxEvXnkqt3cHQuz/mpmlD+PX5w5x9AkIIzzn5ml8AIuJh6CzY/JbnZwOqqYC3rjEJti79l/cDOpibkUoOErB7ibNpqH9MGH+8OIOQwAAATkmKIjm69bJ+tbOAvNIqPt+eD8DTy/Yy9O6PqW1lFqlau0Nq9kL0Ar0rqAOMmw/l+bB/mec+U2v46DcmqdjFL0DMQM99dnuGzzVT/n33j3Y3W33Xefxsaprz/d6H5nJppmnOmfLHL/nlovUA2HAQQSVD7/6YN9ccZGfeccb+7lPSFi5h6N0f89Syve46EyGEi/Su5heAumr48zAYej5c8oJ7PqO59a/AB/8PzrkDzr3LM5/ZWaufhY9vh+s/hwGTO71ba6N7lg5+jcRDX7Cg9ha+ckxsdb/9f5zr7EwWQrjOydn8AqbZY8wlsONDqGo9R4tLHdkES34Dg881Qd3XjL8SQvvAyidbrnPYzfyme5e2WKWUIjq0IUvE46cdJ/3whwQGBfFC0F/4ecASoOUX/j3vbWV/0Qk25ZS0WFdaWUvawiV8v/9oj05JCNF9va+mDpCzBl48Dy56EiZc5b7PqSyB584Bey38z3KISOh4H2/4/Hfw3eOwYINpjnE4YPu7sOwRKNoFASFww1fQd0yLXb/amc/U9GhCnj/b/Aq6cRl8eCtsf58366Zxzq9fxRYUzBNf7mlIV9DMpntn0ic8iFH3fkJFjclgKXlphOiak7emDpCaCXFDYNMb7vsMreG9X0JpLvzkZd8N6ACTbwRlM7nYt70HT58Bi68zsy1d9BSExZj3NSda7Dp9RDIha56Fot0w908QHgfzXoZz7uCywGX0fX8+SbYT/P5HLb8Q6o174DNq6hzOgA6w4eAxyqvrSFu4xPk4VNLxmHohRM/0zpo6wNePwtI/wK1bXN9xaa+DFX+BZQ/B7IebTljhq965ETa/aV7HD4VpC2H0j81onb1L4dUfm181FzXrVC3NhX9MhsHnwOXNbuzasth8sUX1havfpTR8IOPu/wyAK04byGurWyYwa8/VUwZRWlnLB5sOM25ATLv5eYQ42XgsTYBSagDwCtAXcADPaa0fa28fjwT1Y9nw2DiYfg+c/VvXHDN/G2x8Dbb8x4ywGf1jmPdPU+P1dUVZ8PEdZnTQmEtMMG/sywfMF9UlL8LYeQ3L37oGdn8KN38PsYNaHjd3Hfz7Yug3Hq55nz0F5RwoPsGMkSb/zj++yuLPn+12bv7dwumc8fBXnS72DWelc/cFo7p0qkL4I082v9QB/6u1HglMAW5WSnn/rzA2DQZNNU0wPfm1UXIQVj0Dz55tmi1WPwOpp8Jli8zwxd4Q0AEShsLV70DGpS0DOsC0O2HAafDfW+HofrNsz5ew/X046zetB3SA1Emmg3jfMtj3NackRToDOsAt04fyyCVjne/7xYSxZMGZzvfPXDWR7IcvoH9MWKuHf37FfhyOhut3orqOv32+m+NVtZ0/dyGEU5ebX5RS7wP/0Fp/3tY2HqmpQ8NQw8HTTLvysNmtB7R6Wpu7Qg98Cwe+M8+lOWZdyjgYd4Wpxfpy+3lPlByEZ840/RE//a/pBNYOuGklBIW2vV9tFTwxEaL7maGTrXzRaa07HOpYn5hszx/mMOvvy9lbaNr4lyw4kyGJkbz+/UHu/29D6uBNv5tJn7Agisur2ZlXxilJkSRHt1NOIXoxr2RpVEqlAcuBMVrrNscTeiyo2+vgu8dgzYtw/BD0GQCZP4OJPzWB+UQxHF4Ph9Y3PJ+wpo+LSIRBZ8CgMyH9bEga4f7y+oLtH8BbV5t29+IsuPJtGHpex/ut+xf8dwFc/gYMn+OSoqzcW8zlz3c+Rz7Ayjunk9Knoda/48hx0uIjCAtu58tciF7A40FdKRUJfA38QWv9TivrbwRuBBg4cOCkAwdaH/7mFvY62PURrHke9i+HgGCI7Aul9R15yjRP9JsIA6eYZpuEob2nacXVlvwvrHkBRv4ALvt35/ax18KTp0FgKPziG7D1fOBUVa2dEf/3SYvlmYNi253E5LH545k5qi+VtXYm/t78YEyLD2fZb88FzK+Gr3cXcsaQBCpr7WzMKSHnaAV2h+YH4/oRZ013KIQv8WhQV0oFAR8Cn2qt/9rR9h6rqbemcBesfcl0dKaMh/4TzXNotHfK44tqK01Qz5gPkV1ICbxlMbx9fcvO1h5YkVXIU0v38sr1k1skErv6xdWsyDKzOz1++QQWvL6h3WPdOWcEi1Yf5ODRina3kzH0whd5cvSLAv4FHNVa39qZg3o1qAv3cTjg2bOgtsKMlglomT/enfYUlHPeX79usTwuIpijJ2o6fZzfzhrOTecMaciP38xn2/I4e1gioUHSpCM8x1VBPbDjTZgKXA1sUUpttJbdpbX+qJ19hD+y2WD6/8Hrl8HGRTDpWo9+/ClJkc5a9uGSSj7dlsf0EUkMjAtvksfm7GGJXJY5gJtfM4n9j5l9AAASNUlEQVTKxvSP5onLJ/Lgh9v5cmcBf/p0F6FBAdTUOXjkk53MGdOXjNQYLp88gNxjldz46jrOGBLPazdMafL51XV2ggNskvtG+LTee/OR8A6t4cWZ5qalBRvaHzXjYZtyStiVV+ac/MTh0GQXn2BwYiTQdht+WxbMGMrjX2YBTZt/3r7pdCYNinNx6cXJ7uSbo1T4jv0r4F8X9mi+WG8prahl3AOf9fg491wwkqeX7aXYavY5a2gCr15/Wo+PK05eJ3fuF+Fd6WeZrJVfPwLL/2zu7u0l+oQHsebuhiGc2x+YxYi+UU3mkP3ntad2eJwHl+xwBnSAFVlFvLfhkPN9/Z23Qnia1NRF9xTtgQ9ugYMrzfsBp8HYn5jUCr3g5i2HQ6MUTdrHK2vsBNgUwYFN6zpaa/KOVxEZEkhUaBATf/95pztm5586gIcvyeCzbXnc+Oo65/K/XjqOH0/oz+HSKoA277gVJw9pfhG+4dgB2Pq2yZdTsB1sgSZx2OyHIcg/A1Wd3UF28QnSEyIJsEbQ1N8t210LZgwlOjSQ689Ml47Yk5QEdeF78rfBupfh++cgeQxc+grED/F2qTxCa82Zjyx1phdecfu5zH1sBWXVXZ9Ld2hSJBdPTOWmaUP440c7mDEymcnpcVTX2SmvqsOmFBN+/zn3XDCSq08fREhgAMdO1GDXmoRIH5g7V3SLBHXhu7I+h3duMHf6/uhJGHWRt0vkNS99s5831+TwyvWTm+StWZt9lLve3cKzV2dy7p+XdXicM09J4Js9Ra2um5wWx/fZZrapSzNTeXTeOOe60opa5j6+guBAGz8Y14+bzx3inJRc+BYJ6sK3leTAf66FQ2vhtJvg/AcgsBO352tthktG92s/OZsfuvf9rbyy0v3pNV65bjJnD2v9TuLKGjvf7S0iONDGWUPNNsXl1aw7cIyZo/u6vWwnMwnqwvfV1cDn98Lqp03enZE/gPhTTN6d2HQzxl1rM+tS9gozVDL7G6goMhOfnPYLmHD1SZfiQWvNp9vy+MW/1zdZnpHahyevmEhVrZ0hiZGsPXCMS581HdVTT4nn/JHJ3Ncoy2V7IoID+Ntl45k5ui8vf7u/zf0untifd9Y3jOpZd895hAYFEBHS8r7FwrJqKmvsDIwP7+ypikYkqIveY9u78Ok9cDy30UIFMQNMWt/6zJnR/SHtLEjJgB3/NSNrgqNMx+tp/wNx6V4pfm+Sc7SCsx41E433jQ7lxWszGZUSjVIKrXWTO2974qZpQ5gxIomM1Biq6+yMva9h7P+CGUP59fnDKCirItFq45fO345JUBe9T9VxOLrX5LQvyjKpf22BJmtm+lmm9t74j//Qemve1XfAYYch50L/SZA8GpLHmiB/kjXR9NSyXQVc+881ra5bMP0U5oxNITY8mJ15x5tsd+0Zabz8XXaPPnvN3eeRGGWCvMOh2ZVfRklFLZc/v4qbzx3Cb2eNoKbOwZtrDjJrTF+0hupax0lT85egLk4ex4+YtMo7PoTiPaCtCa6DwiFpJCSOMM06zZt2RLuKyqsJstk4XlXLgLiWgTOvtIrv9hZx8cRUAI6UVvL69znO1AnNjegbRf+YML7cWeC2Mj995UTmjE1psbyq1s7tizdz49mDGd43qkXGz66wOzTn/Gkpuccquf7MdP7vwlE4HJqKWjuRrTQ7taWq1t6lpHAS1MXJqbYKCnea4ZP52yB/i6n1lx1ptJEybfKJw63HCEgYDonDILSP14rub3YcOc6cx1a0yGX/381H2J1XxoyRSQTabBw4eoJbXms/bXJ3PHDRaBIiQ7hj8eY2h44OTozglnNP4ddvbeLpKycya3Rfbnl9PR9tyXNus/m+mUSHmoyjHd1vcNO0Idwx20yok5VfxoC48BaBe09BGQte38j2I2YeoZEp0Xz8q7OoqKkjPDiQ+ph75ztbeGNNDqvvmkFydKgEdSGaqC4ztfj6pp2i3dYjC+zVDdsFhpomHxVgsk6qADOpSvwQM7Y+eTQkj4LEkRB8cvzs95Rvsoq46sXVxEcEM31EEo/Oy+B4ZR19woO46Mlv2ZRTwl1zRzB7dApJ0SF8vPUIdyzeQo3d4fayXXP6IE5JiuTe97d1+xjr/+981h84xs9f6V7sO/DIhRLUheiQw25y0xTuMjX8yqMmL7y2m3Xabmr/RbvNHbG19RNsKCvQjzbBPmmUeR0zyCWzPonu2XqolAuf+KbVdStuP5fU2LBOdwZfljmAN9fmtFh+QUYKT8yfgM2m+Hp3IT996Xuum5pO8Ylq3t94uEvlnTEiqdPNURLUhXA1hwOO7W/UtLPVBPqj+wHr7yQ4EvpNMLluBk6B1EwIi/VqsU9W9bGro5E1OUcrSIoOobSilqpaBwPiwprs8/cvdvP3Lxr6Cfb/cW6bxzxSWsn7Gw+TEBnCyJQoBsSF88HGw9zz3tYm2335v+eQGhtGSGAAJRU1/HbxZlZkFVJV62D3g3NQCt7bcIgJA2OdE79IUBfCU6rLrXb8rZC3BXLXmuf6DtvEkTDwNEg/x0xi3gsSmgnX0lpTVl1HeFAAgd3spPXkzEdCnNxCIk2NPLXR31t1ORxeDzmr4eBq2PqOyXsD0HesCfCDp5nhmtI27/eUUs7OVm+TmroQrmCvgyMbYd9S2Pe1Cfb2GggIgbQzYdgsGHo+xA32dkmFj5LRL0L4spoKc0fsni8h6zNzoxWYsfRpZ5mbrGpONH1EJMCQ6XDKDAn+JyEJ6kL0JsV7Yc8XJsDnrIGAIAiOMB2vweHmRqpj2VBiJfSKGwxDZpg2ensNHD8EpYfM8/FD5u7c4HAIimjYPyTKbD/mEgiUFLy9jQR1IfyN1nB0n6nd7/nCJDlzDrHE5MHp09/kyAmLgdpKqCk3vwpqK6CiGMrzISIJTv05ZF4Hka1nYxS+R4K6EP6urhqObDK1+T79O74bVmvTpr/qafOLICAEMn4CmdebdAptzURVkgMHvoMD35ohnIkjTAfvoDPMnbmSjMsjJKgLIdpWuBtWPwMbX4M6MxsTEUkmSMcMgD4DoLzABPPSg2Z9SB9zN23BdqgqNcuiU01wTxkHUX0hMtl6JJkvGQn4LiNBXQjRsYqjpjmnJBtKDjZ65JgmnEFnNNTKk0aZrJcOhwns9bX3A981pEduLCDE9AsEhpoEaoHWIyjc5MAP7QMh1nNoNITHQ0Si6RCOSITwBEm81ogEdSFE9zkcppbdmZq21lB5DE4UQlmeqeGX55tHbQXUVZlUC3XWo6YCqo+bztyqUvOaNuJMUISZESsgGGxBpgM5IMh0+kYkmT6BiETrdRLEDjJZOMPjXPrP4Qvk5iMhRPd1JX+NUiaIhseZrJdd5XBATZn51XCiyHw51D8qjprRPY5asNc/aswXQWmuucHrRFHD3bv1QmNMPv3YdBPs6/ez11rHqgGU+eXhTOBmvQ6OMP0LQdaooeBw86sjIMisDwiyvmCs8Ois+FrPyma+hAKCrS8h6wtJ1+cUqrPyCjnMM9o6hjbLGv5hrS9VZY7pIhLUhRDuZbNZTTB9ujd7lcNhErGV5Zlhn8f2m3w8x/bD4Q3mi6E+uNbX9G3W3Z2OukaB1mGCfW0l1J5oFmD9hwR1IYRvs9msdvgE6DvGNcfU2grwFaa5yF5t7gqu/8XgqDPPzuYp61kpU/t2NPplUP+sVMtfBc6aeH1t3HrtrLk3er7/PJecmgR1IcTJRylzg1ZgiN9l2ZTE0EII4UckqAshhB/pMKgrpV5SShUopbZ2tK0QQgjv6kxN/WVgtpvLIYQQwgU6DOpa6+XAUQ+URQghRA9Jm7oQQvgRlwV1pdSNSqm1Sqm1hYWFrjqsEEKILnBZUNdaP6e1ztRaZyYmSg5nIYTwBml+EUIIP9KZIY2vAyuB4UqpXKXU9e4vlhBCiO7oME2A1vpyTxRECCFEz0nzixBC+BEJ6kII4UckqAshhB+RoC6EEH5EgroQQvgRCepCCOFHJKgLIYQfkaAuhBB+RIK6EEL4EQnqQgjhRySoCyGEH5GgLoQQfkSCuhBC+BEJ6kII4UckqAshhB+RoC6EEH5EgroQQvgRCepCCOFHJKgLIYQfkaAuhBB+RIK6EEL4EQnqQgjhRySoCyGEH5GgLoQQfkSCuhBC+BEJ6kII4UckqAshhB+RoC6EEH5EgroQQvgRCepCCOFHJKgLIYQf6VRQV0rNVkrtUkrtUUotdHehhBBCdE+HQV0pFQA8CcwBRgGXK6VGubtgQgghuq4zNfXJwB6t9T6tdQ3wBnCRe4slhBCiOzoT1PsDOY3e51rLhBBC+JjATmyjWlmmW2yk1I3AjdbbaqXU1p4UzIclAEXeLoSbyLn1Pv56XnDyndsgVxy4M0E9FxjQ6H0qcLj5Rlrr54DnAJRSa7XWma4ooK+Rc+ud/PXc/PW8QM6tuzrT/LIGGKqUSldKBQPzgQ/cURghhBA902FNXWtdp5S6BfgUCABe0lpvc3vJhBBCdFlnml/QWn8EfNSF4z7XveL0CnJuvZO/npu/nhfIuXWL0rpFn6cQQoheStIECCGEH3FpUO+N6QSUUgOUUkuVUjuUUtuUUr+ylscppT5XSmVZz7HWcqWUetw6x81KqYmNjvVTa/sspdRPvXVOjSmlApRSG5RSH1rv05VSq60yvml1fqOUCrHe77HWpzU6xp3W8l1KqVneOZOWlFIxSqnFSqmd1vU73Y+u223W/8etSqnXlVKhvfXaKaVeUkoVNB7m7MrrpJSapJTaYu3zuFKqtWHYnjy3P1n/Jzcrpd5VSsU0Wtfq9WgrdrZ1zdultXbJA9OJuhcYDAQDm4BRrjq+ux5ACjDReh0F7MakQ3gUWGgtXwg8Yr2eC3yMGb8/BVhtLY8D9lnPsdbrWB84v18DrwEfWu/fAuZbr58BbrJe/xJ4xno9H3jTej3KupYhQLp1jQO8fV5W2f4F/Nx6HQzE+MN1w9zctx8Ia3TNru2t1w44G5gIbG20zGXXCfgeON3a52NgjpfPbSYQaL1+pNG5tXo9aCd2tnXN2y2TC0/udODTRu/vBO70xh9FD8/jfeB8YBeQYi1LAXZZr58FLm+0/S5r/eXAs42WN9nOS+eSCnwJTAc+tP7TFzX6D+e8ZpjRTadbrwOt7VTz69h4Oy+fWzQm8Klmy/3hutXfxR1nXYsPgVm9+doBac0Cn0uuk7VuZ6PlTbbzxrk1W/djYJH1utXrQRuxs72/1/Yermx+6fXpBKyfrROA1UCy1voIgPWcZG3W1nn64vn/HbgdcFjv44ESrXWd9b5xGZ3lt9aXWtv74nmBqdUUAv+0mpdeUEpF4AfXTWt9CPgzcBA4grkW6/Cfaweuu079rdfNl/uK6zC/HqDr59be32ubXBnUO5VOwFcppSKBt4FbtdbH29u0lWW6neVeoZS6ECjQWq9rvLiVTXUH63zqvBoJxPzsfVprPQE4gfkZ35Zec35W+/JFmJ/o/YAITJbU5nrrtWtPV8/FZ89RKXU3UAcsql/UymYuPzdXBvVOpRPwRUqpIExAX6S1fsdanK+USrHWpwAF1vK2ztPXzn8q8EOlVDYms+Z0TM09RilVf39C4zI6y2+t7wMcxffOq14ukKu1Xm29X4wJ8r39ugGcB+zXWhdqrWuBd4Az8J9rB667TrnW6+bLvcrqyL0QuFJbbSd0/dyKaPuat8mVQb1XphOwespfBHZorf/aaNUHQH0P+08xbe31y6+xeumnAKXWz8dPgZlKqVirpjXTWuYVWus7tdapWus0zLX4Smt9JbAUmGdt1vy86s93nrW9tpbPt0ZYpANDMR1TXqW1zgNylFLDrUUzgO308utmOQhMUUqFW/8/68/NL66dxSXXyVpXppSaYv1bXdPoWF6hlJoN3AH8UGtd0WhVW9ej1dhpXcO2rnnbXNxhMBczemQvcLcnOyt6UOYzMT9pNgMbrcdcTHvWl0CW9Rxnba8wk4bsBbYAmY2OdR2wx3r8zNvn1qhc02gY/TLY+o+0B/gPEGItD7Xe77HWD260/93W+e7CgyMLOnFe44G11rV7DzMqwi+uG3A/sBPYCryKGTHRK68d8Dqmb6AWUyu93pXXCci0/p32Av+gWee5F85tD6aNvD6ePNPR9aCN2NnWNW/vIXeUCiGEH5E7SoUQwo9IUBdCCD8iQV0IIfyIBHUhhPAjEtSFEMKPSFAXQgg/IkFdCCH8iAR1IYTwI/8f6jYy5Tdgec4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-3\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd, div_factor=25, final_div=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"b0_sz300_60epochs_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1280, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f7bb06ec158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "  (3): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "  (11): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (12): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (13): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (14): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "  (19): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (20): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (21): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (22): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "  (27): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (28): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (29): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (30): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "  (35): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (36): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (37): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (38): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "  (43): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (44): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (45): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (46): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (51): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (52): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (53): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (54): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (57): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (59): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (60): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (61): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (62): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "  (67): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (68): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (69): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (70): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (73): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (75): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (76): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (77): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (78): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (81): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (83): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (84): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (85): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (86): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (89): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "  (91): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (92): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (93): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (94): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (97): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (99): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (100): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (101): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (102): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (105): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (107): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (108): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (109): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (110): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (113): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (115): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (116): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (117): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (118): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (121): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "  (123): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (124): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (125): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (126): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (129): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Dropout(p=0.5)\n",
       "  (131): Linear(in_features=1280, out_features=196, bias=True)\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"b0_sz300_60epochs_001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"exported_models/b0_300x300_2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B0, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop 1.2, cutout p0.5, wd=1e-3, LabelSmoothing, mixup\n",
    "\n",
    "acc = 0.936118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.2), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.5)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b0\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Parameter containing:\n",
      "tensor([[ 0.0578,  0.0263, -0.0778,  ..., -0.0094, -0.0485, -0.0246],\n",
      "        [-0.0734, -0.0396, -0.0109,  ...,  0.0324,  0.0119, -0.0037],\n",
      "        [ 0.0089, -0.0328,  0.0024,  ..., -0.0174,  0.0379, -0.0387],\n",
      "        ...,\n",
      "        [-0.0383,  0.0002, -0.0413,  ..., -0.0609, -0.0292,  0.0201],\n",
      "        [ 0.0377, -0.0567, -0.0270,  ..., -0.0283, -0.0108,  0.0571],\n",
      "        [-0.0219, -0.0084, -0.0193,  ..., -0.0436, -0.0485, -0.0315]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1280, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f04f6cea158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "  (3): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "  (11): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (12): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (13): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (14): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "  (19): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (20): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (21): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (22): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "  (27): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (28): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (29): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (30): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "  (35): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (36): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (37): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (38): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "  (43): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (44): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (45): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (46): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (51): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (52): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (53): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (54): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (57): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (59): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (60): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (61): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (62): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "  (67): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (68): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (69): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (70): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (73): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (75): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (76): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (77): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (78): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (81): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (83): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (84): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (85): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (86): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (89): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "  (91): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (92): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (93): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (94): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (97): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (99): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (100): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (101): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (102): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (105): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (107): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (108): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (109): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (110): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (113): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (115): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (116): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (117): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (118): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (121): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "  (123): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (124): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (125): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (126): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (129): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Dropout(p=0.5)\n",
       "  (131): Linear(in_features=1280, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b0\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.254633</td>\n",
       "      <td>5.096426</td>\n",
       "      <td>0.038698</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.856395</td>\n",
       "      <td>4.322017</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.001905</td>\n",
       "      <td>3.115630</td>\n",
       "      <td>0.396192</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.140227</td>\n",
       "      <td>2.265328</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.677396</td>\n",
       "      <td>2.010758</td>\n",
       "      <td>0.677518</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.511854</td>\n",
       "      <td>2.001122</td>\n",
       "      <td>0.696560</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.384186</td>\n",
       "      <td>2.062442</td>\n",
       "      <td>0.662776</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.391763</td>\n",
       "      <td>2.100782</td>\n",
       "      <td>0.649263</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.374131</td>\n",
       "      <td>2.086936</td>\n",
       "      <td>0.656634</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.427301</td>\n",
       "      <td>2.318772</td>\n",
       "      <td>0.617936</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.416269</td>\n",
       "      <td>2.584761</td>\n",
       "      <td>0.553440</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.436724</td>\n",
       "      <td>2.259740</td>\n",
       "      <td>0.618550</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.422313</td>\n",
       "      <td>2.355909</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.406947</td>\n",
       "      <td>2.699373</td>\n",
       "      <td>0.512899</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.363611</td>\n",
       "      <td>2.409693</td>\n",
       "      <td>0.566953</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.333286</td>\n",
       "      <td>2.388518</td>\n",
       "      <td>0.584152</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.329538</td>\n",
       "      <td>2.363305</td>\n",
       "      <td>0.592138</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.277310</td>\n",
       "      <td>1.850109</td>\n",
       "      <td>0.735258</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.210807</td>\n",
       "      <td>2.056357</td>\n",
       "      <td>0.673833</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.147680</td>\n",
       "      <td>1.945777</td>\n",
       "      <td>0.708845</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.093321</td>\n",
       "      <td>1.999517</td>\n",
       "      <td>0.703317</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.118692</td>\n",
       "      <td>1.783138</td>\n",
       "      <td>0.757371</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.095176</td>\n",
       "      <td>1.825327</td>\n",
       "      <td>0.761671</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.034169</td>\n",
       "      <td>1.751019</td>\n",
       "      <td>0.761056</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.960843</td>\n",
       "      <td>1.718725</td>\n",
       "      <td>0.782555</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.982107</td>\n",
       "      <td>1.593377</td>\n",
       "      <td>0.816339</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.940648</td>\n",
       "      <td>1.553163</td>\n",
       "      <td>0.829853</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.900862</td>\n",
       "      <td>1.489615</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.882838</td>\n",
       "      <td>1.538320</td>\n",
       "      <td>0.835381</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.892986</td>\n",
       "      <td>1.515210</td>\n",
       "      <td>0.856880</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.871531</td>\n",
       "      <td>1.489924</td>\n",
       "      <td>0.848894</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.787533</td>\n",
       "      <td>1.464381</td>\n",
       "      <td>0.843366</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.809646</td>\n",
       "      <td>1.443623</td>\n",
       "      <td>0.863022</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.758825</td>\n",
       "      <td>1.354074</td>\n",
       "      <td>0.890049</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.742888</td>\n",
       "      <td>1.406966</td>\n",
       "      <td>0.874693</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.747915</td>\n",
       "      <td>1.361692</td>\n",
       "      <td>0.887592</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.696153</td>\n",
       "      <td>1.311917</td>\n",
       "      <td>0.896192</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.691109</td>\n",
       "      <td>1.295212</td>\n",
       "      <td>0.899263</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.686497</td>\n",
       "      <td>1.276706</td>\n",
       "      <td>0.907862</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.685313</td>\n",
       "      <td>1.275070</td>\n",
       "      <td>0.912162</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.626489</td>\n",
       "      <td>1.257434</td>\n",
       "      <td>0.909705</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.648994</td>\n",
       "      <td>1.266723</td>\n",
       "      <td>0.914619</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.614186</td>\n",
       "      <td>1.241366</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.603901</td>\n",
       "      <td>1.235133</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.587783</td>\n",
       "      <td>1.220074</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.595696</td>\n",
       "      <td>1.201861</td>\n",
       "      <td>0.929361</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.571914</td>\n",
       "      <td>1.197159</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.555971</td>\n",
       "      <td>1.171591</td>\n",
       "      <td>0.926904</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.588009</td>\n",
       "      <td>1.182021</td>\n",
       "      <td>0.928133</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.516295</td>\n",
       "      <td>1.179476</td>\n",
       "      <td>0.930590</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.521571</td>\n",
       "      <td>1.176514</td>\n",
       "      <td>0.933661</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.523089</td>\n",
       "      <td>1.160072</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.537594</td>\n",
       "      <td>1.161875</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.514839</td>\n",
       "      <td>1.155540</td>\n",
       "      <td>0.933047</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.517779</td>\n",
       "      <td>1.150407</td>\n",
       "      <td>0.936118</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.524650</td>\n",
       "      <td>1.156733</td>\n",
       "      <td>0.934889</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.505053</td>\n",
       "      <td>1.153749</td>\n",
       "      <td>0.934889</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.524774</td>\n",
       "      <td>1.154323</td>\n",
       "      <td>0.935504</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.519438</td>\n",
       "      <td>1.153139</td>\n",
       "      <td>0.934275</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.498528</td>\n",
       "      <td>1.153028</td>\n",
       "      <td>0.936118</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-3\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd, div_factor=25, final_div=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b0_sz300_60epochs_011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1280, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f04f6cea158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "  (3): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "  (11): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (12): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (13): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (14): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "  (19): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (20): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (21): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (22): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "  (27): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (28): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (29): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (30): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "  (35): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (36): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (37): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (38): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "  (43): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (44): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (45): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (46): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (51): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (52): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (53): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (54): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (57): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (59): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (60): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (61): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (62): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "  (67): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (68): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (69): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (70): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (73): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (75): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (76): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (77): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (78): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (81): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (83): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (84): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (85): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (86): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (89): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "  (91): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (92): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (93): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (94): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (97): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (99): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (100): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (101): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (102): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (105): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (107): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (108): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (109): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (110): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (113): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (115): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (116): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (117): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (118): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (121): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "  (123): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (124): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (125): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (126): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (129): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Dropout(p=0.5)\n",
       "  (131): Linear(in_features=1280, out_features=196, bias=True)\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"b0_sz300_60epochs_011\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"exported_models/b0_300x300_best.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B0, size=(300x300), 40 Epochs, normalize(imagenet_stats), zoom_crop 1.2, cutout p0.5, wd=1e-3, LabelSmoothing, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'learn' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.2), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.5)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b0\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "Parameter containing:\n",
      "tensor([[ 0.0578,  0.0263, -0.0778,  ..., -0.0094, -0.0485, -0.0246],\n",
      "        [-0.0734, -0.0396, -0.0109,  ...,  0.0324,  0.0119, -0.0037],\n",
      "        [ 0.0089, -0.0328,  0.0024,  ..., -0.0174,  0.0379, -0.0387],\n",
      "        ...,\n",
      "        [-0.0383,  0.0002, -0.0413,  ..., -0.0609, -0.0292,  0.0201],\n",
      "        [ 0.0377, -0.0567, -0.0270,  ..., -0.0283, -0.0108,  0.0571],\n",
      "        [-0.0219, -0.0084, -0.0193,  ..., -0.0436, -0.0485, -0.0315]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1280, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f368d7fb158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "  (3): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "  (11): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (12): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (13): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (14): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "  (19): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (20): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (21): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (22): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "  (27): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (28): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (29): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (30): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "  (35): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (36): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (37): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (38): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "  (43): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (44): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (45): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (46): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (51): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (52): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (53): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (54): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (57): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (59): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (60): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (61): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (62): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "  (67): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (68): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (69): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (70): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (73): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (75): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (76): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (77): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (78): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (81): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (83): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (84): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (85): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (86): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (89): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "  (91): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (92): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (93): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (94): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (97): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (99): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (100): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (101): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (102): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (105): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (107): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (108): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (109): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (110): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (113): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (115): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (116): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (117): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (118): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (121): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "  (123): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (124): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (125): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (126): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (129): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Dropout(p=0.5)\n",
       "  (131): Linear(in_features=1280, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b0\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.242587</td>\n",
       "      <td>5.066722</td>\n",
       "      <td>0.052211</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.699122</td>\n",
       "      <td>4.095806</td>\n",
       "      <td>0.208845</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.624947</td>\n",
       "      <td>2.727587</td>\n",
       "      <td>0.456388</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.932530</td>\n",
       "      <td>2.352403</td>\n",
       "      <td>0.551597</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.637507</td>\n",
       "      <td>3.014800</td>\n",
       "      <td>0.401106</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.597049</td>\n",
       "      <td>2.672515</td>\n",
       "      <td>0.488943</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.584540</td>\n",
       "      <td>2.534216</td>\n",
       "      <td>0.527641</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.615734</td>\n",
       "      <td>2.616491</td>\n",
       "      <td>0.490172</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.600395</td>\n",
       "      <td>2.678092</td>\n",
       "      <td>0.518427</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.581567</td>\n",
       "      <td>2.469617</td>\n",
       "      <td>0.577396</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.500597</td>\n",
       "      <td>2.233525</td>\n",
       "      <td>0.644963</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.459215</td>\n",
       "      <td>2.253375</td>\n",
       "      <td>0.640049</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.382778</td>\n",
       "      <td>2.349311</td>\n",
       "      <td>0.593366</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.297142</td>\n",
       "      <td>1.883305</td>\n",
       "      <td>0.731573</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.261142</td>\n",
       "      <td>2.043601</td>\n",
       "      <td>0.674447</td>\n",
       "      <td>01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.195846</td>\n",
       "      <td>1.886590</td>\n",
       "      <td>0.726044</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.118783</td>\n",
       "      <td>1.853543</td>\n",
       "      <td>0.730344</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.067958</td>\n",
       "      <td>1.786593</td>\n",
       "      <td>0.748771</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.999982</td>\n",
       "      <td>1.671008</td>\n",
       "      <td>0.792383</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.006664</td>\n",
       "      <td>1.655294</td>\n",
       "      <td>0.799140</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.891085</td>\n",
       "      <td>1.551153</td>\n",
       "      <td>0.825553</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.873339</td>\n",
       "      <td>1.637539</td>\n",
       "      <td>0.804668</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.861287</td>\n",
       "      <td>1.473454</td>\n",
       "      <td>0.843366</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.825089</td>\n",
       "      <td>1.444244</td>\n",
       "      <td>0.859951</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.767977</td>\n",
       "      <td>1.450742</td>\n",
       "      <td>0.855037</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.758705</td>\n",
       "      <td>1.428486</td>\n",
       "      <td>0.859951</td>\n",
       "      <td>00:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.716458</td>\n",
       "      <td>1.333218</td>\n",
       "      <td>0.885135</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.692370</td>\n",
       "      <td>1.329650</td>\n",
       "      <td>0.887592</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.667942</td>\n",
       "      <td>1.292755</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.663631</td>\n",
       "      <td>1.275300</td>\n",
       "      <td>0.897420</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.644174</td>\n",
       "      <td>1.277842</td>\n",
       "      <td>0.899263</td>\n",
       "      <td>01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.620684</td>\n",
       "      <td>1.259119</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.602755</td>\n",
       "      <td>1.235448</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.588360</td>\n",
       "      <td>1.234702</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.604032</td>\n",
       "      <td>1.222038</td>\n",
       "      <td>0.920147</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.574164</td>\n",
       "      <td>1.219407</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.564832</td>\n",
       "      <td>1.222207</td>\n",
       "      <td>0.917076</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.566212</td>\n",
       "      <td>1.218093</td>\n",
       "      <td>0.917076</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.601168</td>\n",
       "      <td>1.218292</td>\n",
       "      <td>0.917690</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.543080</td>\n",
       "      <td>1.218799</td>\n",
       "      <td>0.917076</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-3\n",
    "epochs = 40\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd, div_factor=25, final_div=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"b0_sz300_40epochs_021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Plymouth Neon Coupe 1999,Honda Odyssey Minivan 2012,Aston Martin Virage Convertible 2012,Fisker Karma Sedan 2012,Audi S6 Sedan 2011\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1280, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f368d7fb158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False)\n",
       "  (3): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (9): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False)\n",
       "  (11): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (12): Conv2dSamePadding(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (13): Conv2dSamePadding(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (14): Conv2dSamePadding(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
       "  (19): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (20): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (21): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (22): Conv2dSamePadding(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (25): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False)\n",
       "  (27): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (28): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (29): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (30): Conv2dSamePadding(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (33): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False)\n",
       "  (35): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (36): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (37): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (38): Conv2dSamePadding(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (41): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False)\n",
       "  (43): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (44): Conv2dSamePadding(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (45): Conv2dSamePadding(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (46): Conv2dSamePadding(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (49): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (51): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (52): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (53): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (54): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (57): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False)\n",
       "  (59): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (60): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (61): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (62): Conv2dSamePadding(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (65): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False)\n",
       "  (67): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (68): Conv2dSamePadding(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (69): Conv2dSamePadding(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (70): Conv2dSamePadding(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (73): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (75): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (76): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (77): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (78): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (81): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False)\n",
       "  (83): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (84): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (85): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (86): Conv2dSamePadding(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (89): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False)\n",
       "  (91): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (92): Conv2dSamePadding(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (93): Conv2dSamePadding(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (94): Conv2dSamePadding(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (97): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (99): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (100): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (101): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (102): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (105): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (107): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (108): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (109): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (110): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (113): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False)\n",
       "  (115): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (116): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (117): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (118): Conv2dSamePadding(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (121): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False)\n",
       "  (123): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (124): Conv2dSamePadding(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (125): Conv2dSamePadding(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (126): Conv2dSamePadding(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (129): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Dropout(p=0.5)\n",
       "  (131): Linear(in_features=1280, out_features=196, bias=True)\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.load(\"b0_sz300_40epochs_021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# B3, size=(300x300), 60 Epochs, normalize(imagenet_stats), zoom_crop 1.5, cutout p0.8, wd=1e-5, LabelSmoothing, mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Learner object self-destroyed - it still exists, but no longer usable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    learn.destroy()\n",
    "    del learn\n",
    "    gc.collect()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtra_tfms = zoom_crop(scale=(0.75,1.5), do_rand=True) + [cutout(n_holes=(1,4), length=(10, 40), p=0.8)]\n",
    "tfms = get_transforms(xtra_tfms=xtra_tfms)\n",
    "train_val_data, _ = get_train_test_data(tfms=tfms, bs=32, sz=(300, 300), normalize=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pretrained efficientnet-b3\n",
      "Loaded pretrained weights for efficientnet-b3\n",
      "Parameter containing:\n",
      "tensor([[ 0.0495, -0.0465,  0.0130,  ..., -0.0298, -0.0040,  0.0588],\n",
      "        [-0.0211,  0.0086,  0.0120,  ...,  0.0186,  0.0028,  0.0378],\n",
      "        [-0.0416,  0.0104, -0.0075,  ...,  0.0444, -0.0338, -0.0107],\n",
      "        ...,\n",
      "        [-0.0088, -0.0501, -0.0270,  ...,  0.0581,  0.0089,  0.0060],\n",
      "        [ 0.1170, -0.0492,  0.0538,  ..., -0.0273,  0.0469,  0.0261],\n",
      "        [-0.0158,  0.0151,  0.0020,  ..., -0.0684,  0.0088, -0.0035]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Learner(data=ImageDataBunch;\n",
       "\n",
       "Train: LabelList (6516 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Audi TTS Coupe 2012,Acura TL Sedan 2012,Dodge Dakota Club Cab 2007,Hyundai Sonata Hybrid Sedan 2012,Ford F-450 Super Duty Crew Cab 2012\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Valid: LabelList (1628 items)\n",
       "x: ImageList\n",
       "Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300),Image (3, 300, 300)\n",
       "y: CategoryList\n",
       "Aston Martin Virage Coupe 2012,Honda Accord Coupe 2012,Land Rover Range Rover SUV 2012,Ford Freestar Minivan 2007,Bugatti Veyron 16.4 Coupe 2009\n",
       "Path: Data/cars_train;\n",
       "\n",
       "Test: None, model=EfficientNet(\n",
       "  (_conv_stem): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_se_expand): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (_project_conv): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_fc): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=1536, out_features=196, bias=True)\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=LabelSmoothingCrossEntropy(), metrics=[<function accuracy at 0x7f7a9423e158>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False), <class 'fastai.train.ShowGraph'>, functools.partial(<class 'fastai.callbacks.mixup.MixUpCallback'>, alpha=0.2, stack_x=False, stack_y=True)], callbacks=[MixedPrecision\n",
       "learn: ...\n",
       "loss_scale: 65536\n",
       "max_noskip: 1000\n",
       "dynamic: True\n",
       "clip: None\n",
       "flat_master: False\n",
       "max_scale: 16777216], layer_groups=[Sequential(\n",
       "  (0): Conv2dSamePadding(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (2): Conv2dSamePadding(40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False)\n",
       "  (3): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (4): Conv2dSamePadding(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2dSamePadding(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (6): Conv2dSamePadding(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (7): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (8): Conv2dSamePadding(24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False)\n",
       "  (9): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (10): Conv2dSamePadding(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (11): Conv2dSamePadding(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (12): Conv2dSamePadding(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (13): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (14): Conv2dSamePadding(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (15): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (16): Conv2dSamePadding(144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False)\n",
       "  (17): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (18): Conv2dSamePadding(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (19): Conv2dSamePadding(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (20): Conv2dSamePadding(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (21): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (22): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (23): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (24): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (25): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (26): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (27): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (28): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (29): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (30): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (31): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (32): Conv2dSamePadding(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
       "  (33): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (34): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (35): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (36): Conv2dSamePadding(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (37): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (38): Conv2dSamePadding(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (39): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (40): Conv2dSamePadding(192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False)\n",
       "  (41): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (42): Conv2dSamePadding(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (43): Conv2dSamePadding(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (44): Conv2dSamePadding(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (45): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (46): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (47): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (48): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (49): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (50): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (51): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (52): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (53): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (54): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (55): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (56): Conv2dSamePadding(288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False)\n",
       "  (57): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (58): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (59): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (60): Conv2dSamePadding(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (61): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (62): Conv2dSamePadding(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (63): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (64): Conv2dSamePadding(288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False)\n",
       "  (65): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (66): Conv2dSamePadding(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (67): Conv2dSamePadding(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (68): Conv2dSamePadding(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (69): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (70): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (71): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (72): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (73): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (74): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (75): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (76): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (77): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (78): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (79): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (80): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (81): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (82): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (83): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (84): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (85): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (86): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (87): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (88): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (89): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (90): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (91): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (92): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (93): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (94): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (95): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (96): Conv2dSamePadding(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
       "  (97): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (98): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (99): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (100): Conv2dSamePadding(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (101): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (102): Conv2dSamePadding(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (103): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (104): Conv2dSamePadding(576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False)\n",
       "  (105): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (106): Conv2dSamePadding(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (107): Conv2dSamePadding(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (108): Conv2dSamePadding(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (109): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (110): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (111): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (112): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (113): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (114): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (115): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (116): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (117): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (118): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (119): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (120): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (121): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (122): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (123): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (124): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (125): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (126): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (127): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (128): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (129): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (130): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (131): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (132): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (133): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (134): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (135): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (136): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False)\n",
       "  (137): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (138): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (139): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (140): Conv2dSamePadding(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (141): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (142): Conv2dSamePadding(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (143): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (144): Conv2dSamePadding(816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False)\n",
       "  (145): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (146): Conv2dSamePadding(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (147): Conv2dSamePadding(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (148): Conv2dSamePadding(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (149): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (150): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (151): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (152): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (153): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (154): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (155): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (156): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (157): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (158): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (159): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (160): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (161): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (162): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (163): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (164): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (165): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (166): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (167): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (168): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (169): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (170): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (171): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (172): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (173): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (174): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (175): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (176): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (177): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (178): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (179): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (180): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (181): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (182): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (183): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (184): Conv2dSamePadding(1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False)\n",
       "  (185): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (186): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (187): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (188): Conv2dSamePadding(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (189): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (190): Conv2dSamePadding(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (191): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (192): Conv2dSamePadding(1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False)\n",
       "  (193): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (194): Conv2dSamePadding(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (195): Conv2dSamePadding(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (196): Conv2dSamePadding(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (197): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (198): Conv2dSamePadding(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (199): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (200): Conv2dSamePadding(2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False)\n",
       "  (201): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (202): Conv2dSamePadding(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (203): Conv2dSamePadding(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (204): Conv2dSamePadding(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (205): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (206): Conv2dSamePadding(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (207): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (208): Dropout(p=0.5)\n",
       "  (209): Linear(in_features=1536, out_features=196, bias=True)\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eff_net = get_effnet(name=\"efficientnet-b3\", pretrained=True, n_class=196)\n",
    "learn = Learner(train_val_data, eff_net, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=[accuracy], path='.', callback_fns=ShowGraph).mixup(alpha=0.2)\n",
    "learn.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.231212</td>\n",
       "      <td>5.028637</td>\n",
       "      <td>0.078010</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.682130</td>\n",
       "      <td>4.054018</td>\n",
       "      <td>0.220516</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.646350</td>\n",
       "      <td>2.714485</td>\n",
       "      <td>0.519656</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.899469</td>\n",
       "      <td>2.046319</td>\n",
       "      <td>0.643735</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.527941</td>\n",
       "      <td>1.948936</td>\n",
       "      <td>0.679975</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.410370</td>\n",
       "      <td>1.974418</td>\n",
       "      <td>0.668305</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.399850</td>\n",
       "      <td>2.030266</td>\n",
       "      <td>0.664619</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.398074</td>\n",
       "      <td>2.054531</td>\n",
       "      <td>0.680590</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.423125</td>\n",
       "      <td>2.585084</td>\n",
       "      <td>0.515356</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.412072</td>\n",
       "      <td>2.244997</td>\n",
       "      <td>0.613022</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.432037</td>\n",
       "      <td>2.233859</td>\n",
       "      <td>0.619779</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.437134</td>\n",
       "      <td>2.571075</td>\n",
       "      <td>0.544226</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.450593</td>\n",
       "      <td>2.652452</td>\n",
       "      <td>0.512285</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.447934</td>\n",
       "      <td>2.266950</td>\n",
       "      <td>0.620393</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.438601</td>\n",
       "      <td>2.179502</td>\n",
       "      <td>0.646192</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.390701</td>\n",
       "      <td>2.124672</td>\n",
       "      <td>0.656634</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.355935</td>\n",
       "      <td>1.991218</td>\n",
       "      <td>0.684275</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.328822</td>\n",
       "      <td>1.882246</td>\n",
       "      <td>0.727887</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.242237</td>\n",
       "      <td>2.035070</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.178840</td>\n",
       "      <td>1.897969</td>\n",
       "      <td>0.716830</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.148582</td>\n",
       "      <td>1.855110</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.105736</td>\n",
       "      <td>1.705587</td>\n",
       "      <td>0.769656</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.099848</td>\n",
       "      <td>1.771425</td>\n",
       "      <td>0.759214</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.025066</td>\n",
       "      <td>1.754563</td>\n",
       "      <td>0.766585</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.007826</td>\n",
       "      <td>1.670918</td>\n",
       "      <td>0.785627</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.005703</td>\n",
       "      <td>1.672227</td>\n",
       "      <td>0.791769</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.960651</td>\n",
       "      <td>1.579589</td>\n",
       "      <td>0.815111</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.944057</td>\n",
       "      <td>1.659666</td>\n",
       "      <td>0.799754</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.908125</td>\n",
       "      <td>1.463860</td>\n",
       "      <td>0.846437</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.851783</td>\n",
       "      <td>1.492193</td>\n",
       "      <td>0.830467</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.839497</td>\n",
       "      <td>1.518373</td>\n",
       "      <td>0.822482</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.839861</td>\n",
       "      <td>1.461246</td>\n",
       "      <td>0.851966</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.761051</td>\n",
       "      <td>1.423412</td>\n",
       "      <td>0.842752</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.780562</td>\n",
       "      <td>1.366248</td>\n",
       "      <td>0.864251</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.771680</td>\n",
       "      <td>1.357081</td>\n",
       "      <td>0.872850</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.714115</td>\n",
       "      <td>1.374114</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.726629</td>\n",
       "      <td>1.359514</td>\n",
       "      <td>0.869779</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.691586</td>\n",
       "      <td>1.330410</td>\n",
       "      <td>0.871007</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.666427</td>\n",
       "      <td>1.314083</td>\n",
       "      <td>0.877764</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.683746</td>\n",
       "      <td>1.292734</td>\n",
       "      <td>0.881450</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.623715</td>\n",
       "      <td>1.272427</td>\n",
       "      <td>0.888206</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.631971</td>\n",
       "      <td>1.256206</td>\n",
       "      <td>0.893120</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.636439</td>\n",
       "      <td>1.260153</td>\n",
       "      <td>0.888821</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.596055</td>\n",
       "      <td>1.242190</td>\n",
       "      <td>0.894963</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.590509</td>\n",
       "      <td>1.251246</td>\n",
       "      <td>0.890663</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.569705</td>\n",
       "      <td>1.216439</td>\n",
       "      <td>0.900491</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.571933</td>\n",
       "      <td>1.214139</td>\n",
       "      <td>0.904177</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.527650</td>\n",
       "      <td>1.209880</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.549700</td>\n",
       "      <td>1.191844</td>\n",
       "      <td>0.912162</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.523661</td>\n",
       "      <td>1.197750</td>\n",
       "      <td>0.911548</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.541965</td>\n",
       "      <td>1.184354</td>\n",
       "      <td>0.911548</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.546042</td>\n",
       "      <td>1.192877</td>\n",
       "      <td>0.914005</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.532266</td>\n",
       "      <td>1.183432</td>\n",
       "      <td>0.914619</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.527235</td>\n",
       "      <td>1.182518</td>\n",
       "      <td>0.915233</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.506816</td>\n",
       "      <td>1.179246</td>\n",
       "      <td>0.914619</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.505566</td>\n",
       "      <td>1.177555</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.524955</td>\n",
       "      <td>1.176958</td>\n",
       "      <td>0.914619</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.498409</td>\n",
       "      <td>1.176091</td>\n",
       "      <td>0.915233</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.504452</td>\n",
       "      <td>1.175925</td>\n",
       "      <td>0.914005</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.517592</td>\n",
       "      <td>1.176217</td>\n",
       "      <td>0.914005</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = 3e-3\n",
    "wd = 1e-3\n",
    "epochs = 60\n",
    "learn.fit_one_cycle(epochs, max_lr=lr, wd=wd, div_factor=25, final_div=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save(\"b3_sz300_60epochs_021\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
